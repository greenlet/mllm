dec_rank:
  d_model: 768
  mlp_layers: ''
enc_bert:
  d_model: 768
  emb_type: cls
  inp_len: 128
  pad_token_id: 0
  pretrained_model_name: bert-base-uncased
  tokenizer_name: bert-base-uncased
