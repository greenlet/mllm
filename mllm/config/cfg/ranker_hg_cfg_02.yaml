dec_rank:
  d_model: 512
  with_bias: false
  mlp_layers: []
enc_pyr:
  d_inner: 2048
  d_k: 64
  d_model: 512
  d_v: 64
  dropout_rate: 0.0
  inp_len: 256
  n_heads: 8
  n_layers: 8
  n_similar_layers: 1
  pad_idx: 50267
  reduct_type: matmul
  step: 2
  vocab_encoder:
    d_model: 512
    d_word_vec: 512
    dropout_rate: 0.0
    inp_len: 256
    n_vocab: 50271
    pad_idx: 50267
    pos_enc_type: emb
