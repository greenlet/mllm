dec_pyr:
  d_inner: 3072
  d_k: 64
  d_model: 768
  d_v: 64
  dropout_rate: 0.0
  enhance_type: matmul
  inp_len: 128
  n_heads: 12
  n_layers: 7
  n_similar_layers: 1
  n_vocab: 30522
  step: 2
  temperature: 0.0
emb_attn:
  d_inner: 3072
  d_k: 64
  d_model: 768
  d_v: 64
  dropout_rate: 0.0
  n_heads: 12
  n_layers: 1
emb_graph:
  d_model: 768
  gnn_conv:
    cls_name: GCNConv
    params:
      add_self_loops: null
      bias: true
      cached: false
      improved: false
      normalize: true
  hidden_dim: 768
  n_layers: 2
enc_bert:
  d_model: 768
  emb2_tok_name: ''
  emb_type: cls
  inp_len: 128
  pad_token_id: 0
  pretrained_model_name: bert-base-uncased
  tokenizer_name: bert-base-uncased
middle_type: graph
share_enc_dec_proj_weights: false
