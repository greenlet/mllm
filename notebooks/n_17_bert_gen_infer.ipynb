{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import requests\n",
    "import sys\n",
    "from typing import Optional\n",
    "\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertGenerationEncoder, BertGenerationDecoder, EncoderDecoderModel, BertTokenizer, AutoTokenizer\n",
    "from transformers.modeling_outputs import Seq2SeqLMOutput, BaseModelOutputWithPastAndCrossAttentions, CausalLMOutputWithCrossAttentions\n",
    "\n",
    "from mllm.model.embgen_bert import EncoderEmbDecoderModel, EncEmbExpansionType\n",
    "from mllm.data.qna import get_hotpotqa\n",
    "from mllm.train.embgen_bert import get_sq_batch, get_sq_df, QuesInp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Generator model inference\n",
    "## Configs and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(os.path.expandvars('$HOME')) / 'data'\n",
    "\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "random_seed = 111\n",
    "inp_len = 128\n",
    "train_eed_bert_path = DATA_PATH / 'train_mllm_eed_bert_qna'\n",
    "eed_subdir = 'eedbert-20250316_195907-bert_base_uncased-d768-emp_f-qi_enc'\n",
    "eed_subdir = 'eedbert-20250317_100519-bert_base_uncased-d768-emp_f-qi_enc-chkpt_encdecbert_20250131_223521'\n",
    "eed_subdir = 'eedbert-20250317_223145-bert_base_uncased-d768-emp_f-qi_dec'\n",
    "eed_subdir = 'eedbert-20250319_221739-bert_base_uncased-d768-emp_f-qi_dec-chkpt_encdecbert_20250131_223521'\n",
    "# eed_subdir = 'eedbert-20250323_180203-bert_base_uncased-d768-emp_f-qi_enc-exp_mat_b-bt_6-chkpt_encdecbert_20250131_223521'\n",
    "\n",
    "eed_train_path = train_eed_bert_path / eed_subdir\n",
    "eed_snapshot_fpath = eed_train_path / 'best.pth'\n",
    "\n",
    "device_name = 'cpu'\n",
    "# device_name = 'cuda'\n",
    "\n",
    "device = torch.device(device_name)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EedParams(ques_inp=<QuesInp.Dec: 'dec'>, exp_type=<EncEmbExpansionType.Emb: 'emb'>, exp_bias=False, batch_size=0, enc_batch_size=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dataclass\n",
    "class EedParams:\n",
    "    ques_inp: QuesInp\n",
    "    exp_type: EncEmbExpansionType\n",
    "    exp_bias: bool\n",
    "    batch_size: int\n",
    "    enc_batch_size: int\n",
    "\n",
    "def get_params(subdir: str) -> EedParams:\n",
    "    ques_inp, exp_type, exp_bias, enc_batch_size = None, EncEmbExpansionType.Emb, False, 0\n",
    "    parts = subdir.split('-')\n",
    "    for part in parts:\n",
    "        if part.startswith('qi_'):\n",
    "            ques_inp = QuesInp(part[3:])\n",
    "        elif part.startswith('exp_'):\n",
    "            subparts = part.split('_')\n",
    "            exp_type = EncEmbExpansionType(subparts[1])\n",
    "            if len(subparts) == 3:\n",
    "                assert subparts[-1] == 'b', f'\"{part}\" is expected to end with \\'b\\' when have '\n",
    "                exp_bias = True\n",
    "        elif part.startswith('bt_'):\n",
    "            enc_batch_size = int(part[3:])\n",
    "    assert ques_inp is not None, f'Cannot find part `qi_QUESINP` where QUESINP is one of: {[qi.value for qi in QuesInp]}'\n",
    "    \n",
    "    batch_size = enc_batch_size if ques_inp == QuesInp.Dec else enc_batch_size - 1\n",
    "    return EedParams(\n",
    "        ques_inp=ques_inp, exp_type=exp_type, exp_bias=exp_bias, batch_size=batch_size, enc_batch_size=enc_batch_size,\n",
    "    )\n",
    "\n",
    "eed_params = get_params(eed_subdir)\n",
    "eed_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models and dataset\n",
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type bert-generation. This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type bert to instantiate a model of type bert-generation. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of BertGenerationDecoder were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'lm_head.bias', 'lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tkz = BertTokenizer.from_pretrained(bert_model_name)\n",
    "print(tkz)\n",
    "enc_model: BertGenerationEncoder = BertGenerationEncoder.from_pretrained(bert_model_name, bos_token_id=101, eos_token_id=102)\n",
    "# add cross attention layers and use BERT's cls token as BOS token and sep token as EOS token\n",
    "dec_model: BertGenerationDecoder = BertGenerationDecoder.from_pretrained(\n",
    "    bert_model_name, add_cross_attention=True, is_decoder=True, bos_token_id=101, eos_token_id=102\n",
    ")\n",
    "model = EncoderEmbDecoderModel(\n",
    "    encoder=enc_model, decoder=dec_model, enc_emb_exp_type=eed_params.exp_type, enc_emb_exp_bias=eed_params.exp_bias,\n",
    "    enc_inp_len=inp_len, enc_inp_batch_size=eed_params.enc_batch_size,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-base-uncased'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertGenerationConfig\n",
    "cfg: BertGenerationConfig = enc_model.config\n",
    "cfg.name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load /home/misha/data/train_mllm_eed_bert_qna/eedbert-20250319_221739-bert_base_uncased-d768-emp_f-qi_dec-chkpt_encdecbert_20250131_223521/best.pth\n"
     ]
    }
   ],
   "source": [
    "print(f'Load {eed_snapshot_fpath}')\n",
    "checkpoint = torch.load(eed_snapshot_fpath, map_location=device)\n",
    "model.load_state_dict(checkpoint['model'], strict=True)\n",
    "model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squad v2 Qna dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad_v2 (/home/misha/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d3fc8286be4c8da1f3ae418cc62a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove empty answers from dataset squad_v2. Size: 142192 --> 92749\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(random_seed)\n",
    "# exclude_empty_answers = False\n",
    "exclude_empty_answers = True\n",
    "df_sq = get_sq_df(exclude_empty_answers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contexts: [1 1 1 1 1]. (5, 128)\n",
      "QAs: [24 20 19 33 18]. 114. 2750\n",
      "Qs: [16 15 15 27 14]. 87. 1631\n",
      "As: [7 4 3 5 3]. 22. 108\n",
      "Context1. Traditionally a carnival feast was the last opportunity to eat well before the time of food shortage at the end of the winter during which one was limited to the minimum necessary. On what nowadays is called vastenavond (the days before fasting) all the remaining winter stores of lard, butter and meat which were left would be eaten, for it would soon start to rot and decay. The selected \n",
      "Context2. DNA replication is for the most part extremely accurate, however errors (mutations) do occur.:7.6 The error rate in eukaryotic cells can be as low as 10−8 per nucleotide per replication, whereas for some RNA viruses it can be as high as 10−3. This means that each generation, each human genome accumulates 1–2 new mutations. Small mutations can be caused by DNA replication and the aftermat\n",
      "Context3. Like other American research universities, Northwestern was transformed by World War II. Franklyn B. Snyder led the university from 1939 to 1949, when nearly 50,000 military officers and personnel were trained on the Evanston and Chicago campuses. After the war, surging enrollments under the G.I. Bill drove drastic expansion of both campuses. In 1948 prominent anthropologist Melville J. \n",
      "Context4. There were two main techniques in Greco-Roman mosaic: opus vermiculatum used tiny tesserae, typically cubes of 4 millimeters or less, and was produced in workshops in relatively small panels which were transported to the site glued to some temporary support. The tiny tesserae allowed very fine detail, and an approach to the illusionism of painting. Often small panels called emblemata wer\n",
      "Context5. As a side effect of the electrochemical processes used by neurons for signaling, brain tissue generates electric fields when it is active. When large numbers of neurons show synchronized activity, the electric fields that they generate can be large enough to detect outside the skull, using electroencephalography (EEG) or magnetoencephalography (MEG). EEG recordings, along with recordings\n"
     ]
    }
   ],
   "source": [
    "batch_size = eed_params.batch_size or 5\n",
    "inds = np.arange(batch_size)\n",
    "inds += batch_size * 1\n",
    "batch = get_sq_batch(tkz=tkz, df_sq=df_sq, inds=inds, inp_len=inp_len, device=device, ques_inp=eed_params.ques_inp)\n",
    "for ctx in batch.contexts:\n",
    "    print(ctx[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Context5. Question: MEG of the brain is an abbreviation of what?. A: magnetoencephalography\n",
      "Q: Context1. Question: What was one limited to during the winter?. A: the minimum necessary\n",
      "Q: Context4. Question: What were small panel mosaics known as?. A: emblemata\n",
      "Q: Context3. Question: Between 1939 and 1949, how many military officers and personnel were trained on the Evanston and Chicago campuses?. A: nearly 50,000\n",
      "Q: Context2. Question: What can small mutations be caused by?. A: DNA replication\n"
     ]
    }
   ],
   "source": [
    "for q, a in batch.qas:\n",
    "    print(f'Q: {q}. A: {a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctxs_toks, other_toks = batch.gen_tensors()\n",
    "ctxs_mask = (ctxs_toks > 0).to(batch.device)\n",
    "ctx_enc_out: BaseModelOutputWithPastAndCrossAttentions = model.encoder(input_ids=ctxs_toks, attention_mask=ctxs_mask)\n",
    "ctx_emb = ctx_enc_out.last_hidden_state[:, 0].unsqueeze(0)\n",
    "ctx_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_ind = 3\n",
    "\n",
    "if batch.ques_inp == QuesInp.Enc:\n",
    "    q_toks_l, a_toks_l, a_att_masks_l, a_tgt_masks_l = other_toks\n",
    "    n_ans = len(a_toks_l)\n",
    "    q_toks, a_toks, a_att_mask, a_tgt_mask = q_toks_l[qa_ind], a_toks_l[qa_ind], a_att_masks_l[qa_ind], a_tgt_masks_l[qa_ind]\n",
    "    q_toks = q_toks.unsqueeze(0)\n",
    "    q_mask = (q_toks > 0).to(batch.device)\n",
    "    q_enc_out: BaseModelOutputWithPastAndCrossAttentions = model.encoder(input_ids=q_toks, attention_mask=q_mask)\n",
    "    q_emb = q_enc_out.last_hidden_state[:, 0].unsqueeze(0)\n",
    "    ctxq_emb = torch.concatenate([ctx_emb, q_emb], dim=1)\n",
    "    print(f'ctx_emb: {ctx_emb.shape}. q_emb: {q_emb.shape}. ctxq_emb: {ctxq_emb.shape}')\n",
    "    # a_toks = a_toks.repeat(len(a_att_mask), 1)\n",
    "    # # a_toks_inp = a_toks * a_att_mask\n",
    "    # a_toks_inp = a_toks\n",
    "    # a_dec_out: CausalLMOutputWithCrossAttentions = model.decoder(\n",
    "    #     input_ids=a_toks_inp, attention_mask=a_att_mask, encoder_hidden_states=ctxq_emb,\n",
    "    # )\n",
    "\n",
    "elif batch.ques_inp == QuesInp.Dec:\n",
    "    qa_toks_l, qa_att_masks_l, qa_tgt_masks_l = other_toks\n",
    "    n_qas = len(qa_toks_l)\n",
    "    qa_toks, qa_att_mask, qa_tgt_mask = qa_toks_l[qa_ind].unsqueeze(0), qa_att_masks_l[qa_ind], qa_tgt_masks_l[qa_ind]\n",
    "    # qa_toks = qa_toks.repeat(len(qa_att_mask), 1)\n",
    "    # qa_toks_inp = qa_toks * qa_att_mask\n",
    "    # dec_out: CausalLMOutputWithCrossAttentions = model.decoder(\n",
    "    #     input_ids=qa_toks_inp, attention_mask=qa_att_mask, encoder_hidden_states=ctx_emb\n",
    "    # )\n",
    "    # n = 0\n",
    "    # for i in range(qa_toks.shape[1]):\n",
    "    #     if qa_att_mask[0, i] == 0:\n",
    "    #         n = i\n",
    "    #         break\n",
    "    # q_toks = qa_toks[0, :n + 1].clone()\n",
    "    # q_toks[-1] = 0\n",
    "\n",
    "else:\n",
    "    raise Exception(f'Unsupported Question input type: {ques_inp}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context3. Question: Between 1939 and 1949, how many military officers and personnel were trained on the Evanston and Chicago campuses? - nearly 50,000\n",
      "[101, 6123, 2509, 1012, 3160, 1024, 2090, 3912, 1998, 4085, 1010, 2129, 2116, 2510, 3738, 1998, 5073, 2020, 4738, 2006, 1996, 6473, 2669, 1998, 3190, 13696, 1029, 102, 3053, 2753, 1010, 2199, 102]\n",
      "tensor([  101,  6123,  2509,  1012,  3160,  1024,  2090,  3912,  1998,  4085,\n",
      "         1010,  2129,  2116,  2510,  3738,  1998,  5073,  2020,  4738,  2006,\n",
      "         1996,  6473,  2669,  1998,  3190, 13696,  1029,   102,   103])\n",
      "[CLS] context3. question : between 1939 and 1949, how many military officers and personnel were trained on the evanston and chicago campuses? [SEP] 30, 000\n"
     ]
    }
   ],
   "source": [
    "def predict(model: EncoderEmbDecoderModel, enc_emb: torch.Tensor, toks: torch.Tensor, max_len: int = 10) -> list[int]:\n",
    "    i, toks_cur, toks_out = 0, toks.tolist(), []\n",
    "    inp_ids = toks.unsqueeze(0)\n",
    "    while i < max_len:\n",
    "        # att_mask = (inp_ids > 0).to(torch.int32)\n",
    "        att_mask = torch.ones_like(inp_ids)\n",
    "        dec_out: CausalLMOutputWithCrossAttentions = model.decoder(\n",
    "            input_ids=inp_ids, attention_mask=att_mask, encoder_hidden_states=enc_emb, use_cache=False,\n",
    "        )\n",
    "        # print(dec_out.logits.shape)\n",
    "        probs_pred = torch.softmax(dec_out.logits[0, -1], dim=-1)\n",
    "        # print(probs_pred.shape)\n",
    "        tok_out = torch.argmax(probs_pred, dim=-1)\n",
    "        # print(tok_out.item())\n",
    "        tok = tok_out.item()\n",
    "        if tok == 102:\n",
    "            break\n",
    "        toks_cur[-1] = tok\n",
    "        toks_cur.append(tkz.mask_token_id)\n",
    "        inp_ids = torch.tensor(toks_cur, dtype=toks.dtype, device=toks.device).unsqueeze(0)\n",
    "        i += 1\n",
    "    return toks_cur if toks_cur[-1] != tkz.mask_token_id else toks_cur[:-1]\n",
    "\n",
    "q, a = batch.qas[qa_ind]\n",
    "print(f'{q} - {a}')\n",
    "if eed_params.ques_inp == QuesInp.Enc:\n",
    "    q_toks = [tkz.mask_token_id]\n",
    "    q_toks = torch.tensor(q_toks, dtype=torch.int64, device=device)\n",
    "    toks_out = predict(model, ctxq_emb, q_toks, max_len=20)\n",
    "else:\n",
    "    q_toks = qa_toks.squeeze().tolist()\n",
    "    print(q_toks)\n",
    "    for i, q_tok in enumerate(q_toks):\n",
    "        # print(i, q_tok, q_tok == tkz.sep_token_id)\n",
    "        if q_tok == tkz.sep_token_id:\n",
    "            q_toks = q_toks[:i + 2]\n",
    "            q_toks[i + 1] = tkz.mask_token_id\n",
    "            break\n",
    "    q_toks = torch.tensor(q_toks, dtype=torch.int64, device=device)\n",
    "    print(q_toks)\n",
    "    toks_out = predict(model, ctx_emb, q_toks, max_len=20)\n",
    "print(tkz.decode(toks_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False, False],\n",
       "       [ True,  True, False, False],\n",
       "       [ True,  True,  True, False],\n",
       "       [ True,  True,  True,  True]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 4\n",
    "t = np.tril(np.ones((n, n), dtype=bool), k=0)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 90,  9, 20])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randint(100, size=n)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28, 90,  9, 20],\n",
       "       [28, 90,  9, 20],\n",
       "       [28, 90,  9, 20],\n",
       "       [28, 90,  9, 20]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.repeat(a[None], n, axis=0)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[123,   0,   0,   0],\n",
       "       [ 28, 123,   0,   0],\n",
       "       [ 28,  90, 123,   0],\n",
       "       [ 28,  90,   9, 123]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_id = 123\n",
    "mask = np.eye(n, dtype=bool)\n",
    "bb = np.tril(b, k=-1)\n",
    "bb[mask] = mask_token_id\n",
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([28, 90,  9, 20])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at = torch.tensor(a)\n",
    "at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[28,  0,  0,  0],\n",
       "        [28, 90,  0,  0],\n",
       "        [28, 90,  9,  0],\n",
       "        [28, 90,  9, 20]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atn = at.repeat(n, 1)\n",
    "atn = torch.tril(atn)\n",
    "atn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False, False],\n",
       "        [False,  True, False, False],\n",
       "        [False, False,  True, False],\n",
       "        [False, False, False,  True]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskt = torch.tensor(mask)\n",
    "maskt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[103,   0,   0,   0],\n",
       "        [ 28, 103,   0,   0],\n",
       "        [ 28,  90, 103,   0],\n",
       "        [ 28,  90,   9, 103]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atn[maskt] = tkz.mask_token_id\n",
    "atn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
