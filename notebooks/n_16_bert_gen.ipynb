{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import requests\n",
    "import sys\n",
    "from typing import Optional\n",
    "\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertGenerationEncoder, BertGenerationDecoder, EncoderDecoderModel, BertTokenizer, AutoTokenizer\n",
    "from transformers.modeling_outputs import Seq2SeqLMOutput, BaseModelOutputWithPastAndCrossAttentions, CausalLMOutputWithCrossAttentions\n",
    "\n",
    "from mllm.model.embgen_bert import EncEmbExpansionType, EncoderEmbDecoderModel\n",
    "from mllm.data.qna import get_hotpotqa\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Generator model\n",
    "## Preload Encoder, Decoder and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type bert-generation. This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type bert to instantiate a model of type bert-generation. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of BertGenerationDecoder were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'lm_head.bias', 'lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'google-bert/bert-base-uncased'\n",
    "\n",
    "# leverage checkpoints for Bert2Bert model...\n",
    "# use BERT's cls token as BOS token and sep token as EOS token\n",
    "encoder: BertGenerationEncoder = BertGenerationEncoder.from_pretrained(model_name, bos_token_id=101, eos_token_id=102)\n",
    "# add cross attention layers and use BERT's cls token as BOS token and sep token as EOS token\n",
    "decoder: BertGenerationDecoder = BertGenerationDecoder.from_pretrained(\n",
    "    model_name, add_cross_attention=True, is_decoder=True, bos_token_id=101, eos_token_id=102\n",
    ")\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EncoderDecoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misha/miniconda3/envs/mllm/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2023, 2003, 1037, 2146, 3720, 2000, 7680, 7849, 4697]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert2bert = EncoderDecoderModel(encoder=encoder, decoder=decoder)\n",
    "\n",
    "# create tokenizer...\n",
    "\n",
    "input_ids = tokenizer(\n",
    "    'This is a long article to summarize', add_special_tokens=False, return_tensors='pt'\n",
    ").input_ids\n",
    "labels = tokenizer('This is a short summary', return_tensors='pt').input_ids\n",
    "\n",
    "# train...\n",
    "loss = bert2bert(input_ids=input_ids, decoder_input_ids=labels, labels=labels).loss\n",
    "loss.backward()\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misha/miniconda3/envs/mllm/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:642: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 9]), torch.Size([1, 7]), torch.Size([1, 7, 30522]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert2bert.eval()\n",
    "pred: Seq2SeqLMOutput = bert2bert(input_ids=input_ids, decoder_input_ids=labels, labels=labels)\n",
    "input_ids.shape, labels.shape, pred.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misha/miniconda3/envs/mllm/lib/python3.10/site-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 19782, 24756, 24756, 24756, 24756, 24756, 24756, 24756, 24756,\n",
       "         24756,   101, 26036,   101, 10431,   101, 10431,   101, 10431,   101],\n",
       "        [  101, 10431, 10431, 10431, 10431, 10431, 10431, 10431, 10431, 10431,\n",
       "         10431, 10431, 10431, 10431, 10431, 10431, 10431, 10431, 10431, 10431]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_toks = bert2bert.generate(input_ids)\n",
    "gen_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] hui hui hui hui hui hui hui hui hui hui hui hui hui hui hui hui hui hui [CLS]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(gen_toks.squeeze().detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Bert Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='google-bert/bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2129,  2116,  2616,  2024,  2734,  2000,  6235,  2019,  4153,\n",
       "          1029,  2292,  1005,  1055,  3046,  2000,  2562,  2009,  2460,   999,\n",
       "           102],\n",
       "        [  101,  5925, 13366,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = ['How many words are needed to describe an ocean? Let\\'s try to keep it short!', 'abc def']\n",
    "toks1 = tokenizer(s1, return_tensors='pt', padding=True)\n",
    "toks1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  4153,  2784,  1998,  2630,  1012,  2009,  1005,  1055, 10866,\n",
       "          1998, 11951,  1012,  2025,  2172,  2616,  1010,  1045,  1005,  1040,\n",
       "          2360,  1012,   102],\n",
       "        [  101,  2320,  2588,  1037,  2051,   999,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = ['Ocean deep and blue. It\\'s endless and charming. Not much words, I\\'d say.', 'Once upon a time!']\n",
    "toks2 = tokenizer(s2, return_tensors='pt', padding=True)\n",
    "toks2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPastAndCrossAttentions(last_hidden_state=tensor([[[-0.0525,  0.2416, -0.2183,  ..., -0.2659,  0.5905,  0.8504],\n",
       "         [ 0.5397,  0.1460, -0.4024,  ...,  0.3013,  0.5229,  0.2699],\n",
       "         [ 0.6455, -0.1244,  0.4163,  ..., -0.1054,  0.5575,  0.1057],\n",
       "         ...,\n",
       "         [ 0.7216, -0.1501, -0.1798,  ..., -0.1326,  0.2695, -0.0244],\n",
       "         [ 0.1543,  0.5561,  0.2382,  ...,  0.4147,  0.2552,  0.2053],\n",
       "         [ 0.8313,  0.1728, -0.4358,  ...,  0.1262, -0.4243, -0.3342]],\n",
       "\n",
       "        [[-0.4835, -0.0392,  0.1173,  ..., -0.0122,  0.6183, -0.0138],\n",
       "         [ 0.3884, -0.1305,  0.2819,  ...,  0.0032,  0.9948,  0.0298],\n",
       "         [-0.0101, -0.4335,  0.4002,  ...,  0.3235,  0.4988, -0.4418],\n",
       "         ...,\n",
       "         [ 0.2725, -0.3133,  1.0570,  ..., -0.2669,  0.2520, -0.2070],\n",
       "         [ 0.3274, -0.3323,  0.9303,  ..., -0.2656,  0.2818, -0.1892],\n",
       "         [ 0.4019, -0.1761,  0.9125,  ..., -0.3159,  0.2786, -0.3931]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_out: BaseModelOutputWithPastAndCrossAttentions = encoder(toks1.input_ids)\n",
    "enc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 21]), torch.Size([2, 21, 768]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks1.input_ids.shape, enc_out.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertGenerationConfig {\n",
       "  \"_name_or_path\": \"google-bert/bert-base-uncased\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 101,\n",
       "  \"eos_token_id\": 102,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert-generation\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.42.4\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "encoder.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(enc_out[0], enc_out.last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_out: CausalLMOutputWithCrossAttentions = decoder(input_ids=toks2.input_ids, encoder_hidden_states=enc_out.last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 23]), torch.Size([2, 23, 30522]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks2.input_ids.shape, dec_out.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert2bert.config.tie_encoder_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoderConfig {\n",
       "  \"decoder\": {\n",
       "    \"_name_or_path\": \"google-bert/bert-base-uncased\",\n",
       "    \"add_cross_attention\": true,\n",
       "    \"architectures\": [\n",
       "      \"BertForMaskedLM\"\n",
       "    ],\n",
       "    \"attention_probs_dropout_prob\": 0.1,\n",
       "    \"bad_words_ids\": null,\n",
       "    \"begin_suppress_tokens\": null,\n",
       "    \"bos_token_id\": 101,\n",
       "    \"chunk_size_feed_forward\": 0,\n",
       "    \"cross_attention_hidden_size\": null,\n",
       "    \"decoder_start_token_id\": null,\n",
       "    \"diversity_penalty\": 0.0,\n",
       "    \"do_sample\": false,\n",
       "    \"early_stopping\": false,\n",
       "    \"encoder_no_repeat_ngram_size\": 0,\n",
       "    \"eos_token_id\": 102,\n",
       "    \"exponential_decay_length_penalty\": null,\n",
       "    \"finetuning_task\": null,\n",
       "    \"forced_bos_token_id\": null,\n",
       "    \"forced_eos_token_id\": null,\n",
       "    \"gradient_checkpointing\": false,\n",
       "    \"hidden_act\": \"gelu\",\n",
       "    \"hidden_dropout_prob\": 0.1,\n",
       "    \"hidden_size\": 768,\n",
       "    \"id2label\": {\n",
       "      \"0\": \"LABEL_0\",\n",
       "      \"1\": \"LABEL_1\"\n",
       "    },\n",
       "    \"initializer_range\": 0.02,\n",
       "    \"intermediate_size\": 3072,\n",
       "    \"is_decoder\": true,\n",
       "    \"is_encoder_decoder\": false,\n",
       "    \"label2id\": {\n",
       "      \"LABEL_0\": 0,\n",
       "      \"LABEL_1\": 1\n",
       "    },\n",
       "    \"layer_norm_eps\": 1e-12,\n",
       "    \"length_penalty\": 1.0,\n",
       "    \"max_length\": 20,\n",
       "    \"max_position_embeddings\": 512,\n",
       "    \"min_length\": 0,\n",
       "    \"model_type\": \"bert-generation\",\n",
       "    \"no_repeat_ngram_size\": 0,\n",
       "    \"num_attention_heads\": 12,\n",
       "    \"num_beam_groups\": 1,\n",
       "    \"num_beams\": 1,\n",
       "    \"num_hidden_layers\": 12,\n",
       "    \"num_return_sequences\": 1,\n",
       "    \"output_attentions\": false,\n",
       "    \"output_hidden_states\": false,\n",
       "    \"output_scores\": false,\n",
       "    \"pad_token_id\": 0,\n",
       "    \"position_embedding_type\": \"absolute\",\n",
       "    \"prefix\": null,\n",
       "    \"problem_type\": null,\n",
       "    \"pruned_heads\": {},\n",
       "    \"remove_invalid_values\": false,\n",
       "    \"repetition_penalty\": 1.0,\n",
       "    \"return_dict\": true,\n",
       "    \"return_dict_in_generate\": false,\n",
       "    \"sep_token_id\": null,\n",
       "    \"suppress_tokens\": null,\n",
       "    \"task_specific_params\": null,\n",
       "    \"temperature\": 1.0,\n",
       "    \"tf_legacy_loss\": false,\n",
       "    \"tie_encoder_decoder\": false,\n",
       "    \"tie_word_embeddings\": true,\n",
       "    \"tokenizer_class\": null,\n",
       "    \"top_k\": 50,\n",
       "    \"top_p\": 1.0,\n",
       "    \"torch_dtype\": null,\n",
       "    \"torchscript\": false,\n",
       "    \"type_vocab_size\": 2,\n",
       "    \"typical_p\": 1.0,\n",
       "    \"use_bfloat16\": false,\n",
       "    \"use_cache\": true,\n",
       "    \"vocab_size\": 30522\n",
       "  },\n",
       "  \"encoder\": {\n",
       "    \"_name_or_path\": \"google-bert/bert-base-uncased\",\n",
       "    \"add_cross_attention\": false,\n",
       "    \"architectures\": [\n",
       "      \"BertForMaskedLM\"\n",
       "    ],\n",
       "    \"attention_probs_dropout_prob\": 0.1,\n",
       "    \"bad_words_ids\": null,\n",
       "    \"begin_suppress_tokens\": null,\n",
       "    \"bos_token_id\": 101,\n",
       "    \"chunk_size_feed_forward\": 0,\n",
       "    \"cross_attention_hidden_size\": null,\n",
       "    \"decoder_start_token_id\": null,\n",
       "    \"diversity_penalty\": 0.0,\n",
       "    \"do_sample\": false,\n",
       "    \"early_stopping\": false,\n",
       "    \"encoder_no_repeat_ngram_size\": 0,\n",
       "    \"eos_token_id\": 102,\n",
       "    \"exponential_decay_length_penalty\": null,\n",
       "    \"finetuning_task\": null,\n",
       "    \"forced_bos_token_id\": null,\n",
       "    \"forced_eos_token_id\": null,\n",
       "    \"gradient_checkpointing\": false,\n",
       "    \"hidden_act\": \"gelu\",\n",
       "    \"hidden_dropout_prob\": 0.1,\n",
       "    \"hidden_size\": 768,\n",
       "    \"id2label\": {\n",
       "      \"0\": \"LABEL_0\",\n",
       "      \"1\": \"LABEL_1\"\n",
       "    },\n",
       "    \"initializer_range\": 0.02,\n",
       "    \"intermediate_size\": 3072,\n",
       "    \"is_decoder\": false,\n",
       "    \"is_encoder_decoder\": false,\n",
       "    \"label2id\": {\n",
       "      \"LABEL_0\": 0,\n",
       "      \"LABEL_1\": 1\n",
       "    },\n",
       "    \"layer_norm_eps\": 1e-12,\n",
       "    \"length_penalty\": 1.0,\n",
       "    \"max_length\": 20,\n",
       "    \"max_position_embeddings\": 512,\n",
       "    \"min_length\": 0,\n",
       "    \"model_type\": \"bert-generation\",\n",
       "    \"no_repeat_ngram_size\": 0,\n",
       "    \"num_attention_heads\": 12,\n",
       "    \"num_beam_groups\": 1,\n",
       "    \"num_beams\": 1,\n",
       "    \"num_hidden_layers\": 12,\n",
       "    \"num_return_sequences\": 1,\n",
       "    \"output_attentions\": false,\n",
       "    \"output_hidden_states\": false,\n",
       "    \"output_scores\": false,\n",
       "    \"pad_token_id\": 0,\n",
       "    \"position_embedding_type\": \"absolute\",\n",
       "    \"prefix\": null,\n",
       "    \"problem_type\": null,\n",
       "    \"pruned_heads\": {},\n",
       "    \"remove_invalid_values\": false,\n",
       "    \"repetition_penalty\": 1.0,\n",
       "    \"return_dict\": true,\n",
       "    \"return_dict_in_generate\": false,\n",
       "    \"sep_token_id\": null,\n",
       "    \"suppress_tokens\": null,\n",
       "    \"task_specific_params\": null,\n",
       "    \"temperature\": 1.0,\n",
       "    \"tf_legacy_loss\": false,\n",
       "    \"tie_encoder_decoder\": false,\n",
       "    \"tie_word_embeddings\": true,\n",
       "    \"tokenizer_class\": null,\n",
       "    \"top_k\": 50,\n",
       "    \"top_p\": 1.0,\n",
       "    \"torch_dtype\": null,\n",
       "    \"torchscript\": false,\n",
       "    \"type_vocab_size\": 2,\n",
       "    \"typical_p\": 1.0,\n",
       "    \"use_bfloat16\": false,\n",
       "    \"use_cache\": true,\n",
       "    \"vocab_size\": 30522\n",
       "  },\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"model_type\": \"encoder-decoder\",\n",
       "  \"transformers_version\": \"4.42.4\"\n",
       "}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert2bert.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=30522, bias=True)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.get_output_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=30522, bias=True)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.lm_head.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertGenerationEmbeddings(\n",
       "  (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "  (position_embeddings): Embedding(512, 768)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768, padding_idx=0)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.embeddings.word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.config.tie_word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.bert_generation.modeling_bert_generation import BertGenerationEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=30522, bias=True)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.get_output_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768, padding_idx=0)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(decoder.get_input_embeddings().weight, decoder.get_output_embeddings().weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(encoder.get_input_embeddings().weight, decoder.get_output_embeddings().weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(decoder.get_input_embeddings().weight) == id(decoder.get_output_embeddings().weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(encoder.get_input_embeddings().weight) == id(decoder.get_output_embeddings().weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(bert2bert.get_input_embeddings().weight) == id(bert2bert.get_output_embeddings().weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom override of EncoderDecoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type bert-generation. This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type bert to instantiate a model of type bert-generation. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of BertGenerationDecoder were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'lm_head.bias', 'lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "enc_model: BertGenerationEncoder = BertGenerationEncoder.from_pretrained(model_name, bos_token_id=101, eos_token_id=102)\n",
    "# add cross attention layers and use BERT's cls token as BOS token and sep token as EOS token\n",
    "dec_model: BertGenerationDecoder = BertGenerationDecoder.from_pretrained(\n",
    "    model_name, add_cross_attention=True, is_decoder=True, bos_token_id=101, eos_token_id=102\n",
    ")\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "eed_model = EncoderEmbDecoderModel(encoder=enc_model, decoder=dec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2129,  2116,  2616,  2024,  2734,  2000,  6235,  2019,  4153,\n",
       "          1029,  2292,  1005,  1055,  3046,  2000,  2562,  2009,  2460,   999,\n",
       "           102],\n",
       "        [  101,  5925, 13366,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = ['How many words are needed to describe an ocean? Let\\'s try to keep it short!', 'abc def']\n",
    "toks1 = tokenizer(s1, return_tensors='pt', padding=True)\n",
    "toks1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 4153, 2784, 1998, 2630,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = 'Ocean deep and blue'\n",
    "toks2 = tokenizer(s2, return_tensors='pt', padding=True)\n",
    "toks2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 21]) torch.Size([1, 6]) torch.Size([1, 6, 30522])\n"
     ]
    }
   ],
   "source": [
    "eed_out: Seq2SeqLMOutput = eed_model(input_ids=toks1.input_ids, decoder_input_ids=toks2.input_ids, labels=toks2.input_ids)\n",
    "print(toks1.input_ids.shape, toks2.input_ids.shape, eed_out.logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "### HPQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load /home/misha/data/hotpotqa/hotpot_train_v1.1.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>level</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>_id</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[Arthur's Magazine, 0], [First for Women, 0]]</td>\n",
       "      <td>medium</td>\n",
       "      <td>Which magazine was started first Arthur's Maga...</td>\n",
       "      <td>[[Radio City (Indian radio station), [Radio Ci...</td>\n",
       "      <td>Arthur's Magazine</td>\n",
       "      <td>5a7a06935542990198eaf050</td>\n",
       "      <td>comparison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[Oberoi family, 0], [The Oberoi Group, 0]]</td>\n",
       "      <td>medium</td>\n",
       "      <td>The Oberoi family is part of a hotel company t...</td>\n",
       "      <td>[[Ritz-Carlton Jakarta, [The Ritz-Carlton Jaka...</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>5a879ab05542996e4f30887e</td>\n",
       "      <td>bridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[Allie Goertz, 0], [Allie Goertz, 1], [Allie ...</td>\n",
       "      <td>hard</td>\n",
       "      <td>Musician and satirist Allie Goertz wrote a son...</td>\n",
       "      <td>[[Lisa Simpson, [Lisa Marie Simpson is a ficti...</td>\n",
       "      <td>President Richard Nixon</td>\n",
       "      <td>5a8d7341554299441c6b9fe5</td>\n",
       "      <td>bridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[Peggy Seeger, 0], [Peggy Seeger, 1], [Ewan M...</td>\n",
       "      <td>medium</td>\n",
       "      <td>What nationality was James Henry Miller's wife?</td>\n",
       "      <td>[[Moloch: or, This Gentile World, [Moloch: or,...</td>\n",
       "      <td>American</td>\n",
       "      <td>5a82171f5542990a1d231f4a</td>\n",
       "      <td>bridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[Cadmium chloride, 1], [Ethanol, 0]]</td>\n",
       "      <td>medium</td>\n",
       "      <td>Cadmium Chloride is slightly soluble in this c...</td>\n",
       "      <td>[[Cadmium chloride, [Cadmium chloride is a whi...</td>\n",
       "      <td>alcohol</td>\n",
       "      <td>5a84dd955542997b5ce3ff79</td>\n",
       "      <td>bridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90442</th>\n",
       "      <td>[[Kerry Remsen, 1], [Bert Remsen, 0]]</td>\n",
       "      <td>medium</td>\n",
       "      <td>Kerry Remsen is the daughter of an actor with ...</td>\n",
       "      <td>[[Kerry Remsen, [Kerry Remsen is an American a...</td>\n",
       "      <td>American</td>\n",
       "      <td>5a8f8db25542997ba9cb32b9</td>\n",
       "      <td>bridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90443</th>\n",
       "      <td>[[Northshore Mall, 0], [Northshore Mall, 4], [...</td>\n",
       "      <td>easy</td>\n",
       "      <td>Who manages both Northshore Mall in Peabody, M...</td>\n",
       "      <td>[[Green Tree Mall, [Green Tree Mall is a shopp...</td>\n",
       "      <td>Simon Property Group</td>\n",
       "      <td>5ae4f3615542993aec5ec0fd</td>\n",
       "      <td>bridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90444</th>\n",
       "      <td>[[Charlee Johnson, 4], [DreamWorks, 0]]</td>\n",
       "      <td>medium</td>\n",
       "      <td>Charlee Johnson was part of a band that signed...</td>\n",
       "      <td>[[Simon M. Woods, [Simon M. Woods is a British...</td>\n",
       "      <td>Amblin Partners</td>\n",
       "      <td>5a903fc95542990a984935bd</td>\n",
       "      <td>bridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90445</th>\n",
       "      <td>[[Salt to the Sea, 1], [MV Wilhelm Gustloff, 0]]</td>\n",
       "      <td>medium</td>\n",
       "      <td>What is the ship that sank in the Baltic sea a...</td>\n",
       "      <td>[[The I.V. Stalin White Sea  Baltic Sea Canal...</td>\n",
       "      <td>MV \"Wilhelm Gustloff</td>\n",
       "      <td>5ab56e71554299494045efc8</td>\n",
       "      <td>bridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90446</th>\n",
       "      <td>[[Vietnam national cricket team, 0], [Vietnam ...</td>\n",
       "      <td>medium</td>\n",
       "      <td>Vietnam national cricket team will debut at wh...</td>\n",
       "      <td>[[Vietnam national cricket team, [The Vietnam ...</td>\n",
       "      <td>2017 Southeast Asian Games</td>\n",
       "      <td>5ac28e915542996366519a0a</td>\n",
       "      <td>bridge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90447 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        supporting_facts   level  \\\n",
       "0         [[Arthur's Magazine, 0], [First for Women, 0]]  medium   \n",
       "1            [[Oberoi family, 0], [The Oberoi Group, 0]]  medium   \n",
       "2      [[Allie Goertz, 0], [Allie Goertz, 1], [Allie ...    hard   \n",
       "3      [[Peggy Seeger, 0], [Peggy Seeger, 1], [Ewan M...  medium   \n",
       "4                  [[Cadmium chloride, 1], [Ethanol, 0]]  medium   \n",
       "...                                                  ...     ...   \n",
       "90442              [[Kerry Remsen, 1], [Bert Remsen, 0]]  medium   \n",
       "90443  [[Northshore Mall, 0], [Northshore Mall, 4], [...    easy   \n",
       "90444            [[Charlee Johnson, 4], [DreamWorks, 0]]  medium   \n",
       "90445   [[Salt to the Sea, 1], [MV Wilhelm Gustloff, 0]]  medium   \n",
       "90446  [[Vietnam national cricket team, 0], [Vietnam ...  medium   \n",
       "\n",
       "                                                question  \\\n",
       "0      Which magazine was started first Arthur's Maga...   \n",
       "1      The Oberoi family is part of a hotel company t...   \n",
       "2      Musician and satirist Allie Goertz wrote a son...   \n",
       "3        What nationality was James Henry Miller's wife?   \n",
       "4      Cadmium Chloride is slightly soluble in this c...   \n",
       "...                                                  ...   \n",
       "90442  Kerry Remsen is the daughter of an actor with ...   \n",
       "90443  Who manages both Northshore Mall in Peabody, M...   \n",
       "90444  Charlee Johnson was part of a band that signed...   \n",
       "90445  What is the ship that sank in the Baltic sea a...   \n",
       "90446  Vietnam national cricket team will debut at wh...   \n",
       "\n",
       "                                                 context  \\\n",
       "0      [[Radio City (Indian radio station), [Radio Ci...   \n",
       "1      [[Ritz-Carlton Jakarta, [The Ritz-Carlton Jaka...   \n",
       "2      [[Lisa Simpson, [Lisa Marie Simpson is a ficti...   \n",
       "3      [[Moloch: or, This Gentile World, [Moloch: or,...   \n",
       "4      [[Cadmium chloride, [Cadmium chloride is a whi...   \n",
       "...                                                  ...   \n",
       "90442  [[Kerry Remsen, [Kerry Remsen is an American a...   \n",
       "90443  [[Green Tree Mall, [Green Tree Mall is a shopp...   \n",
       "90444  [[Simon M. Woods, [Simon M. Woods is a British...   \n",
       "90445  [[The I.V. Stalin White Sea  Baltic Sea Canal...   \n",
       "90446  [[Vietnam national cricket team, [The Vietnam ...   \n",
       "\n",
       "                           answer                       _id        type  \n",
       "0               Arthur's Magazine  5a7a06935542990198eaf050  comparison  \n",
       "1                           Delhi  5a879ab05542996e4f30887e      bridge  \n",
       "2         President Richard Nixon  5a8d7341554299441c6b9fe5      bridge  \n",
       "3                        American  5a82171f5542990a1d231f4a      bridge  \n",
       "4                         alcohol  5a84dd955542997b5ce3ff79      bridge  \n",
       "...                           ...                       ...         ...  \n",
       "90442                    American  5a8f8db25542997ba9cb32b9      bridge  \n",
       "90443        Simon Property Group  5ae4f3615542993aec5ec0fd      bridge  \n",
       "90444             Amblin Partners  5a903fc95542990a984935bd      bridge  \n",
       "90445        MV \"Wilhelm Gustloff  5ab56e71554299494045efc8      bridge  \n",
       "90446  2017 Southeast Asian Games  5ac28e915542996366519a0a      bridge  \n",
       "\n",
       "[90447 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hpqa = get_hotpotqa()\n",
    "df_hpqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    90447.000000\n",
       "mean       105.604277\n",
       "std         59.117430\n",
       "min         13.000000\n",
       "25%         69.000000\n",
       "50%         90.000000\n",
       "75%        120.000000\n",
       "max        654.000000\n",
       "Name: question, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hpqa.question.str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ctx in df_hpqa.context:\n",
    "    assert type(ctx) == list, str(ctx)\n",
    "    for l in ctx:\n",
    "        assert type(l) == list and len(l) == 2\n",
    "        assert type(l[0]) == str and type(l[1]) == list\n",
    "        for s in l[1]:\n",
    "            assert type(s) == str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    90447.000000\n",
       "mean       886.234380\n",
       "std        251.339109\n",
       "min         29.000000\n",
       "25%        721.000000\n",
       "50%        867.000000\n",
       "75%       1028.000000\n",
       "max       2792.000000\n",
       "Name: context, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hpqa.context.apply(lambda ctx: sum(len(s.split()) for l in ctx for s in l[1])).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    90447.000000\n",
       "mean        13.719040\n",
       "std         11.828903\n",
       "min          1.000000\n",
       "25%          7.000000\n",
       "50%         12.000000\n",
       "75%         17.000000\n",
       "max        623.000000\n",
       "Name: answer, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hpqa.answer.str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "supporting_facts                [[Cadmium chloride, 1], [Ethanol, 0]]\n",
       "level                                                          medium\n",
       "question            Cadmium Chloride is slightly soluble in this c...\n",
       "context             [[Cadmium chloride, [Cadmium chloride is a whi...\n",
       "answer                                                        alcohol\n",
       "_id                                          5a84dd955542997b5ce3ff79\n",
       "type                                                           bridge\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = df_hpqa.iloc[4]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cadmium Chloride is slightly soluble in this chemical, it is also called what?\n",
      "[['Cadmium chloride', 1], ['Ethanol', 0]]\n"
     ]
    }
   ],
   "source": [
    "print(row.question)\n",
    "print(row.supporting_facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Cadmium chloride',\n",
       "  ['Cadmium chloride is a white crystalline compound of cadmium and chlorine, with the formula CdCl.',\n",
       "   ' It is a hygroscopic solid that is highly soluble in water and slightly soluble in alcohol.',\n",
       "   ' Although it is considered to be ionic, it has considerable covalent character to its bonding.',\n",
       "   ' The crystal structure of cadmium chloride (described below), composed of two-dimensional layers of ions, is a reference for describing other crystal structures.',\n",
       "   ' Also known are CdClHO and CdCl5HO.']],\n",
       " ['Water blue',\n",
       "  ['Water blue, also known as aniline blue, Acid blue 22, Soluble Blue 3M, Marine Blue V, or C.I. 42755, is a chemical compound used as a stain in histology.',\n",
       "   ' Water blue stains collagen blue in tissue sections.',\n",
       "   ' It is soluble in water and slightly soluble in ethanol.']],\n",
       " ['Diflucortolone valerate',\n",
       "  ['Diflucortolone valerate (also \"Nerisone\" cream/oily cream/ointment, \"Neriderm\" ointment, Japanese  (Jifurucorutoron ) is a corticosteroid rated Class 2 \"potent\" (100-150 times) in the New Zealand topical steroid system.',\n",
       "   ' It is a white to creamy white crystalline powder.',\n",
       "   ' It is practically insoluble in water, freely soluble in dichloromethane and in dioxan, sparingly soluble in ether and slightly soluble in methyl alcohol.',\n",
       "   ' Chemically, it is a corticosteroid esterified with valeric acid.',\n",
       "   ' It is commonly used topically in dermatology.',\n",
       "   ' The brand name is Nerisone; its creams come in potencies of 0.1% and 0.3%.']],\n",
       " ['Heptanoic acid',\n",
       "  ['Heptanoic acid, also called enanthic acid, is an organic compound composed of a seven-carbon chain terminating in a carboxylic acid.',\n",
       "   ' It is an oily liquid with an unpleasant, rancid odor.',\n",
       "   ' It contributes to the odor of some rancid oils.',\n",
       "   ' It is slightly soluble in water, but very soluble in ethanol and ether.']],\n",
       " ['Magnesium chloride',\n",
       "  ['Magnesium chloride is the name for the chemical compound with the formula MgCl and its various hydrates MgCl(HO).',\n",
       "   ' These salts are typical ionic halides, being highly soluble in water.',\n",
       "   ' The hydrated magnesium chloride can be extracted from brine or sea water.',\n",
       "   ' In North America, magnesium chloride is produced primarily from Great Salt Lake brine.',\n",
       "   ' It is extracted in a similar process from the Dead Sea in the Jordan valley.',\n",
       "   ' Magnesium chloride, as the natural mineral bischofite, is also extracted (via solution mining) out of ancient seabeds; for example, the Zechstein seabed in northwest Europe.',\n",
       "   ' Some magnesium chloride is made from solar evaporation of seawater.',\n",
       "   ' Anhydrous magnesium chloride is the principal precursor to magnesium metal, which is produced on a large scale.',\n",
       "   ' Hydrated magnesium chloride is the form most readily available.']],\n",
       " ['Ethanol',\n",
       "  ['Ethanol, also called alcohol, ethyl alcohol, and drinking alcohol, is a compound and simple alcohol with the chemical formula C2H5OH .',\n",
       "   ' Its formula can be written also as CH3 CH2 OH or C2H5 OH (an ethyl group linked to a hydroxyl group), and is often abbreviated as EtOH.',\n",
       "   ' Ethanol is a volatile, flammable, colorless liquid with a slight characteristic odor.',\n",
       "   ' It is used as a drug and is the principal type of alcohol found in alcoholic drinks.']],\n",
       " ['Tributyltin oxide',\n",
       "  ['Tributyltin oxide (TBTO) is an organotin compound chiefly used as a biocide (fungicide and molluscicide), especially a wood preservative.',\n",
       "   ' Its chemical formula is <ce>[(C4H9)3Sn]2O</ce>.',\n",
       "   ' It has the form of a colorless to pale yellow liquid that is only slightly soluble in water (20 ppm) but highly soluble in organic solvents.',\n",
       "   ' It is a potent skin irritant.']],\n",
       " ['Benzamide',\n",
       "  ['Benzamide is an off-white solid with the chemical formula of CHCONH.',\n",
       "   ' It is a derivative of benzoic acid.',\n",
       "   ' It is slightly soluble in water, and soluble in many organic solvents.']],\n",
       " ['Gold(III) chloride',\n",
       "  ['Gold(III) chloride, traditionally called auric chloride, is a chemical compound of gold and chlorine.',\n",
       "   ' With the molecular formula AuCl, the name gold trichloride is a simplification, referring to the empirical formula, AuCl.',\n",
       "   ' The Roman numerals in the name indicate that the gold has an oxidation state of +3, which is common for gold compounds.',\n",
       "   ' There is also another related chloride of gold, gold(I) chloride (AuCl).',\n",
       "   ' Chloroauric acid, HAuCl, the product formed when gold dissolves in aqua regia, is sometimes referred to as \"gold chloride\" or \"acid gold trichloride\".',\n",
       "   ' Gold(III) chloride is very hygroscopic and highly soluble in water as well as ethanol.',\n",
       "   ' It decomposes above 160\\xa0C or in light.']],\n",
       " ['Chloride',\n",
       "  ['The chloride ion is the anion (negatively charged ion) Cl.',\n",
       "   ' It is formed when the element chlorine (a halogen) gains an electron or when a compound such as hydrogen chloride is dissolved in water or other polar solvents.',\n",
       "   ' Chloride salts such as sodium chloride are often very soluble in water.',\n",
       "   ' It is an essential electrolyte located in all body fluids responsible for maintaining acid/base balance, transmitting nerve impulses and regulating fluid in and out of cells.',\n",
       "   ' Less frequently, the word \"chloride\" may also form part of the \"common\" name of chemical compounds in which one or more chlorine atoms are covalently bonded.',\n",
       "   ' For example, methyl chloride, with the standard name chloromethane (see IUPAC books) is an organic compound with a covalent CCl bond in which the chlorine is not an anion.']]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squad v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad_v2 (/home/misha/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb5bae8b3784ef7bc3053738474b500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 130319\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 11873\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_sq = load_dataset('squad_v2')\n",
    "ds_sq_t, ds_sq_v = ds_sq['train'], ds_sq['validation']\n",
    "ds_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56cfc773234ae51400d9bf56',\n",
       " 'title': 'Solar_energy',\n",
       " 'context': 'Solar technologies are broadly characterized as either passive or active depending on the way they capture, convert and distribute sunlight and enable solar energy to be harnessed at different levels around the world, mostly depending on distance from the equator. Although solar energy refers primarily to the use of solar radiation for practical ends, all renewable energies, other than geothermal and tidal, derive their energy from the Sun in a direct or indirect way.',\n",
       " 'question': 'How do renewable energies acquire energy from the sun?',\n",
       " 'answers': {'text': ['direct or indirect'], 'answer_start': [449]}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = ds_sq_t[4500]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'direct or indirect'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_txt, ans_start, ctx = row['answers']['text'][0], row['answers']['answer_start'][0], row['context']\n",
    "ctx[ans_start:ans_start + len(ans_txt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sq = ds_sq_t.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    130319.000000\n",
       "mean         58.507739\n",
       "std          73.757111\n",
       "min           1.000000\n",
       "25%          44.000000\n",
       "50%          55.000000\n",
       "75%          69.000000\n",
       "max       25651.000000\n",
       "Name: question, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sq.question.str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    130319.000000\n",
       "mean        754.566287\n",
       "std         307.619239\n",
       "min         151.000000\n",
       "25%         561.000000\n",
       "50%         692.000000\n",
       "75%         891.000000\n",
       "max        3706.000000\n",
       "Name: context, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sq.context.str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                   56be85543aeaaa14008c9063\n",
       "title                                                 Beyonc\n",
       "context     Beyonc Giselle Knowles-Carter (/bijnse/ b...\n",
       "question             When did Beyonce start becoming popular?\n",
       "answers     {'text': ['in the late 1990s'], 'answer_start'...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sq.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    86821.000000\n",
       "mean       319.806475\n",
       "std        266.390192\n",
       "min          0.000000\n",
       "25%        111.000000\n",
       "50%        262.000000\n",
       "75%        468.000000\n",
       "max       3126.000000\n",
       "Name: answers, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast = df_sq['answers'].apply(lambda anss: anss['answer_start'][0] if len(anss['answer_start']) > 0 else -1)\n",
    "ast = ast[ast >= 0]\n",
    "ast.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    130319.000000\n",
       "mean        119.614316\n",
       "std          49.404411\n",
       "min          20.000000\n",
       "25%          89.000000\n",
       "50%         110.000000\n",
       "75%         141.000000\n",
       "max         653.000000\n",
       "Name: context, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl = df_sq['context'].apply(lambda c: len(c.split()))\n",
    "cl.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eli5 Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57fdbb523b3c4ca382778a3095ca20a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.28k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df47aa29845d4fb2883a4f586326cb06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: eli5_category/default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset eli5_category/default (download: 69.54 MiB, generated: 185.70 MiB, post-processed: Unknown size, total: 255.24 MiB) to /home/misha/.cache/huggingface/datasets/eli5_category/default/1.0.0/80106cc49322f1f5075e1387be4a5b74b95e0f56c40ff142b8999d0606aa1908...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95570345832d4929bb9700f2ccdcd347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0568cb63d0fa4f91aa14edad097094a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/62.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c66a00a76dd47938d9bd198b0becd20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/5.00M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9d8b30c571498fa9c1615ce25ce523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.76M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35cf58c154b4fc1a4d7ee0a8853c8b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6690594a1e4428b2ff4c22740a2b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2240048ae84b01ab02c4444f4723ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0617697b194069b749fbbaf8dfe460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eec9b8f8c094955a26923025f7f1643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fda5ca49cbf4f4397f4559bce330a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset eli5_category downloaded and prepared to /home/misha/.cache/huggingface/datasets/eli5_category/default/1.0.0/80106cc49322f1f5075e1387be4a5b74b95e0f56c40ff142b8999d0606aa1908. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "ds_eli5 = load_dataset(\"eli5_category\", split=\"train[:5000]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['q_id', 'title', 'selftext', 'category', 'subreddit', 'answers', 'title_urls', 'selftext_urls'],\n",
       "        num_rows: 4500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['q_id', 'title', 'selftext', 'category', 'subreddit', 'answers', 'title_urls', 'selftext_urls'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_eli5 = ds_eli5.train_test_split(test_size=0.1)\n",
    "ds_eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q_id': '5lwp25',\n",
       " 'title': 'Both the sun and moon appear flat, with no cues that one is further away than the other. What is the maximum distance that variations in depth can be perceived at, and why?',\n",
       " 'selftext': '',\n",
       " 'category': 'Biology',\n",
       " 'subreddit': 'explainlikeimfive',\n",
       " 'answers': {'a_id': ['dbz54c7'],\n",
       "  'text': [\"We don't have depth perception beyond about 10 meters. Anything further than that, your eyes are focused at infinity, and are pointing in the same direction. Beyond that, we use cues like its apparent size and brightness, or color shifts caused by the amount of air between you and the object (how a distant mountain looks more blue than a near one). We determine things are flat or round by their shadows.\"],\n",
       "  'score': [4],\n",
       "  'text_urls': [[]]},\n",
       " 'title_urls': ['url'],\n",
       " 'selftext_urls': ['url']}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_eli5['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type bert-generation. This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type bert to instantiate a model of type bert-generation. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of BertGenerationDecoder were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'lm_head.bias', 'lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "enc_model: BertGenerationEncoder = BertGenerationEncoder.from_pretrained(model_name, bos_token_id=101, eos_token_id=102)\n",
    "# add cross attention layers and use BERT's cls token as BOS token and sep token as EOS token\n",
    "dec_model: BertGenerationDecoder = BertGenerationDecoder.from_pretrained(\n",
    "    model_name, add_cross_attention=True, is_decoder=True, bos_token_id=101, eos_token_id=102\n",
    ")\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "eed_model = EncoderEmbDecoderModel(encoder=enc_model, decoder=dec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>Beyonc</td>\n",
       "      <td>Beyonc Giselle Knowles-Carter (/bijnse/ b...</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>{'text': ['in the late 1990s'], 'answer_start'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56be85543aeaaa14008c9065</td>\n",
       "      <td>Beyonc</td>\n",
       "      <td>Beyonc Giselle Knowles-Carter (/bijnse/ b...</td>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>{'text': ['singing and dancing'], 'answer_star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56be85543aeaaa14008c9066</td>\n",
       "      <td>Beyonc</td>\n",
       "      <td>Beyonc Giselle Knowles-Carter (/bijnse/ b...</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>{'text': ['2003'], 'answer_start': [526]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
       "      <td>Beyonc</td>\n",
       "      <td>Beyonc Giselle Knowles-Carter (/bijnse/ b...</td>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>{'text': ['Houston, Texas'], 'answer_start': [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
       "      <td>Beyonc</td>\n",
       "      <td>Beyonc Giselle Knowles-Carter (/bijnse/ b...</td>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>{'text': ['late 1990s'], 'answer_start': [276]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11868</th>\n",
       "      <td>5737aafd1c456719005744ff</td>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What is the seldom used force unit equal to on...</td>\n",
       "      <td>{'text': ['sthne', 'sthne', 'sthne', 'sthn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11869</th>\n",
       "      <td>5ad28ad0d7d075001a4299cc</td>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What does not have a metric counterpart?</td>\n",
       "      <td>{'text': [], 'answer_start': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11870</th>\n",
       "      <td>5ad28ad0d7d075001a4299cd</td>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What is the force exerted by standard gravity ...</td>\n",
       "      <td>{'text': [], 'answer_start': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11871</th>\n",
       "      <td>5ad28ad0d7d075001a4299ce</td>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What force leads to a commonly used unit of mass?</td>\n",
       "      <td>{'text': [], 'answer_start': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11872</th>\n",
       "      <td>5ad28ad0d7d075001a4299cf</td>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What force is part of the modern SI system?</td>\n",
       "      <td>{'text': [], 'answer_start': []}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142192 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id    title  \\\n",
       "0      56be85543aeaaa14008c9063  Beyonc   \n",
       "1      56be85543aeaaa14008c9065  Beyonc   \n",
       "2      56be85543aeaaa14008c9066  Beyonc   \n",
       "3      56bf6b0f3aeaaa14008c9601  Beyonc   \n",
       "4      56bf6b0f3aeaaa14008c9602  Beyonc   \n",
       "...                         ...      ...   \n",
       "11868  5737aafd1c456719005744ff    Force   \n",
       "11869  5ad28ad0d7d075001a4299cc    Force   \n",
       "11870  5ad28ad0d7d075001a4299cd    Force   \n",
       "11871  5ad28ad0d7d075001a4299ce    Force   \n",
       "11872  5ad28ad0d7d075001a4299cf    Force   \n",
       "\n",
       "                                                 context  \\\n",
       "0      Beyonc Giselle Knowles-Carter (/bijnse/ b...   \n",
       "1      Beyonc Giselle Knowles-Carter (/bijnse/ b...   \n",
       "2      Beyonc Giselle Knowles-Carter (/bijnse/ b...   \n",
       "3      Beyonc Giselle Knowles-Carter (/bijnse/ b...   \n",
       "4      Beyonc Giselle Knowles-Carter (/bijnse/ b...   \n",
       "...                                                  ...   \n",
       "11868  The pound-force has a metric counterpart, less...   \n",
       "11869  The pound-force has a metric counterpart, less...   \n",
       "11870  The pound-force has a metric counterpart, less...   \n",
       "11871  The pound-force has a metric counterpart, less...   \n",
       "11872  The pound-force has a metric counterpart, less...   \n",
       "\n",
       "                                                question  \\\n",
       "0               When did Beyonce start becoming popular?   \n",
       "1      What areas did Beyonce compete in when she was...   \n",
       "2      When did Beyonce leave Destiny's Child and bec...   \n",
       "3          In what city and state did Beyonce  grow up?    \n",
       "4             In which decade did Beyonce become famous?   \n",
       "...                                                  ...   \n",
       "11868  What is the seldom used force unit equal to on...   \n",
       "11869           What does not have a metric counterpart?   \n",
       "11870  What is the force exerted by standard gravity ...   \n",
       "11871  What force leads to a commonly used unit of mass?   \n",
       "11872        What force is part of the modern SI system?   \n",
       "\n",
       "                                                 answers  \n",
       "0      {'text': ['in the late 1990s'], 'answer_start'...  \n",
       "1      {'text': ['singing and dancing'], 'answer_star...  \n",
       "2              {'text': ['2003'], 'answer_start': [526]}  \n",
       "3      {'text': ['Houston, Texas'], 'answer_start': [...  \n",
       "4        {'text': ['late 1990s'], 'answer_start': [276]}  \n",
       "...                                                  ...  \n",
       "11868  {'text': ['sthne', 'sthne', 'sthne', 'sthn...  \n",
       "11869                   {'text': [], 'answer_start': []}  \n",
       "11870                   {'text': [], 'answer_start': []}  \n",
       "11871                   {'text': [], 'answer_start': []}  \n",
       "11872                   {'text': [], 'answer_start': []}  \n",
       "\n",
       "[142192 rows x 5 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sq = pd.concat([ds_sq['train'].to_pandas(), ds_sq['validation'].to_pandas()], axis=0)\n",
    "df_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mllm.train.embgen_bert import get_sq_batch, qna_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'title', 'context', 'question', 'answers'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_sq.columns)\n",
    "inp_len = 128\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = [0, 100, 200]\n",
    "inds = np.array(inds)\n",
    "qnab = get_sq_batch(tkz=tokenizer, df_sq=df_sq, inds=inds, inp_len=inp_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 128)\n",
      "(12,) [False False False False False False False  True False False False False]\n",
      "(15,) [False False False False False False False False False False False False\n",
      " False  True False]\n",
      "(18,) [False False False False False False False False False False False False\n",
      " False False False False  True False]\n",
      "(4, 12)\n",
      "(1, 15)\n",
      "(1, 18)\n",
      "(4, 12)\n",
      "(1, 15)\n",
      "(1, 18)\n"
     ]
    }
   ],
   "source": [
    "print(qnab.ctx_toks.shape)\n",
    "for qa_toks in qnab.qa_toks:\n",
    "    print(qa_toks.shape, qa_toks == tokenizer.sep_token_id)\n",
    "for qa_att_mask in qnab.qa_att_masks:\n",
    "    print(qa_att_mask.shape)\n",
    "for qa_tgt_mask in qnab.qa_tgt_masks:\n",
    "    print(qa_tgt_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 128])\n",
      "torch.Size([12]) tensor([False, False, False, False, False, False, False,  True, False, False,\n",
      "        False, False])\n",
      "torch.Size([15]) tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False])\n",
      "torch.Size([18]) tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False,  True, False])\n",
      "torch.Size([4, 12])\n",
      "torch.Size([1, 15])\n",
      "torch.Size([1, 18])\n",
      "torch.Size([4, 12])\n",
      "torch.Size([1, 15])\n",
      "torch.Size([1, 18])\n"
     ]
    }
   ],
   "source": [
    "qas, qa_att_masks, qa_tgt_masks, ctxs = qnab.gen_tensors()\n",
    "print(ctxs.shape)\n",
    "for qa in qas:\n",
    "    print(qa.shape, qa == tokenizer.sep_token_id)\n",
    "for qa_att_mask in qa_att_masks:\n",
    "    print(qa_att_mask.shape)\n",
    "for qa_tgt_mask in qa_tgt_masks:\n",
    "    print(qa_tgt_mask.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 128, 768]) torch.Size([1, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "enc_out: BaseModelOutputWithPastAndCrossAttentions = enc_model(input_ids=ctxs)\n",
    "enc_emb = enc_out.last_hidden_state[:, 0].unsqueeze(0)\n",
    "print(enc_out.last_hidden_state.shape, enc_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 12]) torch.Size([4, 12])\n",
      "tensor([[ 2043,  2106, 20773,  2707,  3352,  2759,  1029,   102,  1999,  1996,\n",
      "          2397,  4134],\n",
      "        [ 2043,  2106, 20773,  2707,  3352,  2759,  1029,   102,  1999,  1996,\n",
      "          2397,  4134],\n",
      "        [ 2043,  2106, 20773,  2707,  3352,  2759,  1029,   102,  1999,  1996,\n",
      "          2397,  4134],\n",
      "        [ 2043,  2106, 20773,  2707,  3352,  2759,  1029,   102,  1999,  1996,\n",
      "          2397,  4134]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])\n",
      "tensor([[False, False, False, False, False, False, False, False,  True, False,\n",
      "         False, False],\n",
      "        [False, False, False, False, False, False, False, False, False,  True,\n",
      "         False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "          True, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False,  True]])\n"
     ]
    }
   ],
   "source": [
    "ind = 0\n",
    "qa, qa_att_mask, qa_tgt_mask = qas[ind].unsqueeze(0), qa_att_masks[ind], qa_tgt_masks[ind]\n",
    "qa = qa.repeat(len(qa_att_mask), 1)\n",
    "print(qa.shape, qa_att_mask.shape)\n",
    "print(qa)\n",
    "print(qa_att_mask)\n",
    "print(qa_tgt_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 12, 30522])\n"
     ]
    }
   ],
   "source": [
    "dec_out: CausalLMOutputWithCrossAttentions = dec_model(input_ids=qa, attention_mask=qa_att_mask, encoder_hidden_states=enc_emb)\n",
    "print(dec_out.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-3.3552, grad_fn=<MinBackward1>),\n",
       " tensor(-0.1662, grad_fn=<MeanBackward0>),\n",
       " tensor(4.1287, grad_fn=<MaxBackward1>),\n",
       " tensor(0.5924, grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_out.logits.min(), dec_out.logits.mean(), dec_out.logits.max(), dec_out.logits.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 12, 30522]), torch.Size([4, 30522]))"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_logits = dec_out.logits.masked_select(qa_tgt_mask.unsqueeze(-1))\n",
    "tgt_logits = tgt_logits.reshape(dec_out.logits.shape[0], dec_out.logits.shape[2])\n",
    "dec_out.logits.shape, tgt_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1999],\n",
       "        [1996],\n",
       "        [2397],\n",
       "        [4134]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_toks = qa.masked_select(qa_tgt_mask).unsqueeze(-1)\n",
    "tgt_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.3836e-05],\n",
       "        [1.9808e-05],\n",
       "        [2.8551e-05],\n",
       "        [7.0084e-05]], grad_fn=<GatherBackward0>)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_pred = torch.softmax(tgt_logits, dim=-1)\n",
    "torch.gather(probs_pred, dim=-1, index=tgt_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.1433, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = qna_loss(dec_out.logits, qa, qa_tgt_mask)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  b\n",
      "0  1  x\n",
      "1  2  y\n",
      "2  3  z\n",
      "   a  b\n",
      "2  3  z\n",
      "0  1  x\n",
      "1  2  y\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'a': [1, 2, 3], 'b': ['x', 'y', 'z']})\n",
    "print(df)\n",
    "print(df.sample(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'b'), (6, 'f'), (4, 'd'), (5, 'e'), (3, 'c'), (1, 'a')]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd'), (5, 'e'), (6, 'f')]\n",
    "np.random.shuffle(l)\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EncoderDecoderModel middle layer type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type bert-generation. This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type bert to instantiate a model of type bert-generation. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of BertGenerationDecoder were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'lm_head.bias', 'lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<EncEmbExpansionType.Mat: 'mat'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'google-bert/bert-base-uncased'\n",
    "enc_emb_exp_type = EncEmbExpansionType.Mat\n",
    "\n",
    "enc_model: BertGenerationEncoder = BertGenerationEncoder.from_pretrained(model_name, bos_token_id=101, eos_token_id=102)\n",
    "# add cross attention layers and use BERT's cls token as BOS token and sep token as EOS token\n",
    "dec_model: BertGenerationDecoder = BertGenerationDecoder.from_pretrained(\n",
    "    model_name, add_cross_attention=True, is_decoder=True, bos_token_id=101, eos_token_id=102\n",
    ")\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "eed_model = EncoderEmbDecoderModel(encoder=enc_model, decoder=dec_model, enc_emb_exp_type=enc_emb_exp_type)\n",
    "eed_model.config.enc_emb_exp_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertGenerationConfig {\n",
       "  \"_name_or_path\": \"google-bert/bert-base-uncased\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 101,\n",
       "  \"eos_token_id\": 102,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert-generation\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.42.4\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_enc = eed_model.config.encoder\n",
    "cfg_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 1, 6, 8, 8],\n",
       "        [7, 0, 1, 8, 1],\n",
       "        [1, 2, 6, 4, 6]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randint(0, 9, (3, 5))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 1, 6, 8, 8],\n",
       "        [7, 0, 1, 8, 1],\n",
       "        [1, 2, 6, 4, 6],\n",
       "        [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.pad(t, (0, 0, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
