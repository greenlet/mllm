{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from pydantic_yaml import to_yaml_file, parse_yaml_file_as\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "from mllm.config.model import create_mllm_encdec_cfg, create_mllm_ranker_cfg, TokenizerCfg, \\\n",
    "    VocabEncoderCfg, EncoderCfg, MllmRankerCfg\n",
    "from mllm.tokenization.chunk_tokenizer import calc_max_inp_size, gen_all_tokens, tokenizer_from_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration generation\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/misha/prog/mllm/mllm/config/cfg_v001')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_dpath = Path(os.path.abspath('.')).parent / 'mllm' / 'config' / 'cfg_v001'\n",
    "cfg_dpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_config_to_yaml(cfg: BaseModel, fpath: Path, overwrite: bool = False):\n",
    "    if not fpath.exists() or overwrite:\n",
    "        to_yaml_file(fpath, cfg)\n",
    "    else:\n",
    "        print(f'File {fpath} already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', model_max_length=10000)\n",
    "n_tokens_init = len(tokenizer)\n",
    "tok_dict = gen_all_tokens(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenizerCfg(name='gpt2', n_tokens_init=50257, model_max_length=10000, custom_tokens={'doc_begin': CustomToken(name='doc_begin', repr='<|doc_begin|>', special=False, ind=50257), 'doc_end': CustomToken(name='doc_end', repr='<|doc_end|>', special=False, ind=50258), 'doc_id_begin': CustomToken(name='doc_id_begin', repr='<|doc_id_begin|>', special=False, ind=50259), 'doc_id_end': CustomToken(name='doc_id_end', repr='<|doc_id_end|>', special=False, ind=50260), 'doc_offset_begin': CustomToken(name='doc_offset_begin', repr='<|doc_offset_begin|>', special=False, ind=50261), 'doc_offset_end': CustomToken(name='doc_offset_end', repr='<|doc_offset_end|>', special=False, ind=50262), 'doc_title_begin': CustomToken(name='doc_title_begin', repr='<|doc_title_begin|>', special=False, ind=50263), 'doc_title_end': CustomToken(name='doc_title_end', repr='<|doc_title_end|>', special=False, ind=50264), 'doc_body_begin': CustomToken(name='doc_body_begin', repr='<|doc_body_begin|>', special=False, ind=50265), 'doc_body_end': CustomToken(name='doc_body_end', repr='<|doc_body_end|>', special=False, ind=50266), 'pad': CustomToken(name='pad', repr='<|pad|>', special=True, ind=50267), 'query_begin': CustomToken(name='query_begin', repr='<|query_begin|>', special=False, ind=50268), 'query_end': CustomToken(name='query_end', repr='<|query_end|>', special=False, ind=50269)})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkz_cfg = TokenizerCfg(name='gpt2', n_tokens_init=n_tokens_init, model_max_length=10000, custom_tokens=tok_dict)\n",
    "tkz_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/misha/prog/mllm/mllm/config/cfg_v001/tokenizer_cfg_01.yaml already exists\n"
     ]
    }
   ],
   "source": [
    "tkz_cfg_fpath = cfg_dpath / 'tokenizer_cfg_01.yaml'\n",
    "save_config_to_yaml(tkz_cfg, tkz_cfg_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens_init = 50257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2Tokenizer(name_or_path='gpt2', vocab_size=50257, model_max_length=10000, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|pad|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t50257: AddedToken(\"<|doc_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50258: AddedToken(\"<|doc_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50259: AddedToken(\"<|doc_id_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50260: AddedToken(\"<|doc_id_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50261: AddedToken(\"<|doc_offset_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50262: AddedToken(\"<|doc_offset_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50263: AddedToken(\"<|doc_title_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50264: AddedToken(\"<|doc_title_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50265: AddedToken(\"<|doc_body_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50266: AddedToken(\"<|doc_body_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50267: AddedToken(\"<|pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t50268: AddedToken(\"<|query_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50269: AddedToken(\"<|query_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'n_tokens_init = {n_tokens_init}')\n",
    "tkz = tokenizer_from_config(tkz_cfg)\n",
    "tkz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLLM Ranker first layer config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MllmRankerCfg(vocab_encoder=VocabEncoderCfg(n_vocab=50270, d_word_vec=256, d_model=256, pad_idx=-1, inp_len=100, dropout_rate=0.0), encoders=[EncoderCfg(n_layers=1, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=-1, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=True)], decoders=[EncoderCfg(n_layers=1, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=-1, with_graph_mat=False, inp_len=0, dropout_rate=0.0, with_emb_mat=False)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cfg = create_mllm_ranker_cfg(\n",
    "    n_vocab=len(tokenizer), inp_len=100, d_word_wec=256,\n",
    "    n_levels=1, enc_n_layers=1, dec_n_layers=1,\n",
    "    n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024,\n",
    "    pad_idx=-1, dropout_rate=0.0, enc_with_emb_mat=True,\n",
    ")\n",
    "model_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/misha/prog/mllm/mllm/config/cfg_v001/ranker_model_cfg_01.yaml already exists\n"
     ]
    }
   ],
   "source": [
    "ranker_cfg_fpath = cfg_dpath / 'ranker_model_cfg_01.yaml'\n",
    "save_config_to_yaml(model_cfg, ranker_cfg_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLLM Ranker multi layers config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50267\n",
      "GPT2Tokenizer(name_or_path='gpt2', vocab_size=50257, model_max_length=10000, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|pad|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t50257: AddedToken(\"<|doc_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50258: AddedToken(\"<|doc_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50259: AddedToken(\"<|doc_id_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50260: AddedToken(\"<|doc_id_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50261: AddedToken(\"<|doc_offset_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50262: AddedToken(\"<|doc_offset_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50263: AddedToken(\"<|doc_title_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50264: AddedToken(\"<|doc_title_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50265: AddedToken(\"<|doc_body_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50266: AddedToken(\"<|doc_body_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50267: AddedToken(\"<|pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t50268: AddedToken(\"<|query_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50269: AddedToken(\"<|query_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "tkz_cfg_fpath = cfg_dpath / 'tokenizer_cfg_01.yaml'\n",
    "tkz_cfg = parse_yaml_file_as(TokenizerCfg, tkz_cfg_fpath)\n",
    "tkz = tokenizer_from_config(tkz_cfg)\n",
    "print(tkz.pad_token_id)\n",
    "print(tkz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GPT2Tokenizer' object has no attribute 'pad_tok'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m d_word_wec \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m,\n\u001b[1;32m      4\u001b[0m n_heads, d_k, d_v, d_model, d_inner \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m1024\u001b[39m\n\u001b[0;32m----> 5\u001b[0m pad_idx \u001b[38;5;241m=\u001b[39m \u001b[43mtkz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_tok\u001b[49m\n\u001b[1;32m      6\u001b[0m dropout_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m      7\u001b[0m enc_with_emb_mat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GPT2Tokenizer' object has no attribute 'pad_tok'"
     ]
    }
   ],
   "source": [
    "n_vocab = len(tkz)\n",
    "inp_len = 100\n",
    "d_word_wec = 256,\n",
    "n_heads, d_k, d_v, d_model, d_inner = 8, 32, 32, 256, 1024\n",
    "pad_idx = tkz.pad_tok\n",
    "dropout_rate = 0.0\n",
    "enc_with_emb_mat = True\n",
    "\n",
    "cfg_vocab_enc = VocabEncoderCfg(\n",
    "    n_vocab=n_vocab, d_word_vec=d_word_wec, d_model=d_model, pad_idx=pad_idx, inp_len=inp_len, dropout_rate=dropout_rate,\n",
    ")\n",
    "cfgs_enc = [\n",
    "    EncoderCfg(\n",
    "        n_layers=n_layers, n_heads=n_heads, d_k=d_k, d_v=d_v, d_model=d_model, d_inner=d_inner, pad_idx=pad_idx,\n",
    "        with_graph_mat=enc_with_graph_mat, inp_len=inp_len, dropout_rate=dropout_rate, with_emb_mat=enc_with_emb_mat,\n",
    "    ),\n",
    "    EncoderCfg(\n",
    "        n_layers=n_layers, n_heads=n_heads, d_k=d_k, d_v=d_v, d_model=d_model, d_inner=d_inner, pad_idx=pad_idx,\n",
    "        with_graph_mat=enc_with_graph_mat, inp_len=inp_len, dropout_rate=dropout_rate, with_emb_mat=enc_with_emb_mat,\n",
    "    )\n",
    "]\n",
    "\n",
    "cfgs_dec = [\n",
    "    EncoderCfg(\n",
    "        n_layers=n_layers, n_heads=n_heads, d_k=d_k, d_v=d_v, d_model=d_model, d_inner=d_inner, pad_idx=pad_idx,\n",
    "        with_graph_mat=False, inp_len=0, dropout_rate=dropout_rate, with_emb_mat=False,\n",
    "    ),\n",
    "    EncoderCfg(\n",
    "        n_layers=n_layers, n_heads=n_heads, d_k=d_k, d_v=d_v, d_model=d_model, d_inner=d_inner, pad_idx=pad_idx,\n",
    "        with_graph_mat=False, inp_len=0, dropout_rate=dropout_rate, with_emb_mat=False,\n",
    "    )\n",
    "]\n",
    "\n",
    "cfg_mllm_ranker = MllmRankerCfg(\n",
    "    vocab_encoder=cfg_vocab_enc, encoders=cfgs_enc, decoders=cfgs_dec,\n",
    ")\n",
    "\n",
    "cfg_mllm_ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
