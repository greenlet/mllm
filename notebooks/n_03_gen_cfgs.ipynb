{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import sys\n",
    "from typing import TypeVar\n",
    "\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from pydantic_yaml import to_yaml_file, parse_yaml_file_as\n",
    "from transformers import GPT2Tokenizer, PreTrainedTokenizer\n",
    "\n",
    "from mllm.config.model import create_mllm_encdec_cfg, create_mllm_ranker_cfg, TokenizerCfg, \\\n",
    "    VocabEncoderCfg, EncoderCfg, MllmRankerCfg, EncdecHgCfg, create_encdec_hg_cfg, CustomToken, HgReductType, \\\n",
    "    create_ranker_hg_cfg, DecRankType\n",
    "from mllm.tokenization.chunk_tokenizer import calc_max_inp_size, gen_all_tokens, tokenizer_from_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration generation\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/misha/prog/mllm/mllm/config/cfg')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_dpath = Path(os.path.abspath('.')).parent / 'mllm' / 'config' / 'cfg'\n",
    "cfg_dpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TCfg = TypeVar('TCfg', bound=BaseModel)\n",
    "\n",
    "def save_config_to_yaml(cfg: TCfg, fpath: Path, overwrite: bool = False):\n",
    "    if not fpath.exists() or overwrite:\n",
    "        to_yaml_file(fpath, cfg)\n",
    "    else:\n",
    "        cfg_2 = parse_yaml_file_as(cfg.__class__, fpath)\n",
    "        print(f'File {fpath} already exists. Equal:', cfg == cfg_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkz = GPT2Tokenizer.from_pretrained('gpt2', model_max_length=10000)\n",
    "n_tokens_init = len(tkz)\n",
    "tok_dict = gen_all_tokens(tkz, with_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenizerCfg(name='gpt2', n_tokens_init=50257, model_max_length=10000, custom_tokens={'doc_begin': CustomToken(name='doc_begin', repr='<|doc_begin|>', special=False, ind=50257), 'doc_end': CustomToken(name='doc_end', repr='<|doc_end|>', special=False, ind=50258), 'doc_id_begin': CustomToken(name='doc_id_begin', repr='<|doc_id_begin|>', special=False, ind=50259), 'doc_id_end': CustomToken(name='doc_id_end', repr='<|doc_id_end|>', special=False, ind=50260), 'doc_offset_begin': CustomToken(name='doc_offset_begin', repr='<|doc_offset_begin|>', special=False, ind=50261), 'doc_offset_end': CustomToken(name='doc_offset_end', repr='<|doc_offset_end|>', special=False, ind=50262), 'doc_title_begin': CustomToken(name='doc_title_begin', repr='<|doc_title_begin|>', special=False, ind=50263), 'doc_title_end': CustomToken(name='doc_title_end', repr='<|doc_title_end|>', special=False, ind=50264), 'doc_body_begin': CustomToken(name='doc_body_begin', repr='<|doc_body_begin|>', special=False, ind=50265), 'doc_body_end': CustomToken(name='doc_body_end', repr='<|doc_body_end|>', special=False, ind=50266), 'pad': CustomToken(name='pad', repr='<|pad|>', special=True, ind=50267), 'query_begin': CustomToken(name='query_begin', repr='<|query_begin|>', special=False, ind=50268), 'query_end': CustomToken(name='query_end', repr='<|query_end|>', special=False, ind=50269), 'mask': CustomToken(name='mask', repr='<|mask|>', special=False, ind=50270)})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkz_cfg = TokenizerCfg(name='gpt2', n_tokens_init=n_tokens_init, model_max_length=10000, custom_tokens=tok_dict)\n",
    "tkz_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/misha/prog/mllm/mllm/config/cfg/tokenizer_cfg_01.yaml already exists. Equal: True\n"
     ]
    }
   ],
   "source": [
    "tkz_cfg_fpath = cfg_dpath / 'tokenizer_cfg_01.yaml'\n",
    "save_config_to_yaml(tkz_cfg, tkz_cfg_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens_init = 50257. Tokens: 50271\n"
     ]
    }
   ],
   "source": [
    "print(f'n_tokens_init = {n_tokens_init}. Tokens: {len(tkz)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLLM Encdec and Ranker multi level, multi layer configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer with 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50267\n",
      "GPT2Tokenizer(name_or_path='gpt2', vocab_size=50257, model_max_length=10000, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|pad|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t50257: AddedToken(\"<|doc_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50258: AddedToken(\"<|doc_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50259: AddedToken(\"<|doc_id_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50260: AddedToken(\"<|doc_id_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50261: AddedToken(\"<|doc_offset_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50262: AddedToken(\"<|doc_offset_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50263: AddedToken(\"<|doc_title_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50264: AddedToken(\"<|doc_title_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50265: AddedToken(\"<|doc_body_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50266: AddedToken(\"<|doc_body_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50267: AddedToken(\"<|pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t50268: AddedToken(\"<|query_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50269: AddedToken(\"<|query_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50270: AddedToken(\"<|mask|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "tkz_cfg_fpath = cfg_dpath / 'tokenizer_cfg_01.yaml'\n",
    "tkz_cfg = parse_yaml_file_as(TokenizerCfg, tkz_cfg_fpath)\n",
    "tkz = tokenizer_from_config(tkz_cfg)\n",
    "print(tkz.pad_token_id)\n",
    "print(tkz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_encoder=VocabEncoderCfg(n_vocab=50271, d_word_vec=256, d_model=256, pad_idx=50267, inp_len=100, dropout_rate=0.0) encoders=[EncoderCfg(n_layers=2, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=False), EncoderCfg(n_layers=2, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=True)] decoders=[EmbDecoderCfg(d_emb=256, n_layers=2, n_heads=8, d_hid=1024, seq_len=100, dp_rate=0.0), EmbDecoderCfg(d_emb=256, n_layers=2, n_heads=8, d_hid=1024, seq_len=100, dp_rate=0.0)] with_vocab_decoder=True\n",
      "vocab_encoder=VocabEncoderCfg(n_vocab=50271, d_word_vec=256, d_model=256, pad_idx=50267, inp_len=100, dropout_rate=0.0) encoders=[EncoderCfg(n_layers=2, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=False), EncoderCfg(n_layers=2, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=True)] decoders=[EncoderCfg(n_layers=2, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=False), EncoderCfg(n_layers=2, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=False)]\n"
     ]
    }
   ],
   "source": [
    "n_vocab = len(tkz)\n",
    "seq_len = 100\n",
    "d_word_wec = 256\n",
    "n_heads, d_model, d_inner = 8, 256, 1024\n",
    "dropout_rate = 0.0\n",
    "n_levels = 2\n",
    "enc_n_layers = 2\n",
    "enc_with_graph_mat = False\n",
    "enc_with_emb_mat = False, True\n",
    "dec_n_layers = 2\n",
    "pad_tok = tkz_cfg.custom_tokens['pad'].ind\n",
    "dec_with_vocab_decoder = True\n",
    "\n",
    "encdec_cfg_01 = create_mllm_encdec_cfg(\n",
    "    n_vocab=n_vocab, inp_len=seq_len, d_word_wec=d_word_wec, dropout_rate=dropout_rate, n_levels=n_levels,\n",
    "    enc_n_layers=enc_n_layers, n_heads=n_heads, d_model=d_model, d_inner=d_inner,\n",
    "    enc_with_graph_mat=enc_with_graph_mat, enc_with_emb_mat=enc_with_emb_mat,\n",
    "    dec_n_layers=dec_n_layers, pad_idx=pad_tok, with_vocab_decoder=dec_with_vocab_decoder,\n",
    ")\n",
    "\n",
    "ranker_cfg_01 = create_mllm_ranker_cfg(\n",
    "    n_vocab=n_vocab, inp_len=seq_len, d_word_wec=d_word_wec, dropout_rate=dropout_rate, n_levels=n_levels,\n",
    "    enc_n_layers=enc_n_layers, n_heads=n_heads, d_model=d_model, d_inner=d_inner,\n",
    "    enc_with_graph_mat=enc_with_graph_mat, enc_with_emb_mat=enc_with_emb_mat,\n",
    "    dec_n_layers=dec_n_layers, pad_idx=pad_tok,\n",
    ")\n",
    "\n",
    "print(encdec_cfg_01)\n",
    "print(ranker_cfg_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/misha/prog/mllm/mllm/config/cfg/encdec_model_cfg_01.yaml already exists. Equal: True\n",
      "File /home/misha/prog/mllm/mllm/config/cfg/ranker_model_cfg_01.yaml already exists. Equal: True\n"
     ]
    }
   ],
   "source": [
    "encdec_cfg_01_fpath = cfg_dpath / 'encdec_model_cfg_01.yaml'\n",
    "ranker_cfg_01_fpath = cfg_dpath / 'ranker_model_cfg_01.yaml'\n",
    "overwrite = False\n",
    "# overwrite = True\n",
    "save_config_to_yaml(encdec_cfg_01, encdec_cfg_01_fpath, overwrite)\n",
    "save_config_to_yaml(ranker_cfg_01, ranker_cfg_01_fpath, overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Decoder Hourglass model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50267\n",
      "GPT2Tokenizer(name_or_path='gpt2', vocab_size=50257, model_max_length=10000, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|pad|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t50257: AddedToken(\"<|doc_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50258: AddedToken(\"<|doc_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50259: AddedToken(\"<|doc_id_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50260: AddedToken(\"<|doc_id_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50261: AddedToken(\"<|doc_offset_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50262: AddedToken(\"<|doc_offset_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50263: AddedToken(\"<|doc_title_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50264: AddedToken(\"<|doc_title_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50265: AddedToken(\"<|doc_body_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50266: AddedToken(\"<|doc_body_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50267: AddedToken(\"<|pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t50268: AddedToken(\"<|query_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50269: AddedToken(\"<|query_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50270: AddedToken(\"<|mask|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "tkz_cfg_fpath = cfg_dpath / 'tokenizer_cfg_01.yaml'\n",
    "tkz_cfg = parse_yaml_file_as(TokenizerCfg, tkz_cfg_fpath)\n",
    "tkz = tokenizer_from_config(tkz_cfg)\n",
    "print(tkz.pad_token_id)\n",
    "print(tkz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d_model = 256, d_inner = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dec_pyr': {'d_inner': 1024,\n",
      "             'd_k': 32,\n",
      "             'd_model': 256,\n",
      "             'd_v': 32,\n",
      "             'dropout_rate': 0.0,\n",
      "             'inp_len': 256,\n",
      "             'n_heads': 8,\n",
      "             'n_layers': 8,\n",
      "             'n_similar_layers': 1,\n",
      "             'n_vocab': 50271,\n",
      "             'step': 2},\n",
      " 'enc_pyr': {'d_inner': 1024,\n",
      "             'd_k': 32,\n",
      "             'd_model': 256,\n",
      "             'd_v': 32,\n",
      "             'dropout_rate': 0.0,\n",
      "             'inp_len': 256,\n",
      "             'n_heads': 8,\n",
      "             'n_layers': 8,\n",
      "             'n_similar_layers': 1,\n",
      "             'pad_idx': 50267,\n",
      "             'reduct_type': <HgReductType.Matmul: 'matmul'>,\n",
      "             'step': 2,\n",
      "             'vocab_encoder': {'d_model': 256,\n",
      "                               'd_word_vec': 256,\n",
      "                               'dropout_rate': 0.0,\n",
      "                               'inp_len': 256,\n",
      "                               'n_vocab': 50271,\n",
      "                               'pad_idx': 50267}}}\n"
     ]
    }
   ],
   "source": [
    "cfg_encdec_hg = create_encdec_hg_cfg(\n",
    "    n_vocab=len(tkz), pad_idx=tkz.pad_token_id,\n",
    "    d_model=256, n_heads=8, d_inner=1024, inp_len=256, step=2, dropout_rate=0.0, n_similar_layers=1,\n",
    "    reduct_type=HgReductType.Matmul,\n",
    ")\n",
    "pprint(cfg_encdec_hg.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/misha/prog/mllm/mllm/config/cfg/encdec_hg_cfg_01.yaml already exists. Equal: True\n"
     ]
    }
   ],
   "source": [
    "model_cfg_fpath = cfg_dpath / 'encdec_hg_cfg_01.yaml'\n",
    "print(f'Save {model_cfg_fpath}')\n",
    "save_config_to_yaml(cfg_encdec_hg, model_cfg_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HgReductType.Matmul: 'matmul'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = parse_yaml_file_as(EncdecHgCfg, model_cfg_fpath)\n",
    "cfg.enc_pyr.reduct_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d_model = 512, d_inner = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dec_pyr': {'d_inner': 2048,\n",
      "             'd_k': 64,\n",
      "             'd_model': 512,\n",
      "             'd_v': 64,\n",
      "             'dropout_rate': 0.0,\n",
      "             'inp_len': 128,\n",
      "             'n_heads': 8,\n",
      "             'n_layers': 7,\n",
      "             'n_similar_layers': 1,\n",
      "             'n_vocab': 50271,\n",
      "             'step': 2},\n",
      " 'enc_pyr': {'d_inner': 2048,\n",
      "             'd_k': 64,\n",
      "             'd_model': 512,\n",
      "             'd_v': 64,\n",
      "             'dropout_rate': 0.0,\n",
      "             'inp_len': 128,\n",
      "             'n_heads': 8,\n",
      "             'n_layers': 7,\n",
      "             'n_similar_layers': 1,\n",
      "             'pad_idx': 50267,\n",
      "             'reduct_type': <HgReductType.Matmul: 'matmul'>,\n",
      "             'step': 2,\n",
      "             'vocab_encoder': {'d_model': 512,\n",
      "                               'd_word_vec': 512,\n",
      "                               'dropout_rate': 0.0,\n",
      "                               'inp_len': 128,\n",
      "                               'n_vocab': 50271,\n",
      "                               'pad_idx': 50267}}}\n",
      "Save /home/misha/prog/mllm/mllm/config/cfg/encdec_hg_cfg_02.yaml\n"
     ]
    }
   ],
   "source": [
    "cfg_encdec_hg = create_encdec_hg_cfg(\n",
    "    n_vocab=len(tkz), pad_idx=tkz.pad_token_id,\n",
    "    d_model=512, n_heads=8, d_inner=2048, inp_len=128, step=2, dropout_rate=0.0, n_similar_layers=1,\n",
    "    reduct_type=HgReductType.Matmul,\n",
    ")\n",
    "pprint(cfg_encdec_hg.dict())\n",
    "model_cfg_fpath = cfg_dpath / 'encdec_hg_cfg_02.yaml'\n",
    "print(f'Save {model_cfg_fpath}')\n",
    "save_config_to_yaml(cfg_encdec_hg, model_cfg_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d_model = 768, d_inner = 3072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dec_pyr': {'d_inner': 3072,\n",
      "             'd_k': 64,\n",
      "             'd_model': 768,\n",
      "             'd_v': 64,\n",
      "             'dropout_rate': 0.0,\n",
      "             'enhance_type': <HgEnhanceType.Matmul: 'matmul'>,\n",
      "             'inp_len': 256,\n",
      "             'n_heads': 12,\n",
      "             'n_layers': 8,\n",
      "             'n_similar_layers': 1,\n",
      "             'n_vocab': 50271,\n",
      "             'step': 2},\n",
      " 'enc_pyr': {'d_inner': 3072,\n",
      "             'd_k': 64,\n",
      "             'd_model': 768,\n",
      "             'd_v': 64,\n",
      "             'dropout_rate': 0.0,\n",
      "             'inp_len': 256,\n",
      "             'n_heads': 12,\n",
      "             'n_layers': 8,\n",
      "             'n_similar_layers': 1,\n",
      "             'pad_idx': 50267,\n",
      "             'reduct_type': <HgReductType.Matmul: 'matmul'>,\n",
      "             'step': 2,\n",
      "             'vocab_encoder': {'d_model': 768,\n",
      "                               'd_word_vec': 768,\n",
      "                               'dropout_rate': 0.0,\n",
      "                               'inp_len': 256,\n",
      "                               'n_vocab': 50271,\n",
      "                               'pad_idx': 50267,\n",
      "                               'pos_enc_type': <PosEncType.Num: 'num'>}}}\n",
      "Save /home/misha/prog/mllm/mllm/config/cfg/encdec_hg_cfg_03.yaml\n"
     ]
    }
   ],
   "source": [
    "cfg_encdec_hg = create_encdec_hg_cfg(\n",
    "    n_vocab=len(tkz), pad_idx=tkz.pad_token_id,\n",
    "    d_model=768, n_heads=12, d_inner=3072, inp_len=256, step=2, dropout_rate=0.0, n_similar_layers=1,\n",
    "    reduct_type=HgReductType.Matmul,\n",
    ")\n",
    "pprint(cfg_encdec_hg.dict())\n",
    "model_cfg_fpath = cfg_dpath / 'encdec_hg_cfg_03.yaml'\n",
    "print(f'Save {model_cfg_fpath}')\n",
    "overwrite = True\n",
    "# overwrite = False\n",
    "save_config_to_yaml(cfg_encdec_hg, model_cfg_fpath, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranker Hourglass model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d_model = 256, d_inner = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkz_cfg_fpath = cfg_dpath / 'tokenizer_cfg_01.yaml'\n",
    "tkz_cfg = parse_yaml_file_as(TokenizerCfg, tkz_cfg_fpath)\n",
    "tkz = tokenizer_from_config(tkz_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save /home/misha/prog/mllm/mllm/config/cfg/ranker_hg_cfg_01.yaml\n",
      "File /home/misha/prog/mllm/mllm/config/cfg/ranker_hg_cfg_01.yaml already exists. Equal: True\n"
     ]
    }
   ],
   "source": [
    "ranker_hg_cfg = create_ranker_hg_cfg(n_vocab=len(tkz), pad_idx=tkz.pad_token_id,\n",
    "    d_model=256, n_heads=8, d_inner=1024, inp_len=256, step=2, dropout_rate=0.0, n_similar_layers=1,\n",
    "    reduct_type=HgReductType.Matmul, dec_type=DecRankType.Simple)\n",
    "ranker_hg_cfg_fpath = cfg_dpath / 'ranker_hg_cfg_01.yaml'\n",
    "print(f'Save {ranker_hg_cfg_fpath}')\n",
    "save_config_to_yaml(ranker_hg_cfg, ranker_hg_cfg_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d_model = 512, d_inner = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save /home/misha/prog/mllm/mllm/config/cfg/ranker_hg_cfg_02.yaml\n",
      "File /home/misha/prog/mllm/mllm/config/cfg/ranker_hg_cfg_02.yaml already exists. Equal: True\n"
     ]
    }
   ],
   "source": [
    "encdec_hg_cfg_fpath = cfg_dpath / 'encdec_hg_cfg_02.yaml'\n",
    "ranker_hg_cfg = create_ranker_hg_cfg(n_vocab=len(tkz), pad_idx=tkz.pad_token_id,\n",
    "    d_model=512, n_heads=8, d_inner=2048, inp_len=128, step=2, dropout_rate=0.0, n_similar_layers=1,\n",
    "    reduct_type=HgReductType.Matmul, dec_type=DecRankType.Simple)\n",
    "ranker_hg_cfg_fpath = cfg_dpath / 'ranker_hg_cfg_02.yaml'\n",
    "print(f'Save {ranker_hg_cfg_fpath}')\n",
    "save_config_to_yaml(ranker_hg_cfg, ranker_hg_cfg_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
