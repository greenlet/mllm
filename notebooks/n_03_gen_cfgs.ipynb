{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misha/miniconda3/envs/mllm/lib/python3.10/site-packages/torchtext/datasets/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/misha/miniconda3/envs/mllm/lib/python3.10/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import sys\n",
    "from typing import TypeVar\n",
    "\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from pydantic_yaml import to_yaml_file, parse_yaml_file_as\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, PreTrainedTokenizer, BertModel, BertConfig, AutoTokenizer\n",
    "\n",
    "from mllm.config.model import create_mllm_encdec_cfg, create_mllm_ranker_cfg, TokenizerCfg, \\\n",
    "    VocabEncoderCfg, EncoderCfg, MllmRankerCfg, EncdecHgCfg, create_encdec_hg_cfg, CustomToken, HgReductType, \\\n",
    "    create_ranker_hg_cfg,PosEncType, create_encdec_bert_cfg, BertEmbType, HgEnhanceType, create_ranker_bert_cfg, \\\n",
    "    create_encdecrnk_bert_cfg, create_encmix_bert_cfg, EncmixOutEmbsType, create_genmix_bert_cfg\n",
    "from mllm.tokenization.chunk_tokenizer import calc_max_inp_size, gen_all_tokens, tokenizer_from_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration generation\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/misha/prog/mllm/mllm/config/cfg')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_dpath = Path(os.path.abspath('.')).parent / 'mllm' / 'config' / 'cfg'\n",
    "cfg_dpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TCfg = TypeVar('TCfg', bound=BaseModel)\n",
    "\n",
    "def save_config_to_yaml(cfg: TCfg, fpath: Path, overwrite: bool = False):\n",
    "    if not fpath.exists() or overwrite:\n",
    "        to_yaml_file(fpath, cfg)\n",
    "    else:\n",
    "        cfg_2 = parse_yaml_file_as(cfg.__class__, fpath)\n",
    "        print(f'File {fpath} already exists. Equal:', cfg == cfg_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkz = GPT2Tokenizer.from_pretrained('gpt2', model_max_length=10000)\n",
    "n_tokens_init = len(tkz)\n",
    "tok_dict = gen_all_tokens(tkz, with_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_token_id: 50267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TokenizerCfg(name='gpt2', n_tokens_init=50257, model_max_length=10000, custom_tokens={'doc_begin': CustomToken(name='doc_begin', repr='<|doc_begin|>', special=False, ind=50257), 'doc_end': CustomToken(name='doc_end', repr='<|doc_end|>', special=False, ind=50258), 'doc_id_begin': CustomToken(name='doc_id_begin', repr='<|doc_id_begin|>', special=False, ind=50259), 'doc_id_end': CustomToken(name='doc_id_end', repr='<|doc_id_end|>', special=False, ind=50260), 'doc_offset_begin': CustomToken(name='doc_offset_begin', repr='<|doc_offset_begin|>', special=False, ind=50261), 'doc_offset_end': CustomToken(name='doc_offset_end', repr='<|doc_offset_end|>', special=False, ind=50262), 'doc_title_begin': CustomToken(name='doc_title_begin', repr='<|doc_title_begin|>', special=False, ind=50263), 'doc_title_end': CustomToken(name='doc_title_end', repr='<|doc_title_end|>', special=False, ind=50264), 'doc_body_begin': CustomToken(name='doc_body_begin', repr='<|doc_body_begin|>', special=False, ind=50265), 'doc_body_end': CustomToken(name='doc_body_end', repr='<|doc_body_end|>', special=False, ind=50266), 'pad': CustomToken(name='pad', repr='<|pad|>', special=True, ind=50267), 'query_begin': CustomToken(name='query_begin', repr='<|query_begin|>', special=False, ind=50268), 'query_end': CustomToken(name='query_end', repr='<|query_end|>', special=False, ind=50269), 'mask': CustomToken(name='mask', repr='<|mask|>', special=False, ind=50270)})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkz_cfg = TokenizerCfg(name='gpt2', n_tokens_init=n_tokens_init, model_max_length=10000, custom_tokens=tok_dict)\n",
    "print(f'pad_token_id: {tkz.pad_token_id}')\n",
    "tkz_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/misha/prog/mllm/mllm/config/cfg/tokenizer_cfg_01.yaml already exists. Equal: True\n"
     ]
    }
   ],
   "source": [
    "tkz_cfg_fpath = cfg_dpath / 'tokenizer_cfg_01.yaml'\n",
    "save_config_to_yaml(tkz_cfg, tkz_cfg_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens_init = 50257. Tokens: 50271\n"
     ]
    }
   ],
   "source": [
    "print(f'n_tokens_init = {n_tokens_init}. Tokens: {len(tkz)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLLM Encdec and Ranker multi level, multi layer configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer with 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50267\n",
      "GPT2Tokenizer(name_or_path='gpt2', vocab_size=50257, model_max_length=10000, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|pad|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t50257: AddedToken(\"<|doc_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50258: AddedToken(\"<|doc_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50259: AddedToken(\"<|doc_id_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50260: AddedToken(\"<|doc_id_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50261: AddedToken(\"<|doc_offset_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50262: AddedToken(\"<|doc_offset_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50263: AddedToken(\"<|doc_title_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50264: AddedToken(\"<|doc_title_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50265: AddedToken(\"<|doc_body_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50266: AddedToken(\"<|doc_body_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50267: AddedToken(\"<|pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t50268: AddedToken(\"<|query_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50269: AddedToken(\"<|query_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50270: AddedToken(\"<|mask|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "tkz_cfg_fpath = cfg_dpath / 'tokenizer_cfg_01.yaml'\n",
    "tkz_cfg = parse_yaml_file_as(TokenizerCfg, tkz_cfg_fpath)\n",
    "tkz = tokenizer_from_config(tkz_cfg)\n",
    "print(tkz.pad_token_id)\n",
    "print(tkz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_encoder=VocabEncoderCfg(n_vocab=50271, d_word_vec=256, d_model=256, pad_idx=50267, inp_len=100, dropout_rate=0.0) encoders=[EncoderCfg(n_layers=2, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=False), EncoderCfg(n_layers=2, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=True)] decoders=[EmbDecoderCfg(d_emb=256, n_layers=2, n_heads=8, d_hid=1024, seq_len=100, dp_rate=0.0), EmbDecoderCfg(d_emb=256, n_layers=2, n_heads=8, d_hid=1024, seq_len=100, dp_rate=0.0)] with_vocab_decoder=True\n",
      "vocab_encoder=VocabEncoderCfg(n_vocab=50271, d_word_vec=256, d_model=256, pad_idx=50267, inp_len=100, dropout_rate=0.0) encoders=[EncoderCfg(n_layers=2, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=False), EncoderCfg(n_layers=2, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=True)] decoders=[EncoderCfg(n_layers=2, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=False), EncoderCfg(n_layers=2, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=False)]\n"
     ]
    }
   ],
   "source": [
    "n_vocab = len(tkz)\n",
    "seq_len = 100\n",
    "d_word_wec = 256\n",
    "n_heads, d_model, d_inner = 8, 256, 1024\n",
    "dropout_rate = 0.0\n",
    "n_levels = 2\n",
    "enc_n_layers = 2\n",
    "enc_with_graph_mat = False\n",
    "enc_with_emb_mat = False, True\n",
    "dec_n_layers = 2\n",
    "pad_tok = tkz_cfg.custom_tokens['pad'].ind\n",
    "dec_with_vocab_decoder = True\n",
    "\n",
    "encdec_cfg_01 = create_mllm_encdec_cfg(\n",
    "    n_vocab=n_vocab, inp_len=seq_len, d_word_wec=d_word_wec, dropout_rate=dropout_rate, n_levels=n_levels,\n",
    "    enc_n_layers=enc_n_layers, n_heads=n_heads, d_model=d_model, d_inner=d_inner,\n",
    "    enc_with_graph_mat=enc_with_graph_mat, enc_with_emb_mat=enc_with_emb_mat,\n",
    "    dec_n_layers=dec_n_layers, pad_idx=pad_tok, with_vocab_decoder=dec_with_vocab_decoder,\n",
    ")\n",
    "\n",
    "ranker_cfg_01 = create_mllm_ranker_cfg(\n",
    "    n_vocab=n_vocab, inp_len=seq_len, d_word_wec=d_word_wec, dropout_rate=dropout_rate, n_levels=n_levels,\n",
    "    enc_n_layers=enc_n_layers, n_heads=n_heads, d_model=d_model, d_inner=d_inner,\n",
    "    enc_with_graph_mat=enc_with_graph_mat, enc_with_emb_mat=enc_with_emb_mat,\n",
    "    dec_n_layers=dec_n_layers, pad_idx=pad_tok,\n",
    ")\n",
    "\n",
    "print(encdec_cfg_01)\n",
    "print(ranker_cfg_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/misha/prog/mllm/mllm/config/cfg/encdec_model_cfg_01.yaml already exists. Equal: True\n",
      "File /home/misha/prog/mllm/mllm/config/cfg/ranker_model_cfg_01.yaml already exists. Equal: True\n"
     ]
    }
   ],
   "source": [
    "encdec_cfg_01_fpath = cfg_dpath / 'encdec_model_cfg_01.yaml'\n",
    "ranker_cfg_01_fpath = cfg_dpath / 'ranker_model_cfg_01.yaml'\n",
    "overwrite = False\n",
    "# overwrite = True\n",
    "save_config_to_yaml(encdec_cfg_01, encdec_cfg_01_fpath, overwrite)\n",
    "save_config_to_yaml(ranker_cfg_01, ranker_cfg_01_fpath, overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Decoder Hourglass model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50267\n",
      "GPT2Tokenizer(name_or_path='gpt2', vocab_size=50257, model_max_length=10000, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|pad|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t50257: AddedToken(\"<|doc_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50258: AddedToken(\"<|doc_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50259: AddedToken(\"<|doc_id_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50260: AddedToken(\"<|doc_id_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50261: AddedToken(\"<|doc_offset_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50262: AddedToken(\"<|doc_offset_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50263: AddedToken(\"<|doc_title_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50264: AddedToken(\"<|doc_title_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50265: AddedToken(\"<|doc_body_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50266: AddedToken(\"<|doc_body_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50267: AddedToken(\"<|pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t50268: AddedToken(\"<|query_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50269: AddedToken(\"<|query_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50270: AddedToken(\"<|mask|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "tkz_cfg_fpath = cfg_dpath / 'tokenizer_cfg_01.yaml'\n",
    "tkz_cfg = parse_yaml_file_as(TokenizerCfg, tkz_cfg_fpath)\n",
    "tkz = tokenizer_from_config(tkz_cfg)\n",
    "print(tkz.pad_token_id)\n",
    "print(tkz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EncdecHg d_model = 256, d_inner = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dec_pyr': {'d_inner': 1024,\n",
      "             'd_k': 32,\n",
      "             'd_model': 256,\n",
      "             'd_v': 32,\n",
      "             'dropout_rate': 0.0,\n",
      "             'inp_len': 256,\n",
      "             'n_heads': 8,\n",
      "             'n_layers': 8,\n",
      "             'n_similar_layers': 1,\n",
      "             'n_vocab': 50271,\n",
      "             'step': 2},\n",
      " 'enc_pyr': {'d_inner': 1024,\n",
      "             'd_k': 32,\n",
      "             'd_model': 256,\n",
      "             'd_v': 32,\n",
      "             'dropout_rate': 0.0,\n",
      "             'inp_len': 256,\n",
      "             'n_heads': 8,\n",
      "             'n_layers': 8,\n",
      "             'n_similar_layers': 1,\n",
      "             'pad_idx': 50267,\n",
      "             'reduct_type': <HgReductType.Matmul: 'matmul'>,\n",
      "             'step': 2,\n",
      "             'vocab_encoder': {'d_model': 256,\n",
      "                               'd_word_vec': 256,\n",
      "                               'dropout_rate': 0.0,\n",
      "                               'inp_len': 256,\n",
      "                               'n_vocab': 50271,\n",
      "                               'pad_idx': 50267}}}\n"
     ]
    }
   ],
   "source": [
    "cfg_encdec_hg = create_encdec_hg_cfg(\n",
    "    n_vocab=len(tkz), pad_idx=tkz.pad_token_id,\n",
    "    d_model=256, n_heads=8, d_inner=1024, inp_len=256, step=2, dropout_rate=0.0, n_similar_layers=1,\n",
    "    reduct_type=HgReductType.Matmul,\n",
    ")\n",
    "pprint(cfg_encdec_hg.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/misha/prog/mllm/mllm/config/cfg/encdec_hg_cfg_01.yaml already exists. Equal: True\n"
     ]
    }
   ],
   "source": [
    "model_cfg_fpath = cfg_dpath / 'encdec_hg_cfg_01.yaml'\n",
    "print(f'Save {model_cfg_fpath}')\n",
    "save_config_to_yaml(cfg_encdec_hg, model_cfg_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HgReductType.Matmul: 'matmul'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = parse_yaml_file_as(EncdecHgCfg, model_cfg_fpath)\n",
    "cfg.enc_pyr.reduct_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EncdecHg d_model = 512, d_inner = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dec_pyr': {'d_inner': 2048,\n",
      "             'd_k': 64,\n",
      "             'd_model': 512,\n",
      "             'd_v': 64,\n",
      "             'dropout_rate': 0.0,\n",
      "             'inp_len': 128,\n",
      "             'n_heads': 8,\n",
      "             'n_layers': 7,\n",
      "             'n_similar_layers': 1,\n",
      "             'n_vocab': 50271,\n",
      "             'step': 2},\n",
      " 'enc_pyr': {'d_inner': 2048,\n",
      "             'd_k': 64,\n",
      "             'd_model': 512,\n",
      "             'd_v': 64,\n",
      "             'dropout_rate': 0.0,\n",
      "             'inp_len': 128,\n",
      "             'n_heads': 8,\n",
      "             'n_layers': 7,\n",
      "             'n_similar_layers': 1,\n",
      "             'pad_idx': 50267,\n",
      "             'reduct_type': <HgReductType.Matmul: 'matmul'>,\n",
      "             'step': 2,\n",
      "             'vocab_encoder': {'d_model': 512,\n",
      "                               'd_word_vec': 512,\n",
      "                               'dropout_rate': 0.0,\n",
      "                               'inp_len': 128,\n",
      "                               'n_vocab': 50271,\n",
      "                               'pad_idx': 50267}}}\n",
      "Save /home/misha/prog/mllm/mllm/config/cfg/encdec_hg_cfg_02.yaml\n"
     ]
    }
   ],
   "source": [
    "cfg_encdec_hg = create_encdec_hg_cfg(\n",
    "    n_vocab=len(tkz), pad_idx=tkz.pad_token_id,\n",
    "    d_model=512, n_heads=8, d_inner=2048, inp_len=128, step=2, dropout_rate=0.0, n_similar_layers=1,\n",
    "    reduct_type=HgReductType.Matmul,\n",
    ")\n",
    "pprint(cfg_encdec_hg.dict())\n",
    "model_cfg_fpath = cfg_dpath / 'encdec_hg_cfg_02.yaml'\n",
    "print(f'Save {model_cfg_fpath}')\n",
    "save_config_to_yaml(cfg_encdec_hg, model_cfg_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EncdecHg d_model = 768, d_inner = 3072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dec_pyr': {'d_inner': 3072,\n",
      "             'd_k': 64,\n",
      "             'd_model': 768,\n",
      "             'd_v': 64,\n",
      "             'dropout_rate': 0.0,\n",
      "             'enhance_type': <HgEnhanceType.Matmul: 'matmul'>,\n",
      "             'inp_len': 256,\n",
      "             'n_heads': 12,\n",
      "             'n_layers': 8,\n",
      "             'n_similar_layers': 1,\n",
      "             'n_vocab': 50271,\n",
      "             'step': 2},\n",
      " 'enc_pyr': {'d_inner': 3072,\n",
      "             'd_k': 64,\n",
      "             'd_model': 768,\n",
      "             'd_v': 64,\n",
      "             'dropout_rate': 0.0,\n",
      "             'inp_len': 256,\n",
      "             'n_heads': 12,\n",
      "             'n_layers': 8,\n",
      "             'n_similar_layers': 1,\n",
      "             'pad_idx': 50267,\n",
      "             'reduct_type': <HgReductType.Matmul: 'matmul'>,\n",
      "             'step': 2,\n",
      "             'vocab_encoder': {'d_model': 768,\n",
      "                               'd_word_vec': 768,\n",
      "                               'dropout_rate': 0.0,\n",
      "                               'inp_len': 256,\n",
      "                               'n_vocab': 50271,\n",
      "                               'pad_idx': 50267,\n",
      "                               'pos_enc_type': <PosEncType.Num: 'num'>}}}\n",
      "Save /home/misha/prog/mllm/mllm/config/cfg/encdec_hg_cfg_03.yaml\n"
     ]
    }
   ],
   "source": [
    "cfg_encdec_hg = create_encdec_hg_cfg(\n",
    "    n_vocab=len(tkz), pad_idx=tkz.pad_token_id,\n",
    "    d_model=768, n_heads=12, d_inner=3072, inp_len=256, step=2, dropout_rate=0.0, n_similar_layers=1,\n",
    "    reduct_type=HgReductType.Matmul,\n",
    ")\n",
    "pprint(cfg_encdec_hg.dict())\n",
    "model_cfg_fpath = cfg_dpath / 'encdec_hg_cfg_03.yaml'\n",
    "print(f'Save {model_cfg_fpath}')\n",
    "overwrite = True\n",
    "# overwrite = False\n",
    "save_config_to_yaml(cfg_encdec_hg, model_cfg_fpath, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranker Hourglass model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RankerHg d_model = 256, d_inner = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkz_cfg_fpath = cfg_dpath / 'tokenizer_cfg_01.yaml'\n",
    "tkz_cfg = parse_yaml_file_as(TokenizerCfg, tkz_cfg_fpath)\n",
    "tkz = tokenizer_from_config(tkz_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save /home/misha/prog/mllm/mllm/config/cfg/ranker_hg_cfg_01.yaml\n"
     ]
    }
   ],
   "source": [
    "d_model = 256\n",
    "ranker_hg_cfg = create_ranker_hg_cfg(n_vocab=len(tkz), pad_idx=tkz.pad_token_id,\n",
    "    d_model=d_model, n_heads=8, d_inner=1024, inp_len=256, step=2, dropout_rate=0.0, n_similar_layers=1,\n",
    "    reduct_type=HgReductType.Matmul, pos_enc_type=PosEncType.Emb, dec_mlp_layers=f'{d_model}', temperature=0,\n",
    ")\n",
    "ranker_hg_cfg_fpath = cfg_dpath / 'ranker_hg_cfg_01.yaml'\n",
    "print(f'Save {ranker_hg_cfg_fpath}')\n",
    "overwrite = True\n",
    "# overwrite = False\n",
    "save_config_to_yaml(ranker_hg_cfg, ranker_hg_cfg_fpath, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RankerHg d_model = 512, d_inner = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save /home/misha/prog/mllm/mllm/config/cfg/ranker_hg_cfg_02.yaml\n"
     ]
    }
   ],
   "source": [
    "d_model = 512\n",
    "ranker_hg_cfg = create_ranker_hg_cfg(n_vocab=len(tkz), pad_idx=tkz.pad_token_id,\n",
    "    d_model=d_model, n_heads=8, d_inner=2048, inp_len=256, step=2, dropout_rate=0.0, n_similar_layers=1,\n",
    "    reduct_type=HgReductType.Matmul, pos_enc_type=PosEncType.Emb, dec_mlp_layers=f'{d_model}', temperature=0,\n",
    ")\n",
    "ranker_hg_cfg_fpath = cfg_dpath / 'ranker_hg_cfg_02.yaml'\n",
    "print(f'Save {ranker_hg_cfg_fpath}')\n",
    "overwrite = True\n",
    "# overwrite = False\n",
    "save_config_to_yaml(ranker_hg_cfg, ranker_hg_cfg_fpath, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RankerHg d_model = 768, d_inner = 3072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save /home/misha/prog/mllm/mllm/config/cfg/ranker_hg_cfg_03.yaml\n"
     ]
    }
   ],
   "source": [
    "d_model = 768\n",
    "ranker_hg_cfg = create_ranker_hg_cfg(n_vocab=len(tkz), pad_idx=tkz.pad_token_id,\n",
    "    d_model=d_model, n_heads=12, d_inner=3072, inp_len=256, step=2, dropout_rate=0.0, n_similar_layers=1,\n",
    "    reduct_type=HgReductType.Matmul, pos_enc_type=PosEncType.Emb, dec_mlp_layers=f'{d_model}', temperature=0,\n",
    ")\n",
    "ranker_hg_cfg_fpath = cfg_dpath / 'ranker_hg_cfg_03.yaml'\n",
    "print(f'Save {ranker_hg_cfg_fpath}')\n",
    "overwrite = True\n",
    "# overwrite = False\n",
    "save_config_to_yaml(ranker_hg_cfg, ranker_hg_cfg_fpath, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Decoder Bert model\n",
    "#### EncdecBert bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save /home/misha/prog/mllm/mllm/config/cfg/encdec_bert_cfg_01.yaml\n"
     ]
    }
   ],
   "source": [
    "encdec_bert_cfg = create_encdec_bert_cfg(\n",
    "    pretrained_model_name='bert-base-uncased', tokenizer_name='', emb_type=BertEmbType.Cls,\n",
    "    inp_len=128, dec_enhance_type=HgEnhanceType.Matmul,\n",
    "    dec_n_layers=7, dec_n_similar_layers=1, dec_dropout_rate=0.0, dec_temperature=0,\n",
    ")\n",
    "encdec_bert_cfg_fpath = cfg_dpath / 'encdec_bert_cfg_01.yaml'\n",
    "print(f'Save {encdec_bert_cfg_fpath}')\n",
    "overwrite = True\n",
    "# overwrite = False\n",
    "save_config_to_yaml(encdec_bert_cfg, encdec_bert_cfg_fpath, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranker Bert model\n",
    "#### RankerBert bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save /home/misha/prog/mllm/mllm/config/cfg/ranker_bert_cfg_01.yaml\n"
     ]
    }
   ],
   "source": [
    "ranker_bert_cfg = create_ranker_bert_cfg(\n",
    "    pretrained_model_name='bert-base-uncased', tokenizer_name='', emb_type=BertEmbType.Cls,\n",
    "    inp_len=128, dec_mlp_layers='',\n",
    ")\n",
    "ranker_bert_cfg_fpath = cfg_dpath / 'ranker_bert_cfg_01.yaml'\n",
    "print(f'Save {ranker_bert_cfg_fpath}')\n",
    "overwrite = True\n",
    "# overwrite = False\n",
    "save_config_to_yaml(ranker_bert_cfg, ranker_bert_cfg_fpath, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Decoder Ranker Bert model\n",
    "#### Add custom special token (experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = 'bert-base-uncased'\n",
    "tkz = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "tkz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30523,\n",
       " BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]', 'additional_special_tokens': ['[RNK]']}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       " \t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t30522: AddedToken(\"[RNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " })"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkz.add_special_tokens({\n",
    "    'additional_special_tokens': ['[RNK]']\n",
    "})\n",
    "len(tkz), tkz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.38.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained(pretrained_model_name, torch_dtype=torch.float32)\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"bert-base-uncased\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.38.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30523\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tkz))\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[RNK]'], [30522])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkz.additional_special_tokens, tkz.additional_special_tokens_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2745, 4027, 102] [101, 30522, 2745, 4027, 102]\n"
     ]
    }
   ],
   "source": [
    "print(tkz('Michael Jackson')['input_ids'], tkz('[RNK] Michael Jackson')['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EncdecRankBert bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save /Users/misha/prog/mllm/mllm/config/cfg/encdecrnk_bert_cfg_01.yaml\n"
     ]
    }
   ],
   "source": [
    "encdecrnk_bert_cfg = create_encdecrnk_bert_cfg(\n",
    "    pretrained_model_name='bert-base-uncased', tokenizer_name='', emb_type=BertEmbType.Cls,\n",
    "    inp_len=128, dec_pyr_enhance_type=HgEnhanceType.Matmul,\n",
    "    dec_pyr_n_layers=7, dec_pyr_n_similar_layers=1, dec_pyr_dropout_rate=0.0, dec_pyr_temperature=0,\n",
    "    dec_rank_mlp_layers='',\n",
    ")\n",
    "encdecrnk_bert_cfg_fpath = cfg_dpath / 'encdecrnk_bert_cfg_01.yaml'\n",
    "print(f'Save {encdecrnk_bert_cfg_fpath}')\n",
    "overwrite = True\n",
    "# overwrite = False\n",
    "save_config_to_yaml(encdecrnk_bert_cfg, encdecrnk_bert_cfg_fpath, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tok False\n",
      "TOK False\n",
      "[T False\n",
      "TT] False\n",
      "[tok] False\n",
      "[ABC] True\n",
      "[A] True\n",
      "[] False\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "SPEC_TOK_PAT = re.compile(r'^\\[[A-Z]+]$')\n",
    "for t in ['tok', 'TOK', '[T', 'TT]', '[tok]', '[ABC]', '[A]', '[]']:\n",
    "    matched =  SPEC_TOK_PAT.match(t) is not None\n",
    "    print(t, matched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Mixed Bert model\n",
    "#### EncmixBert bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save /home/misha/prog/mllm/mllm/config/cfg/encmix_bert_cfg_01_base.yaml\n"
     ]
    }
   ],
   "source": [
    "encmix_bert_cfg = create_encmix_bert_cfg(\n",
    "    pretrained_model_name='bert-base-uncased', tokenizer_name='', inp_len=128,\n",
    "    out_embs_type=EncmixOutEmbsType.Inp, token_types_for_embs=False,\n",
    ")\n",
    "encmix_bert_cfg_fpath = cfg_dpath / 'encmix_bert_cfg_01_base.yaml'\n",
    "print(f'Save {encmix_bert_cfg_fpath}')\n",
    "overwrite = True\n",
    "# overwrite = False\n",
    "save_config_to_yaml(encmix_bert_cfg, encmix_bert_cfg_fpath, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EncmixBert bert-large-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save /home/misha/prog/mllm/mllm/config/cfg/encmix_bert_cfg_02_large.yaml\n"
     ]
    }
   ],
   "source": [
    "encmix_bert_cfg = create_encmix_bert_cfg(\n",
    "    pretrained_model_name='bert-large-uncased', tokenizer_name='', inp_len=128,\n",
    "    out_embs_type=EncmixOutEmbsType.Inp, token_types_for_embs=False,\n",
    ")\n",
    "encmix_bert_cfg_fpath = cfg_dpath / 'encmix_bert_cfg_02_large.yaml'\n",
    "print(f'Save {encmix_bert_cfg_fpath}')\n",
    "overwrite = True\n",
    "# overwrite = False\n",
    "save_config_to_yaml(encmix_bert_cfg, encmix_bert_cfg_fpath, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EncmixBert bert-base-uncased with 3 token types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save /home/misha/prog/mllm/mllm/config/cfg/encmix_bert_cfg_03_base_tte.yaml\n"
     ]
    }
   ],
   "source": [
    "encmix_bert_cfg = create_encmix_bert_cfg(\n",
    "    pretrained_model_name='bert-base-uncased', tokenizer_name='', inp_len=128,\n",
    "    out_embs_type=EncmixOutEmbsType.Inp, token_types_for_embs=True,\n",
    ")\n",
    "encmix_bert_cfg_fpath = cfg_dpath / 'encmix_bert_cfg_03_base_tte.yaml'\n",
    "print(f'Save {encmix_bert_cfg_fpath}')\n",
    "overwrite = True\n",
    "# overwrite = False\n",
    "save_config_to_yaml(encmix_bert_cfg, encmix_bert_cfg_fpath, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkz = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "tkz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 4931, 4931, 2129, 2024, 2017, 102], [101, 3116, 102, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 0, 0, 0, 0]], 'special_tokens_mask': [[1, 0, 0, 0, 0, 0, 1], [1, 0, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkz(['hey hey how are you', 'meeting'], padding=True, return_attention_mask=True, return_special_tokens_mask=True, return_token_type_ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] huggingface is based in nyc [SEP] where is huggingface based? [SEP]\n"
     ]
    }
   ],
   "source": [
    "sequence_a = \"HuggingFace is based in NYC\"\n",
    "sequence_b = \"Where is HuggingFace based?\"\n",
    "encoded_dict = tkz(sequence_a, sequence_b)\n",
    "decoded = tkz.decode(encoded_dict[\"input_ids\"])\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 17662, 12172, 2003, 2241, 1999, 16392, 102, 2073, 2003, 17662, 12172, 2241, 1029, 102]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_dict['input_ids'])\n",
    "print(encoded_dict['token_type_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EncoderDecoder Mixed Bert model\n",
    "#### GenmixBert bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save /home/misha/prog/mllm/mllm/config/cfg/genmix_bert_cfg_01_base_tte.yaml\n"
     ]
    }
   ],
   "source": [
    "genmix_bert_cfg = create_genmix_bert_cfg(\n",
    "    pretrained_model_name='bert-base-uncased', tokenizer_name='', inp_len=128, max_inp_chunks=10, max_out_toks=128,\n",
    ")\n",
    "genmix_bert_cfg_fpath = cfg_dpath / 'genmix_bert_cfg_01_base_tte.yaml'\n",
    "print(f'Save {genmix_bert_cfg_fpath}')\n",
    "overwrite = True\n",
    "# overwrite = False\n",
    "save_config_to_yaml(genmix_bert_cfg, genmix_bert_cfg_fpath, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EncoderDecoder Attention2 Bert model\n",
    "#### EncAt2Dec config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import yaml\n",
    "\n",
    "from mllm.model.encoder_at2_decoder_bert import EncoderAt2DecoderConfig\n",
    "from mllm.model.encoder_at2_decoder_cont import EncAt2DecCfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type bert-at2-generation. This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type bert to instantiate a model of type bert-at2-generation. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of BertGenerationAt2Decoder were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.0.dec_at2.key.bias', 'bert.encoder.layer.0.dec_at2.key.weight', 'bert.encoder.layer.0.dec_at2.query.bias', 'bert.encoder.layer.0.dec_at2.query.weight', 'bert.encoder.layer.0.dec_at2.value.bias', 'bert.encoder.layer.0.dec_at2.value.weight', 'bert.encoder.layer.0.enc_at2.key.bias', 'bert.encoder.layer.0.enc_at2.key.weight', 'bert.encoder.layer.0.enc_at2.query.bias', 'bert.encoder.layer.0.enc_at2.query.weight', 'bert.encoder.layer.0.enc_at2.value.bias', 'bert.encoder.layer.0.enc_at2.value.weight', 'bert.encoder.layer.0.last_dec_to_all_enc_at2.key.bias', 'bert.encoder.layer.0.last_dec_to_all_enc_at2.key.weight', 'bert.encoder.layer.0.last_dec_to_all_enc_at2.query.bias', 'bert.encoder.layer.0.last_dec_to_all_enc_at2.query.weight', 'bert.encoder.layer.0.last_dec_to_all_enc_at2.value.bias', 'bert.encoder.layer.0.last_dec_to_all_enc_at2.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.1.dec_at2.key.bias', 'bert.encoder.layer.1.dec_at2.key.weight', 'bert.encoder.layer.1.dec_at2.query.bias', 'bert.encoder.layer.1.dec_at2.query.weight', 'bert.encoder.layer.1.dec_at2.value.bias', 'bert.encoder.layer.1.dec_at2.value.weight', 'bert.encoder.layer.1.enc_at2.key.bias', 'bert.encoder.layer.1.enc_at2.key.weight', 'bert.encoder.layer.1.enc_at2.query.bias', 'bert.encoder.layer.1.enc_at2.query.weight', 'bert.encoder.layer.1.enc_at2.value.bias', 'bert.encoder.layer.1.enc_at2.value.weight', 'bert.encoder.layer.1.last_dec_to_all_enc_at2.key.bias', 'bert.encoder.layer.1.last_dec_to_all_enc_at2.key.weight', 'bert.encoder.layer.1.last_dec_to_all_enc_at2.query.bias', 'bert.encoder.layer.1.last_dec_to_all_enc_at2.query.weight', 'bert.encoder.layer.1.last_dec_to_all_enc_at2.value.bias', 'bert.encoder.layer.1.last_dec_to_all_enc_at2.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.10.dec_at2.key.bias', 'bert.encoder.layer.10.dec_at2.key.weight', 'bert.encoder.layer.10.dec_at2.query.bias', 'bert.encoder.layer.10.dec_at2.query.weight', 'bert.encoder.layer.10.dec_at2.value.bias', 'bert.encoder.layer.10.dec_at2.value.weight', 'bert.encoder.layer.10.enc_at2.key.bias', 'bert.encoder.layer.10.enc_at2.key.weight', 'bert.encoder.layer.10.enc_at2.query.bias', 'bert.encoder.layer.10.enc_at2.query.weight', 'bert.encoder.layer.10.enc_at2.value.bias', 'bert.encoder.layer.10.enc_at2.value.weight', 'bert.encoder.layer.10.last_dec_to_all_enc_at2.key.bias', 'bert.encoder.layer.10.last_dec_to_all_enc_at2.key.weight', 'bert.encoder.layer.10.last_dec_to_all_enc_at2.query.bias', 'bert.encoder.layer.10.last_dec_to_all_enc_at2.query.weight', 'bert.encoder.layer.10.last_dec_to_all_enc_at2.value.bias', 'bert.encoder.layer.10.last_dec_to_all_enc_at2.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.11.dec_at2.key.bias', 'bert.encoder.layer.11.dec_at2.key.weight', 'bert.encoder.layer.11.dec_at2.query.bias', 'bert.encoder.layer.11.dec_at2.query.weight', 'bert.encoder.layer.11.dec_at2.value.bias', 'bert.encoder.layer.11.dec_at2.value.weight', 'bert.encoder.layer.11.enc_at2.key.bias', 'bert.encoder.layer.11.enc_at2.key.weight', 'bert.encoder.layer.11.enc_at2.query.bias', 'bert.encoder.layer.11.enc_at2.query.weight', 'bert.encoder.layer.11.enc_at2.value.bias', 'bert.encoder.layer.11.enc_at2.value.weight', 'bert.encoder.layer.11.last_dec_to_all_enc_at2.key.bias', 'bert.encoder.layer.11.last_dec_to_all_enc_at2.key.weight', 'bert.encoder.layer.11.last_dec_to_all_enc_at2.query.bias', 'bert.encoder.layer.11.last_dec_to_all_enc_at2.query.weight', 'bert.encoder.layer.11.last_dec_to_all_enc_at2.value.bias', 'bert.encoder.layer.11.last_dec_to_all_enc_at2.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.2.dec_at2.key.bias', 'bert.encoder.layer.2.dec_at2.key.weight', 'bert.encoder.layer.2.dec_at2.query.bias', 'bert.encoder.layer.2.dec_at2.query.weight', 'bert.encoder.layer.2.dec_at2.value.bias', 'bert.encoder.layer.2.dec_at2.value.weight', 'bert.encoder.layer.2.enc_at2.key.bias', 'bert.encoder.layer.2.enc_at2.key.weight', 'bert.encoder.layer.2.enc_at2.query.bias', 'bert.encoder.layer.2.enc_at2.query.weight', 'bert.encoder.layer.2.enc_at2.value.bias', 'bert.encoder.layer.2.enc_at2.value.weight', 'bert.encoder.layer.2.last_dec_to_all_enc_at2.key.bias', 'bert.encoder.layer.2.last_dec_to_all_enc_at2.key.weight', 'bert.encoder.layer.2.last_dec_to_all_enc_at2.query.bias', 'bert.encoder.layer.2.last_dec_to_all_enc_at2.query.weight', 'bert.encoder.layer.2.last_dec_to_all_enc_at2.value.bias', 'bert.encoder.layer.2.last_dec_to_all_enc_at2.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.3.dec_at2.key.bias', 'bert.encoder.layer.3.dec_at2.key.weight', 'bert.encoder.layer.3.dec_at2.query.bias', 'bert.encoder.layer.3.dec_at2.query.weight', 'bert.encoder.layer.3.dec_at2.value.bias', 'bert.encoder.layer.3.dec_at2.value.weight', 'bert.encoder.layer.3.enc_at2.key.bias', 'bert.encoder.layer.3.enc_at2.key.weight', 'bert.encoder.layer.3.enc_at2.query.bias', 'bert.encoder.layer.3.enc_at2.query.weight', 'bert.encoder.layer.3.enc_at2.value.bias', 'bert.encoder.layer.3.enc_at2.value.weight', 'bert.encoder.layer.3.last_dec_to_all_enc_at2.key.bias', 'bert.encoder.layer.3.last_dec_to_all_enc_at2.key.weight', 'bert.encoder.layer.3.last_dec_to_all_enc_at2.query.bias', 'bert.encoder.layer.3.last_dec_to_all_enc_at2.query.weight', 'bert.encoder.layer.3.last_dec_to_all_enc_at2.value.bias', 'bert.encoder.layer.3.last_dec_to_all_enc_at2.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.4.dec_at2.key.bias', 'bert.encoder.layer.4.dec_at2.key.weight', 'bert.encoder.layer.4.dec_at2.query.bias', 'bert.encoder.layer.4.dec_at2.query.weight', 'bert.encoder.layer.4.dec_at2.value.bias', 'bert.encoder.layer.4.dec_at2.value.weight', 'bert.encoder.layer.4.enc_at2.key.bias', 'bert.encoder.layer.4.enc_at2.key.weight', 'bert.encoder.layer.4.enc_at2.query.bias', 'bert.encoder.layer.4.enc_at2.query.weight', 'bert.encoder.layer.4.enc_at2.value.bias', 'bert.encoder.layer.4.enc_at2.value.weight', 'bert.encoder.layer.4.last_dec_to_all_enc_at2.key.bias', 'bert.encoder.layer.4.last_dec_to_all_enc_at2.key.weight', 'bert.encoder.layer.4.last_dec_to_all_enc_at2.query.bias', 'bert.encoder.layer.4.last_dec_to_all_enc_at2.query.weight', 'bert.encoder.layer.4.last_dec_to_all_enc_at2.value.bias', 'bert.encoder.layer.4.last_dec_to_all_enc_at2.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.5.dec_at2.key.bias', 'bert.encoder.layer.5.dec_at2.key.weight', 'bert.encoder.layer.5.dec_at2.query.bias', 'bert.encoder.layer.5.dec_at2.query.weight', 'bert.encoder.layer.5.dec_at2.value.bias', 'bert.encoder.layer.5.dec_at2.value.weight', 'bert.encoder.layer.5.enc_at2.key.bias', 'bert.encoder.layer.5.enc_at2.key.weight', 'bert.encoder.layer.5.enc_at2.query.bias', 'bert.encoder.layer.5.enc_at2.query.weight', 'bert.encoder.layer.5.enc_at2.value.bias', 'bert.encoder.layer.5.enc_at2.value.weight', 'bert.encoder.layer.5.last_dec_to_all_enc_at2.key.bias', 'bert.encoder.layer.5.last_dec_to_all_enc_at2.key.weight', 'bert.encoder.layer.5.last_dec_to_all_enc_at2.query.bias', 'bert.encoder.layer.5.last_dec_to_all_enc_at2.query.weight', 'bert.encoder.layer.5.last_dec_to_all_enc_at2.value.bias', 'bert.encoder.layer.5.last_dec_to_all_enc_at2.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.6.dec_at2.key.bias', 'bert.encoder.layer.6.dec_at2.key.weight', 'bert.encoder.layer.6.dec_at2.query.bias', 'bert.encoder.layer.6.dec_at2.query.weight', 'bert.encoder.layer.6.dec_at2.value.bias', 'bert.encoder.layer.6.dec_at2.value.weight', 'bert.encoder.layer.6.enc_at2.key.bias', 'bert.encoder.layer.6.enc_at2.key.weight', 'bert.encoder.layer.6.enc_at2.query.bias', 'bert.encoder.layer.6.enc_at2.query.weight', 'bert.encoder.layer.6.enc_at2.value.bias', 'bert.encoder.layer.6.enc_at2.value.weight', 'bert.encoder.layer.6.last_dec_to_all_enc_at2.key.bias', 'bert.encoder.layer.6.last_dec_to_all_enc_at2.key.weight', 'bert.encoder.layer.6.last_dec_to_all_enc_at2.query.bias', 'bert.encoder.layer.6.last_dec_to_all_enc_at2.query.weight', 'bert.encoder.layer.6.last_dec_to_all_enc_at2.value.bias', 'bert.encoder.layer.6.last_dec_to_all_enc_at2.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.7.dec_at2.key.bias', 'bert.encoder.layer.7.dec_at2.key.weight', 'bert.encoder.layer.7.dec_at2.query.bias', 'bert.encoder.layer.7.dec_at2.query.weight', 'bert.encoder.layer.7.dec_at2.value.bias', 'bert.encoder.layer.7.dec_at2.value.weight', 'bert.encoder.layer.7.enc_at2.key.bias', 'bert.encoder.layer.7.enc_at2.key.weight', 'bert.encoder.layer.7.enc_at2.query.bias', 'bert.encoder.layer.7.enc_at2.query.weight', 'bert.encoder.layer.7.enc_at2.value.bias', 'bert.encoder.layer.7.enc_at2.value.weight', 'bert.encoder.layer.7.last_dec_to_all_enc_at2.key.bias', 'bert.encoder.layer.7.last_dec_to_all_enc_at2.key.weight', 'bert.encoder.layer.7.last_dec_to_all_enc_at2.query.bias', 'bert.encoder.layer.7.last_dec_to_all_enc_at2.query.weight', 'bert.encoder.layer.7.last_dec_to_all_enc_at2.value.bias', 'bert.encoder.layer.7.last_dec_to_all_enc_at2.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.8.dec_at2.key.bias', 'bert.encoder.layer.8.dec_at2.key.weight', 'bert.encoder.layer.8.dec_at2.query.bias', 'bert.encoder.layer.8.dec_at2.query.weight', 'bert.encoder.layer.8.dec_at2.value.bias', 'bert.encoder.layer.8.dec_at2.value.weight', 'bert.encoder.layer.8.enc_at2.key.bias', 'bert.encoder.layer.8.enc_at2.key.weight', 'bert.encoder.layer.8.enc_at2.query.bias', 'bert.encoder.layer.8.enc_at2.query.weight', 'bert.encoder.layer.8.enc_at2.value.bias', 'bert.encoder.layer.8.enc_at2.value.weight', 'bert.encoder.layer.8.last_dec_to_all_enc_at2.key.bias', 'bert.encoder.layer.8.last_dec_to_all_enc_at2.key.weight', 'bert.encoder.layer.8.last_dec_to_all_enc_at2.query.bias', 'bert.encoder.layer.8.last_dec_to_all_enc_at2.query.weight', 'bert.encoder.layer.8.last_dec_to_all_enc_at2.value.bias', 'bert.encoder.layer.8.last_dec_to_all_enc_at2.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.9.dec_at2.key.bias', 'bert.encoder.layer.9.dec_at2.key.weight', 'bert.encoder.layer.9.dec_at2.query.bias', 'bert.encoder.layer.9.dec_at2.query.weight', 'bert.encoder.layer.9.dec_at2.value.bias', 'bert.encoder.layer.9.dec_at2.value.weight', 'bert.encoder.layer.9.enc_at2.key.bias', 'bert.encoder.layer.9.enc_at2.key.weight', 'bert.encoder.layer.9.enc_at2.query.bias', 'bert.encoder.layer.9.enc_at2.query.weight', 'bert.encoder.layer.9.enc_at2.value.bias', 'bert.encoder.layer.9.enc_at2.value.weight', 'bert.encoder.layer.9.last_dec_to_all_enc_at2.key.bias', 'bert.encoder.layer.9.last_dec_to_all_enc_at2.key.weight', 'bert.encoder.layer.9.last_dec_to_all_enc_at2.query.bias', 'bert.encoder.layer.9.last_dec_to_all_enc_at2.query.weight', 'bert.encoder.layer.9.last_dec_to_all_enc_at2.value.bias', 'bert.encoder.layer.9.last_dec_to_all_enc_at2.value.weight', 'lm_head.bias', 'lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "a2_cfg = EncAt2DecCfg.create(\n",
    "    inp_len = 128, pretrained_model_name = 'bert-base-uncased', max_inp_chunks = 10, max_out_toks = 50,\n",
    "    enc_at2_enabled = True, dec_at2_enabled = True, last_dec_to_all_enc_at2_enabled = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2_cfg_dict = dataclasses.asdict(a2_cfg)\n",
    "a2_cfg_dict['bert'] = a2_cfg_dict['bert'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save /home/misha/prog/mllm/mllm/config/cfg/a2_cfg_01_base.yaml\n"
     ]
    }
   ],
   "source": [
    "a2_cfg_fpath = cfg_dpath / 'a2_cfg_01_base.yaml'\n",
    "print(f'Save {a2_cfg_fpath}')\n",
    "with open(a2_cfg_fpath, 'w') as f:\n",
    "    yaml.dump(a2_cfg_dict, f, default_flow_style=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(a2_cfg_fpath, 'r') as f:\n",
    "    a2_cfg_dict_2 = yaml.safe_load(f)\n",
    "    a2_cfg_dict_2['bert'] = EncoderAt2DecoderConfig.from_dict(a2_cfg_dict_2['bert'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2_cfg.bert.to_dict() == a2_cfg_dict_2['bert'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
