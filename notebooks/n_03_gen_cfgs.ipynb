{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from pydantic_yaml import to_yaml_file, parse_yaml_file_as\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "from mllm.config.model import create_mllm_encdec_cfg, create_mllm_ranker_cfg, TokenizerCfg, \\\n",
    "    VocabEncoderCfg, EncoderCfg, MllmRankerCfg\n",
    "from mllm.tokenization.chunk_tokenizer import calc_max_inp_size, gen_all_tokens, tokenizer_from_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration generation\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/misha/prog/mllm/mllm/config/cfg')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_dpath = Path(os.path.abspath('.')).parent / 'mllm' / 'config' / 'cfg'\n",
    "cfg_dpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_config_to_yaml(cfg: BaseModel, fpath: Path, rewrite: bool = False):\n",
    "    if not fpath.exists() or rewrite:\n",
    "        to_yaml_file(fpath, cfg)\n",
    "    else:\n",
    "        print(f'File {fpath} already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', model_max_length=10000)\n",
    "n_tokens_init = len(tokenizer)\n",
    "tok_dict = gen_all_tokens(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenizerCfg(name='gpt2', n_tokens_init=50257, model_max_length=10000, custom_tokens={'doc_begin': CustomToken(name='doc_begin', repr='<|doc_begin|>', special=False, ind=50257), 'doc_end': CustomToken(name='doc_end', repr='<|doc_end|>', special=False, ind=50258), 'doc_id_begin': CustomToken(name='doc_id_begin', repr='<|doc_id_begin|>', special=False, ind=50259), 'doc_id_end': CustomToken(name='doc_id_end', repr='<|doc_id_end|>', special=False, ind=50260), 'doc_offset_begin': CustomToken(name='doc_offset_begin', repr='<|doc_offset_begin|>', special=False, ind=50261), 'doc_offset_end': CustomToken(name='doc_offset_end', repr='<|doc_offset_end|>', special=False, ind=50262), 'doc_title_begin': CustomToken(name='doc_title_begin', repr='<|doc_title_begin|>', special=False, ind=50263), 'doc_title_end': CustomToken(name='doc_title_end', repr='<|doc_title_end|>', special=False, ind=50264), 'doc_body_begin': CustomToken(name='doc_body_begin', repr='<|doc_body_begin|>', special=False, ind=50265), 'doc_body_end': CustomToken(name='doc_body_end', repr='<|doc_body_end|>', special=False, ind=50266), 'pad': CustomToken(name='pad', repr='<|pad|>', special=True, ind=50267), 'query_begin': CustomToken(name='query_begin', repr='<|query_begin|>', special=False, ind=50268), 'query_end': CustomToken(name='query_end', repr='<|query_end|>', special=False, ind=50269)})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkz_cfg = TokenizerCfg(name='gpt2', n_tokens_init=n_tokens_init, model_max_length=10000, custom_tokens=tok_dict)\n",
    "tkz_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/misha/prog/mllm/mllm/config/cfg/tokenizer_cfg_01.yaml already exists\n"
     ]
    }
   ],
   "source": [
    "tkz_cfg_fpath = cfg_dpath / 'tokenizer_cfg_01.yaml'\n",
    "save_config_to_yaml(tkz_cfg, tkz_cfg_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens_init = 50257\n"
     ]
    }
   ],
   "source": [
    "print(f'n_tokens_init = {n_tokens_init}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLLM Ranker first layer config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50267\n",
      "GPT2Tokenizer(name_or_path='gpt2', vocab_size=50257, model_max_length=10000, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|pad|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t50257: AddedToken(\"<|doc_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50258: AddedToken(\"<|doc_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50259: AddedToken(\"<|doc_id_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50260: AddedToken(\"<|doc_id_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50261: AddedToken(\"<|doc_offset_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50262: AddedToken(\"<|doc_offset_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50263: AddedToken(\"<|doc_title_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50264: AddedToken(\"<|doc_title_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50265: AddedToken(\"<|doc_body_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50266: AddedToken(\"<|doc_body_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50267: AddedToken(\"<|pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t50268: AddedToken(\"<|query_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50269: AddedToken(\"<|query_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "tkz_cfg_fpath = cfg_dpath / 'tokenizer_cfg_01.yaml'\n",
    "tkz_cfg = parse_yaml_file_as(TokenizerCfg, tkz_cfg_fpath)\n",
    "tkz = tokenizer_from_config(tkz_cfg)\n",
    "print(tkz.pad_token_id)\n",
    "print(tkz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MllmRankerCfg(vocab_encoder=VocabEncoderCfg(n_vocab=50270, d_word_vec=256, d_model=256, pad_idx=50267, inp_len=100, dropout_rate=0.0), encoders=[EncoderCfg(n_layers=1, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=True)], decoders=[EncoderCfg(n_layers=1, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=False)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_vocab = len(tkz)\n",
    "seq_len = 100\n",
    "d_word_wec = 256\n",
    "n_heads, d_model, d_inner = 8, 256, 1024\n",
    "dropout_rate = 0.0\n",
    "n_levels = 1\n",
    "enc_n_layers = 1\n",
    "enc_with_graph_mat = False\n",
    "enc_with_emb_mat = True\n",
    "dec_n_layers = 1\n",
    "pad_tok = tkz_cfg.custom_tokens['pad'].ind\n",
    "\n",
    "\n",
    "ranker_cfg_01 = create_mllm_ranker_cfg(\n",
    "    n_vocab=n_vocab, inp_len=seq_len, d_word_wec=d_word_wec, dropout_rate=dropout_rate, n_levels=n_levels,\n",
    "    enc_n_layers=enc_n_layers, n_heads=n_heads, d_model=d_model, d_inner=d_inner,\n",
    "    enc_with_graph_mat=enc_with_graph_mat, enc_with_emb_mat=enc_with_emb_mat,\n",
    "    dec_n_layers=dec_n_layers, pad_idx=pad_tok,\n",
    ")\n",
    "ranker_cfg_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/misha/prog/mllm/mllm/config/cfg/ranker_model_cfg_01.yaml already exists\n"
     ]
    }
   ],
   "source": [
    "ranker_cfg_01_fpath = cfg_dpath / 'ranker_model_cfg_01.yaml'\n",
    "save_config_to_yaml(ranker_cfg_01, ranker_cfg_01_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLLM Encdec and Ranker multi layers configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50267\n",
      "GPT2Tokenizer(name_or_path='gpt2', vocab_size=50257, model_max_length=10000, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|pad|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t50257: AddedToken(\"<|doc_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50258: AddedToken(\"<|doc_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50259: AddedToken(\"<|doc_id_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50260: AddedToken(\"<|doc_id_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50261: AddedToken(\"<|doc_offset_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50262: AddedToken(\"<|doc_offset_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50263: AddedToken(\"<|doc_title_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50264: AddedToken(\"<|doc_title_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50265: AddedToken(\"<|doc_body_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50266: AddedToken(\"<|doc_body_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50267: AddedToken(\"<|pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t50268: AddedToken(\"<|query_begin|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "\t50269: AddedToken(\"<|query_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "tkz_cfg_fpath = cfg_dpath / 'tokenizer_cfg_01.yaml'\n",
    "tkz_cfg = parse_yaml_file_as(TokenizerCfg, tkz_cfg_fpath)\n",
    "tkz = tokenizer_from_config(tkz_cfg)\n",
    "print(tkz.pad_token_id)\n",
    "print(tkz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_encoder=VocabEncoderCfg(n_vocab=50270, d_word_vec=256, d_model=256, pad_idx=50267, inp_len=100, dropout_rate=0.0) encoders=[EncoderCfg(n_layers=1, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=True), EncoderCfg(n_layers=1, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=False)] decoders=[EmbDecoderCfg(d_emb=256, n_layers=1, n_heads=8, d_hid=1024, seq_len=100, dp_rate=0.0), EmbDecoderCfg(d_emb=256, n_layers=1, n_heads=8, d_hid=1024, seq_len=100, dp_rate=0.0)]\n",
      "vocab_encoder=VocabEncoderCfg(n_vocab=50270, d_word_vec=256, d_model=256, pad_idx=50267, inp_len=100, dropout_rate=0.0) encoders=[EncoderCfg(n_layers=1, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=True), EncoderCfg(n_layers=1, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=False)] decoders=[EncoderCfg(n_layers=1, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=False), EncoderCfg(n_layers=1, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=False)]\n"
     ]
    }
   ],
   "source": [
    "n_vocab = len(tkz)\n",
    "seq_len = 100\n",
    "d_word_wec = 256\n",
    "n_heads, d_model, d_inner = 8, 256, 1024\n",
    "dropout_rate = 0.0\n",
    "n_levels = 2\n",
    "enc_n_layers = 1\n",
    "enc_with_graph_mat = False\n",
    "enc_with_emb_mat = True, False\n",
    "dec_n_layers = 1\n",
    "pad_tok = tkz_cfg.custom_tokens['pad'].ind\n",
    "\n",
    "encdec_cfg_02 = create_mllm_encdec_cfg(\n",
    "    n_vocab=n_vocab, inp_len=seq_len, d_word_wec=d_word_wec, dropout_rate=dropout_rate, n_levels=n_levels,\n",
    "    enc_n_layers=enc_n_layers, n_heads=n_heads, d_model=d_model, d_inner=d_inner,\n",
    "    enc_with_graph_mat=enc_with_graph_mat, enc_with_emb_mat=enc_with_emb_mat,\n",
    "    dec_n_layers=dec_n_layers, pad_idx=pad_tok,\n",
    ")\n",
    "\n",
    "ranker_cfg_02 = create_mllm_ranker_cfg(\n",
    "    n_vocab=n_vocab, inp_len=seq_len, d_word_wec=d_word_wec, dropout_rate=dropout_rate, n_levels=n_levels,\n",
    "    enc_n_layers=enc_n_layers, n_heads=n_heads, d_model=d_model, d_inner=d_inner,\n",
    "    enc_with_graph_mat=enc_with_graph_mat, enc_with_emb_mat=enc_with_emb_mat,\n",
    "    dec_n_layers=dec_n_layers, pad_idx=pad_tok,\n",
    ")\n",
    "\n",
    "print(encdec_cfg_02)\n",
    "print(ranker_cfg_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/misha/prog/mllm/mllm/config/cfg/encdec_model_cfg_02.yaml already exists\n",
      "File /home/misha/prog/mllm/mllm/config/cfg/ranker_model_cfg_02.yaml already exists\n"
     ]
    }
   ],
   "source": [
    "encdec_cfg_02_fpath = cfg_dpath / 'encdec_model_cfg_02.yaml'\n",
    "ranker_cfg_02_fpath = cfg_dpath / 'ranker_model_cfg_02.yaml'\n",
    "rewrite = False\n",
    "# rewrite = True\n",
    "save_config_to_yaml(encdec_cfg_02, encdec_cfg_02_fpath, rewrite)\n",
    "save_config_to_yaml(ranker_cfg_02, ranker_cfg_02_fpath, rewrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_encoder=VocabEncoderCfg(n_vocab=50270, d_word_vec=256, d_model=256, pad_idx=50267, inp_len=100, dropout_rate=0.0) encoders=[EncoderCfg(n_layers=2, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=True), EncoderCfg(n_layers=2, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=False)] decoders=[EmbDecoderCfg(d_emb=256, n_layers=2, n_heads=8, d_hid=1024, seq_len=100, dp_rate=0.0), EmbDecoderCfg(d_emb=256, n_layers=2, n_heads=8, d_hid=1024, seq_len=100, dp_rate=0.0)]\n",
      "vocab_encoder=VocabEncoderCfg(n_vocab=50270, d_word_vec=256, d_model=256, pad_idx=50267, inp_len=100, dropout_rate=0.0) encoders=[EncoderCfg(n_layers=2, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=True), EncoderCfg(n_layers=2, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=False)] decoders=[EncoderCfg(n_layers=2, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=False), EncoderCfg(n_layers=2, n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024, pad_idx=50267, with_graph_mat=False, inp_len=100, dropout_rate=0.0, with_emb_mat=False)]\n"
     ]
    }
   ],
   "source": [
    "n_vocab = len(tkz)\n",
    "seq_len = 100\n",
    "d_word_wec = 256\n",
    "n_heads, d_model, d_inner = 8, 256, 1024\n",
    "dropout_rate = 0.0\n",
    "n_levels = 2\n",
    "enc_n_layers = 2\n",
    "enc_with_graph_mat = False\n",
    "enc_with_emb_mat = True, False\n",
    "dec_n_layers = 2\n",
    "pad_tok = tkz_cfg.custom_tokens['pad'].ind\n",
    "\n",
    "encdec_cfg_03 = create_mllm_encdec_cfg(\n",
    "    n_vocab=n_vocab, inp_len=seq_len, d_word_wec=d_word_wec, dropout_rate=dropout_rate, n_levels=n_levels,\n",
    "    enc_n_layers=enc_n_layers, n_heads=n_heads, d_model=d_model, d_inner=d_inner,\n",
    "    enc_with_graph_mat=enc_with_graph_mat, enc_with_emb_mat=enc_with_emb_mat,\n",
    "    dec_n_layers=dec_n_layers, pad_idx=pad_tok,\n",
    ")\n",
    "\n",
    "ranker_cfg_03 = create_mllm_ranker_cfg(\n",
    "    n_vocab=n_vocab, inp_len=seq_len, d_word_wec=d_word_wec, dropout_rate=dropout_rate, n_levels=n_levels,\n",
    "    enc_n_layers=enc_n_layers, n_heads=n_heads, d_model=d_model, d_inner=d_inner,\n",
    "    enc_with_graph_mat=enc_with_graph_mat, enc_with_emb_mat=enc_with_emb_mat,\n",
    "    dec_n_layers=dec_n_layers, pad_idx=pad_tok,\n",
    ")\n",
    "\n",
    "print(encdec_cfg_03)\n",
    "print(ranker_cfg_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encdec_cfg_03_fpath = cfg_dpath / 'encdec_model_cfg_03.yaml'\n",
    "ranker_cfg_03_fpath = cfg_dpath / 'ranker_model_cfg_03.yaml'\n",
    "# rewrite = False\n",
    "rewrite = True\n",
    "save_config_to_yaml(encdec_cfg_03, encdec_cfg_03_fpath, rewrite)\n",
    "save_config_to_yaml(ranker_cfg_03, ranker_cfg_03_fpath, rewrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
