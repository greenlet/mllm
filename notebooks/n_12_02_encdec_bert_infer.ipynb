{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import Optional\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets.arrow_dataset import Dataset\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pydantic_yaml import parse_yaml_file_as\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import GPT2Tokenizer, AddedToken, PreTrainedTokenizer, AutoTokenizer\n",
    "\n",
    "from mllm.data.wiki.dswiki import WikiDsLoader\n",
    "from mllm.exp.args import ENCDEC_BERT_MODEL_CFG_FNAME\n",
    "from mllm.model.encdec_ranker_hg import EncdecBert\n",
    "from mllm.config.model import EncdecBertCfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(os.path.expandvars('$HOME')) / 'data'\n",
    "# WIKI_DS_NAME = '20200501.en'\n",
    "WIKI_DS_NAME = '20220301.en'\n",
    "\n",
    "TRAIN_ENCDEC_BERT_PATH = DATA_PATH / 'train_mllm_encdec_bert'\n",
    "# encdec_subdir = 'encdecbert-20250131_223521-bert-base-uncased-d768-emb_cls-inp128-lrs7x1-enh_mmbb-step2-h12-dp0-t0.0'\n",
    "encdec_subdir = 'encdecbert-20250629_222704-bert-base-uncased-d768-emb_cls-inp128-lrs7x1-enh_mmbb-step2-h12-tgt_all-dp0-t0.0'\n",
    "encdec_subdir = 'encdecbert-20250701_225013-bert-base-uncased-d768-emb_cls-inp128-lrs7x1-enh_mmbb-step2-h12-tgt_allmsk-dp0-t0.0'\n",
    "encdec_subdir = 'encdecbert-20250703_225845-bert-base-uncased-d768-emb_cls-inp128-lrs7x1-enh_mmbb-step2-h12-tgt_mskseq-dp0-t0.0'\n",
    "encdec_subdir = 'encdecbert-20250704_213735-bert-base-uncased-d768-emb_cls-inp128-lrs7x1-enh_mmbb-step2-h12-tgt_mskseq-dp0-t0.0'\n",
    "\n",
    "encdec_train_path = TRAIN_ENCDEC_BERT_PATH / encdec_subdir\n",
    "encdec_snapshot_fpath = encdec_train_path / 'best.pth'\n",
    "encdec_model_cfg_fpath = encdec_train_path / ENCDEC_BERT_MODEL_CFG_FNAME\n",
    "\n",
    "device_name = 'cpu'\n",
    "# device_name = 'cuda'\n",
    "\n",
    "device = torch.device(device_name)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e17baea6f014455a82e9aeda14f33706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/41 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia 20220301.en docs: 6458670\n"
     ]
    }
   ],
   "source": [
    "# dss = load_dataset('wikipedia', WIKI_DS_NAME, beam_runner='DirectRunner', cache_dir=str(DATA_PATH))\n",
    "dss = load_dataset('wikipedia', WIKI_DS_NAME, cache_dir=str(DATA_PATH))\n",
    "ds: Dataset = dss['train']\n",
    "n_docs = len(ds)\n",
    "print(f'Wikipedia {WIKI_DS_NAME} docs: {n_docs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_bert=EncBertCfg(inp_len=128, d_model=768, pad_token_id=0, pretrained_model_name='bert-base-uncased', tokenizer_name='bert-base-uncased', emb_type=<BertEmbType.Cls: 'cls'>, emb2_tok_name='') dec_pyr=DecPyrCfg(d_model=768, n_heads=12, d_k=64, d_v=64, d_inner=3072, inp_len=128, step=2, n_layers=7, dropout_rate=0.0, n_vocab=30522, n_similar_layers=1, enhance_type=<HgEnhanceType.MatmulBeginBias: 'mmbb'>, temperature=0.0)\n",
      "BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_cfg = parse_yaml_file_as(EncdecBertCfg, encdec_model_cfg_fpath)\n",
    "tkz = AutoTokenizer.from_pretrained(model_cfg.enc_bert.pretrained_model_name)\n",
    "print(model_cfg)\n",
    "print(tkz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt = torch.load(encdec_snapshot_fpath, map_location=device)\n",
    "model = EncdecBert(model_cfg).to(device)\n",
    "strict = True\n",
    "# strict = False\n",
    "model.load_state_dict(chkpt['model'], strict=strict)\n",
    "del chkpt\n",
    "model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp_len: 128\n"
     ]
    }
   ],
   "source": [
    "inp_len = model_cfg.enc_bert.inp_len\n",
    "print('inp_len:', inp_len)\n",
    "\n",
    "def get_batch_tokens(doc_inds: list[int], randomize: bool = False, mask_toks_len_max: int = 5) -> torch.Tensor:\n",
    "    docs_toks = np.full((len(doc_inds), inp_len), tkz.pad_token_id)\n",
    "    for i, doc_ind in enumerate(doc_inds):\n",
    "        doc = ds[doc_ind]\n",
    "        title, text = doc['title'], doc['text']\n",
    "        doc_txt = f'{title} {text}'\n",
    "        doc_txt = text\n",
    "        doc_txt = doc_txt.lower()\n",
    "        doc_toks: list[int] | np.ndarray = tkz(doc_txt)['input_ids']\n",
    "        n_toks = len(doc_toks)\n",
    "        if n_toks > inp_len:\n",
    "            i_off = np.random.randint(1, n_toks - inp_len + 1) if randomize else 1\n",
    "            doc_toks = np.concatenate([doc_toks[:1], doc_toks[i_off:i_off + inp_len - 2], doc_toks[-1:]])\n",
    "            # print(doc_toks)\n",
    "\n",
    "        mask_toks_len = np.random.randint(1, mask_toks_len_max + 1)\n",
    "        mask_toks_off = np.random.randint(len(doc_toks) - mask_toks_len + 1)\n",
    "        masked_toks = doc_toks[mask_toks_off:mask_toks_off + mask_toks_len]\n",
    "        masked_substr = tkz.decode(masked_toks)\n",
    "        print(f'{doc_ind:03d}. {masked_substr}')\n",
    "        doc_toks[mask_toks_off:mask_toks_off + mask_toks_len] = tkz.mask_token_id\n",
    "\n",
    "        docs_toks[i, :len(doc_toks)] = doc_toks\n",
    "    docs_toks_t = torch.from_numpy(docs_toks).to(device)\n",
    "    return docs_toks_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000 \"Anarchism\" Anarchism is a political philosophy and movement that is sceptical of authority and rejects all involuntary, coercive forms of hierarchy. Anarchism calls for the abolition of the state, which it holds to be unnecessary, undesirable, and harmful. As a historically left-wing movement, placed on the farthest left of the political spectrum, it is usually described alongside communalism and libertarian\n",
      "001 \"Autism\" Autism is a neurodevelopmental disorder characterized by difficulties with social interaction and communication, and by restricted and repetitive behavior. Parents often notice signs during the first three years of their child's life. These signs often develop gradually, though some autistic children experience regression in their communication and social skills after reaching developmental milest\n",
      "002 \"Albedo\" Albedo (; ) is the measure of the diffuse reflection of solar radiation out of the total solar radiation and measured on a scale from 0, corresponding to a black body that absorbs all incident radiation, to 1, corresponding to a body that reflects all incident radiation.\\n\\nSurface albedo is defined as the ratio of radiosity Je to the irradiance Ee (flux per unit area) received by a surface. The p\n",
      "003 \"A\" A, or a, is the first letter and the first vowel of the modern English alphabet and the ISO basic Latin alphabet. Its name in English is a (pronounced ), plural aes. It is similar in shape to the Ancient Greek letter alpha, from which it derives. The uppercase version consists of the two slanting sides of a triangle, crossed in the middle by a horizontal bar. The lowercase version can be written i\n",
      "004 \"Alabama\" Alabama () is a state in the Southeastern region of the United States, bordered by Tennessee to the north; Georgia to the east; Florida and the Gulf of Mexico to the south; and Mississippi to the west. Alabama is the 30th largest by area and the 24th-most populous of the U.S. states. With a total of  of inland waterways, Alabama has among the most of any state.\\n\\nAlabama is nicknamed the Yellowha\n"
     ]
    }
   ],
   "source": [
    "doc_inds = np.arange(5)\n",
    "# doc_inds += 5\n",
    "doc_inds = [x.item() for x in doc_inds]\n",
    "for doc_ind in doc_inds:\n",
    "    doc = ds[doc_ind]\n",
    "    title, text = doc['title'], doc['text'].replace('\\n', '\\\\n')\n",
    "    print(f'{doc_ind:03d} \"{title}\" {text[:400]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000. formal hierarch\n",
      "001. first\n",
      "002. albedo (\n",
      "003. written\n",
      "004. yellowhammer state,\n",
      "tensor([  101,  9617, 11140,  2964,  2003,  1037,  2576,  4695,  1998,  2929,\n",
      "         2008,  2003,  8040, 23606,  7476,  1997,  3691,  1998, 19164,  2035,\n",
      "        26097,  1010, 24873, 11890,  3512,  3596,  1997, 12571,  1012,  9617,\n",
      "        11140,  2964,  4455,  2005,  1996, 15766,  1997,  1996,  2110,  1010,\n",
      "         2029,  2009,  4324,  2000,  2022, 14203,  1010,  6151,  2229,  7895,\n",
      "         3468,  1010,  1998, 17631,  1012,  2004,  1037,  7145,  2187,  1011,\n",
      "         3358,  2929,  1010,  2872,  2006,  1996,  2521, 20515,  2187,  1997,\n",
      "         1996,  2576,  8674,  1010,  2009,  2003,  2788,  2649,  4077, 15029,\n",
      "         2964,  1998, 19297, 27255,  2004,  1996, 19297,  3358,  1006, 19297,\n",
      "        14649,  1007,  1997,  1996,  6102,  2929,  1010,  1998,  2038,  1037,\n",
      "         2844,  3439,  2523,  2007,  3424,  1011, 16498,  1998, 14649,  1012,\n",
      "         4286,  2973,  1999,  8384,  2302,   103,   103,   103,   103,  3111,\n",
      "         2146,  2077,  1996,  5069,  1997,  5337,  2163,   102])\n",
      "torch.Size([5, 128])\n",
      "torch.Size([5, 128, 30522])\n",
      "torch.Size([5, 128])\n"
     ]
    }
   ],
   "source": [
    "docs_toks_in = get_batch_tokens(doc_inds)\n",
    "print(docs_toks_in[0])\n",
    "print(docs_toks_in.shape)\n",
    "logits_pred = model(docs_toks_in, docs_toks_in != tkz.pad_token_id)\n",
    "probs_pred = torch.softmax(logits_pred, dim=-1)\n",
    "# probs_pred = torch.sigmoid(logits_pred)\n",
    "print(probs_pred.shape)\n",
    "docs_toks_out = torch.argmax(probs_pred, dim=-1)\n",
    "print(docs_toks_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000 [CLS] anarchism is a political philosophy and movement that is sceptical of authority and rejects all involuntary, coercive forms of hierarchy. anarchism calls for the abolition of the state, which it holds to be unnecessary, undesirable, and harmful. as a historically left - wing movement, placed on the farthest left of the political spectrum, it is usually described alongside communalism and libertarian marxism as the libertarian wing ( libertarian socialism ) of the socialist movement, and has a strong historical association with anti - capitalism and socialism. humans lived in societies without [MASK] [MASK] [MASK] [MASK]ies long before the establishment of formal states [SEP]\n",
      "001 [CLS] autism is a neurodevelopmental disorder characterized by difficulties with social interaction and communication, and by restricted and repetitive behavior. parents often notice signs during the [MASK] three years of their child ' s life. these signs often develop gradually, though some autistic children experience regression in their communication and social skills after reaching developmental milestones at a normal pace. autism is associated with a combination of genetic and environmental factors. risk factors during pregnancy include certain infections, such as rubella, toxins including valproic acid, alcohol, cocaine, pesticides, lead, and air pollution, fetal growth restriction, and autoimmun [SEP]\n",
      "002 [CLS] [MASK] [MASK] [MASK] ; ) is the measure of the diffuse reflection of solar radiation out of the total solar radiation and measured on a scale from 0, corresponding to a black body that absorbs all incident radiation, to 1, corresponding to a body that reflects all incident radiation. surface albedo is defined as the ratio of radiosity je to the irradiance ee ( flux per unit area ) received by a surface. the proportion reflected is not only determined by properties of the surface itself, but also by the spectral and angular distribution of solar radiation reaching the earth ' s surface. these factors vary with atmospheric composition, geographic location, and [SEP]\n",
      "003 [CLS] a, or a, is the first letter and the first vowel of the modern english alphabet and the iso basic latin alphabet. its name in english is a ( pronounced ), plural aes. it is similar in shape to the ancient greek letter alpha, from which it derives. the uppercase version consists of the two slanting sides of a triangle, crossed in the middle by a horizontal bar. the lowercase version can be [MASK] in two forms : the double - storey a and single - storey ɑ. the latter is commonly used in handwriting and fonts based on it, especially fonts intended to be read by children, [SEP]\n",
      "004 [CLS] alabama ( ) is a state in the southeastern region of the united states, bordered by tennessee to the north ; georgia to the east ; florida and the gulf of mexico to the south ; and mississippi to the west. alabama is the 30th largest by area and the 24th - most populous of the u. s. states. with a total of of inland waterways, alabama has among the most of any state. alabama is nicknamed the [MASK] [MASK] [MASK] [MASK] after the state bird. alabama is also known as the \" heart of dixie \" and the \" cotton state \". the state tree is the longleaf pine, and the state flower is [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i, doc_ind in enumerate(doc_inds):\n",
    "    s = tkz.decode(docs_toks_in[i])\n",
    "    s = s.replace('\\n', '\\\\n')\n",
    "    print(f'{doc_ind:03d} {s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000 the, andrel [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "001 past two [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "002 ( ( ( [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "003 used in [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "004 \" of \" named [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "for i, doc_ind in enumerate(doc_inds):\n",
    "    s = tkz.decode(docs_toks_out[i])\n",
    "    s = s.replace('\\n', '\\\\n')\n",
    "    print(f'{doc_ind:03d} {s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder embedding evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(txts: list[str]) -> torch.Tensor:\n",
    "    batch_toks = np.full((len(txts), inp_len), tkz.pad_token_id)\n",
    "    for i, txt in enumerate(txts):\n",
    "        toks: list[int] = tkz(txt)['input_ids']\n",
    "        n_toks = len(toks)\n",
    "        if n_toks > inp_len:\n",
    "            i_off = np.random.randint(n_toks - inp_len + 1)\n",
    "            toks = toks[i_off:i_off + inp_len]\n",
    "        batch_toks[i, :len(toks)] = toks\n",
    "    batch_toks_t = torch.from_numpy(batch_toks).to(device)\n",
    "    return batch_toks_t\n",
    "\n",
    "model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 768])\n"
     ]
    }
   ],
   "source": [
    "txts = [\n",
    "    '\"Orana Australia Ltd\" Orana Australia Ltd is a not-for-profit organisation that provides a diverse range of training and support services to over 650 people with disabilities and their families in South Australia.\\n\\nHistory\\nThe Mentally Retarded Children’s Society of SA Inc. was established in 1950 by a group of parent',\n",
    "    'Australia',\n",
    "    'Orana Australia Ltd',\n",
    "    'Hello Kitty',\n",
    "]\n",
    "batch_toks = get_tokens(txts)\n",
    "embs = model.enc_bert(batch_toks, batch_toks != tkz.pad_token_id)\n",
    "# embs = embs.detach().cpu().numpy()\n",
    "embs = embs.detach().cpu()\n",
    "print(embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Australia [0.1348315] tensor(9.7678)\n",
      "Orana Australia Ltd [0.14778207] tensor(10.4330)\n",
      "Hello Kitty [0.08750954] tensor(10.7561)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(embs)):\n",
    "    cos_dist = F.cosine_similarity(embs[0:1], embs[i:i + 1])\n",
    "    norm_dist = torch.norm(embs[0] - embs[i])\n",
    "    print(txts[i], cos_dist.numpy(), norm_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answering questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx = 'Context3. Like other American research universities, Northwestern was transformed by World War II. Franklyn B. Snyder led the university from 1939 to 1949, when nearly 50,000 military officers and personnel were trained on the Evanston and Chicago campuses. After the war, surging enrollments under the G.I. Bill drove drastic expansion of both campuses. In 1948 prominent anthropologist Melville J. '\n",
    "q = 'Question: Between 1939 and 1949, how many military officers and personnel were trained on the Evanston and Chicago campuses? Answer: [MASK] [MASK] [MASK] [MASK]'\n",
    "s = f'{ctx} {q}'\n",
    "toks = tkz(s).input_ids\n",
    "len(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 30522])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  101,  6123,  2509,  1012,  2066,  2060,  2137,  2470,  5534,  1010,\n",
       "         7855,  2001,  8590,  2011,  2088,  2162,  2462,  1012, 19597,  2078,\n",
       "         1038,  1012, 17840,  2419,  1996,  2118,  2013,  3912,  2000,  4085,\n",
       "         1010,  2043,  3053,  2753,  1010,  2199,  2510,  3738,  1998,  5073,\n",
       "         2020,  4738,  2006,  1996,  6473,  2669,  1998,  3190, 13696,  1012,\n",
       "         2044,  1996,  2162,  1010,  7505,  4726, 10316,  2015,  2104,  1996,\n",
       "         1043,  1012,  1045,  1012,  3021,  6303, 20851,  4935,  1997,  2119,\n",
       "        13696,  1012,  1999,  3882,  4069, 21571, 20154,  1046,  1012,  3160,\n",
       "         1024,  2090,  3912,  1998,  4085,  1010,  2129,  2116,  2510,  3738,\n",
       "         1998,  5073,  2020,  4738,  2006,  1996,  6473,  2669,  1998,  3190,\n",
       "        13696,  1029,  3437,  1024,  1000,  1024,  2137,  2015,   102,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks_in = torch.tensor(toks).to(device).unsqueeze(0)\n",
    "logits_pred = model(toks_in, toks_in != tkz.pad_token_id)\n",
    "print(logits_pred.shape)\n",
    "probs_pred = torch.softmax(logits_pred[0], dim=-1)\n",
    "toks_out = torch.argmax(probs_pred, dim=-1)\n",
    "toks_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] context3. like other american research universities, northwestern was transformed by world war ii. franklyn b. snyder led the university from 1939 to 1949, when nearly 50, 000 military officers and personnel were trained on the evanston and chicago campuses. after the war, surging enrollments under the g. i. bill demanded ample expansion of both campuses. in 1948 prominent anthropologist melville j. question : between 1939 and 1949, how many military officers and personnel were trained on the evanston and chicago campuses? answer : \" : americans [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkz.decode(toks_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 1.1139e-12, 6.2658e-13, 1.4770e-12, 1.5230e-12, 1.4352e-12,\n",
       "        1.0220e-12, 1.1165e-12, 1.0452e-12, 1.1000e-12],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 128, 30522])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6792, 0.0907, 0.6140, 0.9981],\n",
       "         [0.2409, 0.8605, 0.0702, 0.2925],\n",
       "         [0.1105, 0.1167, 0.4092, 0.3401]],\n",
       "\n",
       "        [[0.3772, 0.2479, 0.2412, 0.0046],\n",
       "         [0.8316, 0.8350, 0.4125, 0.5759],\n",
       "         [0.0096, 0.6448, 0.9033, 0.0755]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(2, 3, 4)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2586, 0.1435, 0.2422, 0.3557],\n",
      "         [0.2103, 0.3908, 0.1773, 0.2215],\n",
      "         [0.2168, 0.2182, 0.2923, 0.2728]],\n",
      "\n",
      "        [[0.2906, 0.2554, 0.2537, 0.2002],\n",
      "         [0.2911, 0.2921, 0.1914, 0.2254],\n",
      "         [0.1563, 0.2949, 0.3819, 0.1669]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.softmax(t, dim=2)\n",
    "print(t1)\n",
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1],\n",
       "         [1],\n",
       "         [3]],\n",
       "\n",
       "        [[2],\n",
       "         [2],\n",
       "         [1]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.randint(0, 4, (2, 3, 1))\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1435],\n",
       "         [0.3908],\n",
       "         [0.2728]],\n",
       "\n",
       "        [[0.2537],\n",
       "         [0.1914],\n",
       "         [0.2949]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(t1, dim=2, index=t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
