{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import Optional\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets.arrow_dataset import Dataset\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pydantic_yaml import parse_yaml_file_as\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import GPT2Tokenizer, AddedToken, PreTrainedTokenizer, AutoTokenizer\n",
    "\n",
    "from mllm.data.wiki.dswiki import WikiDsLoader\n",
    "from mllm.exp.args import ENCDEC_BERT_MODEL_CFG_FNAME\n",
    "from mllm.model.encdec_ranker_hg import EncdecBert\n",
    "from mllm.config.model import EncdecBertCfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(os.path.expandvars('$HOME')) / 'data'\n",
    "WIKI_DS_NAME = '20200501.en'\n",
    "\n",
    "TRAIN_ENCDEC_BERT_PATH = DATA_PATH / 'train_mllm_encdec_bert'\n",
    "# encdec_subdir = 'encdecbert-20250126_212805-bert-base-uncased-d768-emb_cls-inp128-lrs7x1-enh_mmbb-step2-h12-dp0-t0.0'\n",
    "encdec_subdir = 'encdecbert-20250131_223521-bert-base-uncased-d768-emb_cls-inp128-lrs7x1-enh_mmbb-step2-h12-dp0-t0.0'\n",
    "\n",
    "encdec_train_path = TRAIN_ENCDEC_BERT_PATH / encdec_subdir\n",
    "encdec_snapshot_fpath = encdec_train_path / 'best.pth'\n",
    "encdec_model_cfg_fpath = encdec_train_path / ENCDEC_BERT_MODEL_CFG_FNAME\n",
    "\n",
    "device_name = 'cpu'\n",
    "# device_name = 'cuda'\n",
    "\n",
    "device = torch.device(device_name)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikipedia (/home/misha/data/wikipedia/20200501.en/1.0.0/009f923d9b6dd00c00c8cdc7f408f2b47f45dd4f5fb7982a21f9448f4afbe475)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199768fe3a9b43d8afdfdb7566a4d127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia 20200501.en docs: 6078422\n"
     ]
    }
   ],
   "source": [
    "dss = load_dataset('wikipedia', WIKI_DS_NAME, beam_runner='DirectRunner', cache_dir=str(DATA_PATH))\n",
    "ds: Dataset = dss['train']\n",
    "n_docs = len(ds)\n",
    "print(f'Wikipedia {WIKI_DS_NAME} docs: {n_docs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_bert=EncBertCfg(inp_len=128, d_model=768, pretrained_model_name='bert-base-uncased', tokenizer_name='bert-base-uncased', emb_type=<BertEmbType.Cls: 'cls'>) dec_pyr=DecPyrCfg(d_model=768, n_heads=12, d_k=64, d_v=64, d_inner=3072, inp_len=128, step=2, n_layers=7, dropout_rate=0.0, n_vocab=30522, n_similar_layers=1, enhance_type=<HgEnhanceType.MatmulBeginBias: 'mmbb'>, temperature=0.0)\n",
      "BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model_cfg = parse_yaml_file_as(EncdecBertCfg, encdec_model_cfg_fpath)\n",
    "tkz = AutoTokenizer.from_pretrained(model_cfg.enc_bert.pretrained_model_name)\n",
    "print(model_cfg)\n",
    "print(tkz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncdecBert(\n",
       "  (enc_bert): EncoderBert(\n",
       "    (bert_model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSdpaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dec_pyr): DecoderPyramid(\n",
       "    (enc_layers): ModuleList(\n",
       "      (0-6): 7 x EncoderLayer(\n",
       "        (slf_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (w_ks): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (w_vs): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (fc): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (enh_beg_layer): Linear(in_features=768, out_features=98304, bias=True)\n",
       "    (vocab_decoder): VocabDecoder(\n",
       "      (word_prj): Linear(in_features=768, out_features=30522, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chkpt = torch.load(encdec_snapshot_fpath, map_location=device)\n",
    "model = EncdecBert(model_cfg).to(device)\n",
    "strict = True\n",
    "# strict = False\n",
    "model.load_state_dict(chkpt['model'], strict=strict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp_len: 128\n"
     ]
    }
   ],
   "source": [
    "inp_len = model_cfg.enc_bert.inp_len\n",
    "print('inp_len:', inp_len)\n",
    "\n",
    "def get_batch_tokens(doc_inds: list[int], randomize: bool = False) -> torch.Tensor:\n",
    "    docs_toks = np.full((len(doc_inds), inp_len), tkz.pad_token_id)\n",
    "    for i, doc_ind in enumerate(doc_inds):\n",
    "        doc = ds[doc_ind]\n",
    "        title, text = doc['title'], doc['text']\n",
    "        doc_txt = f'{title} {text}'\n",
    "        doc_txt = text\n",
    "        doc_txt = doc_txt.lower()\n",
    "        doc_toks: list[int] | np.ndarray = tkz(doc_txt)['input_ids']\n",
    "        n_toks = len(doc_toks)\n",
    "        if n_toks > inp_len:\n",
    "            i_off = np.random.randint(1, n_toks - inp_len + 1) if randomize else 1\n",
    "            doc_toks = np.concatenate([doc_toks[:1], doc_toks[i_off:i_off + inp_len - 2], doc_toks[-1:]])\n",
    "            # print(doc_toks)\n",
    "        docs_toks[i, :len(doc_toks)] = doc_toks\n",
    "    docs_toks_t = torch.from_numpy(docs_toks).to(device)\n",
    "    return docs_toks_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000 \"Yangliuqing\" Yangliuqing () is a market town in Xiqing District, in the western suburbs of Tianjin, People's Republic of China. Despite its relatively small size, it has been named since 2006 in the \"famous historical and cultural market towns in China\".\\n\\nIt is best known in China for creating nianhua or Yangl\n",
      "001 \"Orana Australia Ltd\" Orana Australia Ltd is a not-for-profit organisation that provides a diverse range of training and support services to over 650 people with disabilities and their families in South Australia.\\n\\nHistory\\nThe Mentally Retarded Children’s Society of SA Inc. was established in 1950 by a group of parent\n",
      "002 \"St. Mary's Church, Sønderborg\" The St. Mary's Church is a church owned by the Church of Denmark in Sønderborg, Denmark and the church of the parish with the same name. Thanks to its location on a hill, the church building is very iconic for the city.\\n\\nHistory \\nIn the Middle Ages there was a leper colony on a hill just outside \n",
      "003 \"Kalitta\" Kalitta may refer to:\\n\\nConnie Kalitta (born 1938), a retired American drag racer and CEO of the eponymous Kallita Air.\\nDoug Kalitta (born 1964), an American drag racer, nephew of Connie Kalitta and owner of Kalitta Charters.\\nScott Kalitta (1962-2008), an American drag racer and son of Connie Kal\n",
      "004 \"Where Is Freedom?\" Where Is Freedom? () is a 1954 Italian comedy-drama film directed by Roberto Rossellini. \\n \\nThe film had a troubled production because, after shooting some scenes, Rossellini lost interest in the film and abandoned the set. The work was completed after about a year, mainly from Mario Monicelli, wi\n"
     ]
    }
   ],
   "source": [
    "doc_inds = np.arange(5)\n",
    "# doc_inds += 5\n",
    "doc_inds = [x.item() for x in doc_inds]\n",
    "for doc_ind in doc_inds:\n",
    "    doc = ds[doc_ind]\n",
    "    title, text = doc['title'], doc['text'].replace('\\n', '\\\\n')\n",
    "    print(f'{doc_ind:03d} \"{title}\" {text[:300]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 128, 30522])\n",
      "torch.Size([5, 128])\n"
     ]
    }
   ],
   "source": [
    "docs_toks_in = get_batch_tokens(doc_inds)\n",
    "logits_pred = model(docs_toks_in, docs_toks_in != tkz.pad_token_id)\n",
    "probs_pred = torch.softmax(logits_pred, dim=-1)\n",
    "# probs_pred = torch.sigmoid(logits_pred)\n",
    "print(probs_pred.shape)\n",
    "docs_toks_out = torch.argmax(probs_pred, dim=-1)\n",
    "print(docs_toks_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000 [CLS] yangliuqing ( ) is a market town in xiqing district, in the western suburbs of tianjin, people's republic of china. despite its relatively small size, it has been named since 2006 in the \" famous historical and cultural market towns in china \". it is best known in china for creating nianhua or yangliuqing nianhua. for more than 400 years, yangliuqing has in effect specialised in the creation of these woodcuts for the new year. wood block prints using vivid colourschemes to portray traditional scenes of children's games often interwoven with auspicious [SEP]\n",
      "001 [CLS] orana australia ltd is a not - for - profit organisation that provides a diverse range of training and support services to over 650 people with disabilities and their families in south australia. history the mentally retarded children ’ s society of sa inc. was established in 1950 by a group of parents who wanted education, employment and accommodation opportunities for their children within the local community at a time when institutionalised care in adelaide was their only alternative. the society ’ s aims were to seek education or training facilities for people with intellectual disabilities, to establish sheltered workshops, and to establish residential hostels. a number of sheltered workshops were established, and [SEP]\n",
      "002 [CLS] the st. mary's church is a church owned by the church of denmark in sønderborg, denmark and the church of the parish with the same name. thanks to its location on a hill, the church building is very iconic for the city. history in the middle ages there was a leper colony on a hill just outside the city. it was named after saint george and around 1300 the chapel of this leper colony stood in the place of the present st. mary's church. after the old parish church of the city, the st. nicholas church, was demolished around 1530, the saint - george [SEP]\n",
      "003 [CLS] kalitta may refer to : connie kalitta ( born 1938 ), a retired american drag racer and ceo of the eponymous kallita air. doug kalitta ( born 1964 ), an american drag racer, nephew of connie kalitta and owner of kalitta charters. scott kalitta ( 1962 - 2008 ), an american drag racer and son of connie kalitta. kalitta air, a cargo airline flying boeing 747 aircraft. kalitta charters, a cargo airline flying medium - sized aircraft. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "004 [CLS] where is freedom? ( ) is a 1954 italian comedy - drama film directed by roberto rossellini. the film had a troubled production because, after shooting some scenes, rossellini lost interest in the film and abandoned the set. the work was completed after about a year, mainly from mario monicelli, with some scenes also shot by lucio fulci and federico fellini. despite that, rossellini is the sole credited director of the film. plot difficulties and troubles of an ex - convict. embittered and disillusioned by life, he will soon plan his return to prison. cast to [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i, doc_ind in enumerate(doc_inds):\n",
    "    s = tkz.decode(docs_toks_in[i])\n",
    "    s = s.replace('\\n', '\\\\n')\n",
    "    print(f'{doc_ind:03d} {s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000 [CLS] yangliuqing ( ) is a market town in xiqing district, in the western suburbs of tianjin, people's republic of china. despite its relatively small size, it has been named since 2006 in the \" famous historical and cultural market towns in china \". it is best known in china for creating nianhua or yangliuqing nianhua. for more than 400 years, yangliuqing has in effect specialised in the creation of these woodcuts for the new year. wood block prints using vivid colourschemes to portray traditional scenes of children's games often interwoven with auspicious [SEP]\n",
      "001 [CLS] orana australia ltd is a not - for - profit organisation that provides a diverse range of training and support services to over 650 people with disabilities and their families in south australia. history the mentally retarded children ’ s society of sa inc. was established in 1950 by a group of parents who wanted education, employment and accommodation opportunities for their children within the local community at a time when institutionalised care in adelaide was their only alternative. the society ’ s aims were to seek education or training facilities for people with intellectual disabilities, to establish processing workshops, and to establish residential hostels. a number of sheltered workshops were established, and [SEP]\n",
      "002 [CLS] the st. mary's church is a church owned by the church of denmark in sønderborg, denmark and the church of the parish with the same name. thanks to its location on a hill, the church building is very iconic for the city. history in the middle ages there was a leper colony on a hill just outside the city. it was named after saint george and around 1300 the chapel of this leper colony stood in the place of the present st. mary's church. after the old parish church of the city, the st. nicholas church, was demolished around 1530, the saint - george [SEP]\n",
      "003 [CLS] kalitta may refer to : connie kalitta ( born 1938 ), a retired american drag racer and ceo of the eponymous kallita air. doug kalitta ( born 1964 ), an american drag racer, nephew of connie kalitta and owner of kalitta charters. scott kalitta ( 1962 - 2008 ), an american drag racer and son of connie kalitta. kalitta air, a cargo airline flying boeing 747 aircraft. kalitta charters, a cargo airline flying medium - sized aircraft. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "004 [CLS] where is freedom? ( ) is a 1954 italian comedy - drama film directed by roberto rossellini. the film had a troubled production because, after shooting some scenes, rossellini lost interest in the film and abandoned the set. the work was completed after about a year, mainly from mario monicelli, with some scenes also shot by lucio fulci and federico fellini. despite that, rossellini is the sole credited director of the film. plot difficulties and troubles of an ex - convict. embittered and disillusioned by life, he will soon stop his return to prison. according to [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i, doc_ind in enumerate(doc_inds):\n",
    "    s = tkz.decode(docs_toks_out[i])\n",
    "    s = s.replace('\\n', '\\\\n')\n",
    "    print(f'{doc_ind:03d} {s}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder embedding evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(txts: list[str]) -> torch.Tensor:\n",
    "    batch_toks = np.full((len(txts), inp_len), tkz.pad_token_id)\n",
    "    for i, txt in enumerate(txts):\n",
    "        toks: list[int] = tkz(txt)['input_ids']\n",
    "        n_toks = len(toks)\n",
    "        if n_toks > inp_len:\n",
    "            i_off = np.random.randint(n_toks - inp_len + 1)\n",
    "            toks = toks[i_off:i_off + inp_len]\n",
    "        batch_toks[i, :len(toks)] = toks\n",
    "    batch_toks_t = torch.from_numpy(batch_toks).to(device)\n",
    "    return batch_toks_t\n",
    "\n",
    "model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 768])\n"
     ]
    }
   ],
   "source": [
    "txts = [\n",
    "    '\"Orana Australia Ltd\" Orana Australia Ltd is a not-for-profit organisation that provides a diverse range of training and support services to over 650 people with disabilities and their families in South Australia.\\n\\nHistory\\nThe Mentally Retarded Children’s Society of SA Inc. was established in 1950 by a group of parent',\n",
    "    'Australia',\n",
    "    'Orana Australia Ltd',\n",
    "    'Hello Kitty',\n",
    "]\n",
    "batch_toks = get_tokens(txts)\n",
    "embs = model.enc_bert(batch_toks, batch_toks != tkz.pad_token_id)\n",
    "# embs = embs.detach().cpu().numpy()\n",
    "embs = embs.detach().cpu()\n",
    "print(embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Australia [0.13148455] tensor(9.9159)\n",
      "Orana Australia Ltd [0.14719056] tensor(10.5426)\n",
      "Hello Kitty [0.08668104] tensor(10.8450)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(embs)):\n",
    "    cos_dist = F.cosine_similarity(embs[0:1], embs[i:i + 1])\n",
    "    norm_dist = torch.norm(embs[0] - embs[i])\n",
    "    print(txts[i], cos_dist.numpy(), norm_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
