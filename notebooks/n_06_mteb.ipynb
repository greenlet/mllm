{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "from dataclasses import dataclass\n",
    "import gzip\n",
    "import itertools\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import re\n",
    "import sys\n",
    "from typing import Optional\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "import mteb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from mllm.utils.utils import write_tsv, read_tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTEB Datasets\n",
    "## Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(os.path.expandvars('$HOME')) / 'data'\n",
    "MTEB_PATH = DATA_PATH / 'mteb'\n",
    "FEVER_PATH = DATA_PATH / 'fever'\n",
    "FEVER_PATH.mkdir(parents=True, exist_ok=True)\n",
    "FEVER_QS_FPATH = FEVER_PATH / 'queries.tsv'\n",
    "FEVER_QRELS_FPATH = FEVER_PATH / 'qrels.tsv'\n",
    "FEVER_DOCS_FPATH = FEVER_PATH / 'docs.tsv'\n",
    "FEVER_DOCS_OFF_FPATH = FEVER_PATH / 'docs_offsets.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SadeemQuestionRetrieval(name='SadeemQuestionRetrieval', languages=['ara'])\n",
      "AppsRetrieval(name='AppsRetrieval', languages=['eng', 'python'])\n",
      "CodeEditSearchRetrieval(name='CodeEditSearchRetrieval', languages=['c', 'c++', 'go', '...'])\n",
      "CodeFeedbackMT(name='CodeFeedbackMT', languages=['eng'])\n",
      "CodeFeedbackST(name='CodeFeedbackST', languages=['eng'])\n",
      "CodeSearchNetCCRetrieval(name='CodeSearchNetCCRetrieval', languages=['go', 'java', 'javascript', '...'])\n",
      "CodeSearchNetRetrieval(name='CodeSearchNetRetrieval', languages=['go', 'java', 'javascript', '...'])\n",
      "CodeTransOceanContestRetrieval(name='CodeTransOceanContest', languages=['c++', 'python'])\n",
      "CodeTransOceanDLRetrieval(name='CodeTransOceanDL', languages=['python'])\n",
      "COIRCodeSearchNetRetrieval(name='COIRCodeSearchNetRetrieval', languages=['go', 'java', 'javascript', '...'])\n",
      "CosQARetrieval(name='CosQA', languages=['eng', 'python'])\n",
      "StackOverflowQARetrieval(name='StackOverflowQA', languages=['eng'])\n",
      "SyntheticText2SQLRetrieval(name='SyntheticText2SQL', languages=['eng', 'sql'])\n",
      "DanFeverRetrieval(name='DanFeverRetrieval', languages=['dan'])\n",
      "TV2Nordretrieval(name='TV2Nordretrieval', languages=['dan'])\n",
      "TwitterHjerneRetrieval(name='TwitterHjerneRetrieval', languages=['dan'])\n",
      "GerDaLIR(name='GerDaLIR', languages=['deu'])\n",
      "GerDaLIRSmall(name='GerDaLIRSmall', languages=['deu'])\n",
      "GermanDPR(name='GermanDPR', languages=['deu'])\n",
      "GermanGovServiceRetrieval(name='GermanGovServiceRetrieval', languages=['deu'])\n",
      "GermanQuADRetrieval(name='GermanQuAD-Retrieval', languages=['deu'])\n",
      "LegalQuAD(name='LegalQuAD', languages=['deu'])\n",
      "GreekCivicsQA(name='GreekCivicsQA', languages=['ell'])\n",
      "AILACasedocs(name='AILACasedocs', languages=['eng'])\n",
      "AILAStatutes(name='AILAStatutes', languages=['eng'])\n",
      "AlphaNLI(name='AlphaNLI', languages=['eng'])\n",
      "ARCChallenge(name='ARCChallenge', languages=['eng'])\n",
      "ArguAna(name='ArguAna', languages=['eng'])\n",
      "BrightRetrieval(name='BrightRetrieval', languages=['eng'])\n",
      "ClimateFEVER(name='ClimateFEVER', languages=['eng'])\n",
      "ClimateFEVERHardNegatives(name='ClimateFEVERHardNegatives', languages=['eng'])\n",
      "CQADupstackAndroidRetrieval(name='CQADupstackAndroidRetrieval', languages=['eng'])\n",
      "CQADupstackEnglishRetrieval(name='CQADupstackEnglishRetrieval', languages=['eng'])\n",
      "CQADupstackGamingRetrieval(name='CQADupstackGamingRetrieval', languages=['eng'])\n",
      "CQADupstackGisRetrieval(name='CQADupstackGisRetrieval', languages=['eng'])\n",
      "CQADupstackMathematicaRetrieval(name='CQADupstackMathematicaRetrieval', languages=['eng'])\n",
      "CQADupstackPhysicsRetrieval(name='CQADupstackPhysicsRetrieval', languages=['eng'])\n",
      "CQADupstackProgrammersRetrieval(name='CQADupstackProgrammersRetrieval', languages=['eng'])\n",
      "CQADupstackStatsRetrieval(name='CQADupstackStatsRetrieval', languages=['eng'])\n",
      "CQADupstackTexRetrieval(name='CQADupstackTexRetrieval', languages=['eng'])\n",
      "CQADupstackUnixRetrieval(name='CQADupstackUnixRetrieval', languages=['eng'])\n",
      "CQADupstackWebmastersRetrieval(name='CQADupstackWebmastersRetrieval', languages=['eng'])\n",
      "CQADupstackWordpressRetrieval(name='CQADupstackWordpressRetrieval', languages=['eng'])\n",
      "DBPedia(name='DBPedia', languages=['eng'])\n",
      "DBPediaHardNegatives(name='DBPediaHardNegatives', languages=['eng'])\n",
      "FaithDialRetrieval(name='FaithDial', languages=['eng'])\n",
      "FeedbackQARetrieval(name='FeedbackQARetrieval', languages=['eng'])\n",
      "FEVER(name='FEVER', languages=['eng'])\n",
      "FEVERHardNegatives(name='FEVERHardNegatives', languages=['eng'])\n",
      "FiQA2018(name='FiQA2018', languages=['eng'])\n",
      "HagridRetrieval(name='HagridRetrieval', languages=['eng'])\n",
      "HellaSwag(name='HellaSwag', languages=['eng'])\n",
      "HotpotQA(name='HotpotQA', languages=['eng'])\n",
      "HotpotQAHardNegatives(name='HotpotQAHardNegatives', languages=['eng'])\n",
      "LegalBenchConsumerContractsQA(name='LegalBenchConsumerContractsQA', languages=['eng'])\n",
      "LegalBenchCorporateLobbying(name='LegalBenchCorporateLobbying', languages=['eng'])\n",
      "LegalSummarization(name='LegalSummarization', languages=['eng'])\n",
      "LEMBNarrativeQARetrieval(name='LEMBNarrativeQARetrieval', languages=['eng'])\n",
      "LEMBNeedleRetrieval(name='LEMBNeedleRetrieval', languages=['eng'])\n",
      "LEMBPasskeyRetrieval(name='LEMBPasskeyRetrieval', languages=['eng'])\n",
      "LEMBQMSumRetrieval(name='LEMBQMSumRetrieval', languages=['eng'])\n",
      "LEMBSummScreenFDRetrieval(name='LEMBSummScreenFDRetrieval', languages=['eng'])\n",
      "LEMBWikimQARetrieval(name='LEMBWikimQARetrieval', languages=['eng'])\n",
      "LitSearchRetrieval(name='LitSearchRetrieval', languages=['eng'])\n",
      "MedicalQARetrieval(name='MedicalQARetrieval', languages=['eng'])\n",
      "MLQuestionsRetrieval(name='MLQuestions', languages=['eng'])\n",
      "MSMARCO(name='MSMARCO', languages=['eng'])\n",
      "MSMARCOHardNegatives(name='MSMARCOHardNegatives', languages=['eng'])\n",
      "MSMARCOv2(name='MSMARCOv2', languages=['eng'])\n",
      "NarrativeQARetrieval(name='NarrativeQARetrieval', languages=['eng'])\n",
      "NFCorpus(name='NFCorpus', languages=['eng'])\n",
      "NQ(name='NQ', languages=['eng'])\n",
      "NQHardNegatives(name='NQHardNegatives', languages=['eng'])\n",
      "PIQA(name='PIQA', languages=['eng'])\n",
      "Quail(name='Quail', languages=['eng'])\n",
      "QuoraRetrieval(name='QuoraRetrieval', languages=['eng'])\n",
      "QuoraRetrievalHardNegatives(name='QuoraRetrievalHardNegatives', languages=['eng'])\n",
      "RARbCode(name='RARbCode', languages=['eng'])\n",
      "RARbMath(name='RARbMath', languages=['eng'])\n",
      "SCIDOCS(name='SCIDOCS', languages=['eng'])\n",
      "SciFact(name='SciFact', languages=['eng'])\n",
      "SIQA(name='SIQA', languages=['eng'])\n",
      "SpartQA(name='SpartQA', languages=['eng'])\n",
      "TempReasonL1(name='TempReasonL1', languages=['eng'])\n",
      "TempReasonL2Context(name='TempReasonL2Context', languages=['eng'])\n",
      "TempReasonL2Fact(name='TempReasonL2Fact', languages=['eng'])\n",
      "TempReasonL2Pure(name='TempReasonL2Pure', languages=['eng'])\n",
      "TempReasonL3Context(name='TempReasonL3Context', languages=['eng'])\n",
      "TempReasonL3Fact(name='TempReasonL3Fact', languages=['eng'])\n",
      "TempReasonL3Pure(name='TempReasonL3Pure', languages=['eng'])\n",
      "TopiOCQARetrieval(name='TopiOCQA', languages=['eng'])\n",
      "TopiOCQARetrievalHardNegatives(name='TopiOCQAHardNegatives', languages=['eng'])\n",
      "Touche2020v3Retrieval(name='Touche2020Retrieval.v3', languages=['eng'])\n",
      "TRECCOVID(name='TRECCOVID', languages=['eng'])\n",
      "WinoGrande(name='WinoGrande', languages=['eng'])\n",
      "EstQA(name='EstQA', languages=['est'])\n",
      "AlloprofRetrieval(name='AlloprofRetrieval', languages=['fra'])\n",
      "BSARDRetrieval(name='BSARDRetrieval', languages=['fra'])\n",
      "FQuADRetrieval(name='FQuADRetrieval', languages=['fra'])\n",
      "SyntecRetrieval(name='SyntecRetrieval', languages=['fra'])\n",
      "HunSum2AbstractiveRetrieval(name='HunSum2AbstractiveRetrieval', languages=['hun'])\n",
      "JaGovFaqsRetrieval(name='JaGovFaqsRetrieval', languages=['jpn'])\n",
      "JaqketRetrieval(name='JaqketRetrieval', languages=['jpn'])\n",
      "JaQuADRetrieval(name='JaQuADRetrieval', languages=['jpn'])\n",
      "NLPJournalAbsIntroRetrieval(name='NLPJournalAbsIntroRetrieval', languages=['jpn'])\n",
      "NLPJournalTitleAbsRetrieval(name='NLPJournalTitleAbsRetrieval', languages=['jpn'])\n",
      "NLPJournalTitleIntroRetrieval(name='NLPJournalTitleIntroRetrieval', languages=['jpn'])\n",
      "GeorgianFAQRetrieval(name='GeorgianFAQRetrieval', languages=['kat'])\n",
      "AutoRAGRetrieval(name='AutoRAGRetrieval', languages=['kor'])\n",
      "KoStrategyQA(name='Ko-StrategyQA', languages=['kor'])\n",
      "BelebeleRetrieval(name='BelebeleRetrieval', languages=['acm', 'afr', 'als', '...'])\n",
      "CrossLingualSemanticDiscriminationWMT19(name='CrossLingualSemanticDiscriminationWMT19', languages=['deu', 'fra'])\n",
      "CrossLingualSemanticDiscriminationWMT21(name='CrossLingualSemanticDiscriminationWMT21', languages=['deu', 'fra'])\n",
      "CUREv1Retrieval(name='CUREv1', languages=['eng', 'fra', 'spa'])\n",
      "IndicQARetrieval(name='IndicQARetrieval', languages=['asm', 'ben', 'guj', '...'])\n",
      "MintakaRetrieval(name='MintakaRetrieval', languages=['ara', 'deu', 'fra', '...'])\n",
      "MIRACLRetrieval(name='MIRACLRetrieval', languages=['ara', 'ben', 'deu', '...'])\n",
      "MIRACLRetrievalHardNegatives(name='MIRACLRetrievalHardNegatives', languages=['ara', 'ben', 'deu', '...'])\n",
      "MLQARetrieval(name='MLQARetrieval', languages=['ara', 'deu', 'eng', '...'])\n",
      "MrTidyRetrieval(name='MrTidyRetrieval', languages=['ara', 'ben', 'eng', '...'])\n",
      "MultiLongDocRetrieval(name='MultiLongDocRetrieval', languages=['ara', 'cmn', 'deu', '...'])\n",
      "NeuCLIR2022Retrieval(name='NeuCLIR2022Retrieval', languages=['fas', 'rus', 'zho'])\n",
      "NeuCLIR2022RetrievalHardNegatives(name='NeuCLIR2022RetrievalHardNegatives', languages=['fas', 'rus', 'zho'])\n",
      "NeuCLIR2023Retrieval(name='NeuCLIR2023Retrieval', languages=['fas', 'rus', 'zho'])\n",
      "NeuCLIR2023RetrievalHardNegatives(name='NeuCLIR2023RetrievalHardNegatives', languages=['fas', 'rus', 'zho'])\n",
      "PublicHealthQARetrieval(name='PublicHealthQA', languages=['ara', 'eng', 'fra', '...'])\n",
      "StatcanDialogueDatasetRetrieval(name='StatcanDialogueDatasetRetrieval', languages=['eng', 'fra'])\n",
      "WikipediaRetrievalMultilingual(name='WikipediaRetrievalMultilingual', languages=['ben', 'bul', 'ces', '...'])\n",
      "XMarket(name='XMarket', languages=['deu', 'eng', 'spa'])\n",
      "XPQARetrieval(name='XPQARetrieval', languages=['ara', 'cmn', 'deu', '...'])\n",
      "XQuADRetrieval(name='XQuADRetrieval', languages=['arb', 'deu', 'ell', '...'])\n",
      "NorQuadRetrieval(name='NorQuadRetrieval', languages=['nob'])\n",
      "SNLRetrieval(name='SNLRetrieval', languages=['nob'])\n",
      "ArguAnaPL(name='ArguAna-PL', languages=['pol'])\n",
      "DBPediaPL(name='DBPedia-PL', languages=['pol'])\n",
      "DBPediaPLHardNegatives(name='DBPedia-PLHardNegatives', languages=['pol'])\n",
      "FiQAPLRetrieval(name='FiQA-PL', languages=['pol'])\n",
      "HotpotQAPL(name='HotpotQA-PL', languages=['pol'])\n",
      "HotpotQAPLHardNegatives(name='HotpotQA-PLHardNegatives', languages=['pol'])\n",
      "MSMARCOPL(name='MSMARCO-PL', languages=['pol'])\n",
      "MSMARCOPLHardNegatives(name='MSMARCO-PLHardNegatives', languages=['pol'])\n",
      "NFCorpusPL(name='NFCorpus-PL', languages=['pol'])\n",
      "NQPL(name='NQ-PL', languages=['pol'])\n",
      "NQPLHardNegatives(name='NQ-PLHardNegatives', languages=['pol'])\n",
      "QuoraPLRetrieval(name='Quora-PL', languages=['pol'])\n",
      "QuoraPLRetrievalHardNegatives(name='Quora-PLHardNegatives', languages=['pol'])\n",
      "SCIDOCSPL(name='SCIDOCS-PL', languages=['pol'])\n",
      "SciFactPL(name='SciFact-PL', languages=['pol'])\n",
      "TRECCOVIDPL(name='TRECCOVID-PL', languages=['pol'])\n",
      "RiaNewsRetrieval(name='RiaNewsRetrieval', languages=['rus'])\n",
      "RiaNewsRetrievalHardNegatives(name='RiaNewsRetrievalHardNegatives', languages=['rus'])\n",
      "RuBQRetrieval(name='RuBQRetrieval', languages=['rus'])\n",
      "SKQuadRetrieval(name='SKQuadRetrieval', languages=['slk'])\n",
      "SlovakSumRetrieval(name='SlovakSumRetrieval', languages=['slk'])\n",
      "SpanishPassageRetrievalS2P(name='SpanishPassageRetrievalS2P', languages=['spa'])\n",
      "SpanishPassageRetrievalS2S(name='SpanishPassageRetrievalS2S', languages=['spa'])\n",
      "SwednRetrieval(name='SwednRetrieval', languages=['swe'])\n",
      "SweFaqRetrieval(name='SweFaqRetrieval', languages=['swe'])\n",
      "TurHistQuadRetrieval(name='TurHistQuadRetrieval', languages=['tur'])\n",
      "VieQuADRetrieval(name='VieQuADRetrieval', languages=['vie'])\n",
      "T2Retrieval(name='T2Retrieval', languages=['cmn'])\n",
      "MMarcoRetrieval(name='MMarcoRetrieval', languages=['cmn'])\n",
      "DuRetrieval(name='DuRetrieval', languages=['cmn'])\n",
      "CovidRetrieval(name='CovidRetrieval', languages=['cmn'])\n",
      "CmedqaRetrieval(name='CmedqaRetrieval', languages=['cmn'])\n",
      "EcomRetrieval(name='EcomRetrieval', languages=['cmn'])\n",
      "MedicalRetrieval(name='MedicalRetrieval', languages=['cmn'])\n",
      "VideoRetrieval(name='VideoRetrieval', languages=['cmn'])\n",
      "LeCaRDv2(name='LeCaRDv2', languages=['zho'])\n",
      "mFollowIRCrossLingual(name='mFollowIRCrossLingualInstructionRetrieval', languages=['eng', 'fas', 'rus', '...'])\n",
      "mFollowIR(name='mFollowIRInstructionRetrieval', languages=['fas', 'rus', 'zho'])\n"
     ]
    }
   ],
   "source": [
    "tasks = mteb.get_tasks(task_types=['Retrieval'])\n",
    "for task in tasks:\n",
    "    print(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ara', 9), ('eng', 92), ('python', 8), ('go', 4), ('java', 4), ('javascript', 4), ('php', 4), ('ruby', 4), ('dan', 5), ('deu', 18), ('ell', 3), ('fra', 15), ('jpn', 13), ('kor', 9), ('ben', 6), ('fin', 5), ('hin', 10), ('ind', 4), ('ita', 5), ('nob', 3), ('pol', 18), ('por', 5), ('ron', 3), ('rus', 16), ('slk', 3), ('spa', 13), ('swe', 4), ('tam', 3), ('tel', 5), ('tha', 6), ('tur', 3), ('vie', 5), ('yor', 3), ('zho', 13), ('fas', 9), ('swa', 3), ('cmn', 10)]\n"
     ]
    }
   ],
   "source": [
    "langs = defaultdict(lambda: 0)\n",
    "for task in tasks:\n",
    "    for lang in task.languages:\n",
    "        langs[lang] += 1\n",
    "print([(lang, cnt) for (lang, cnt) in langs.items() if cnt >= 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mteb import FEVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FEVER(name='FEVER', languages=['eng'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fever = FEVER()\n",
    "fever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40aa4a5e956e4495961e7792b77f1a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c99f9bd9a142fe810b17226284c7f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7937 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7598e8aee7c4c678dc5a91e31a8574f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/123142 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fever.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splits: ['train', 'dev', 'test']\n",
      "train. Docs: 5416568\n",
      "train. 1928_in_association_football. {'title': '1928 in association football', 'text': 'The following are the football ( soccer ) events of the year 1928 throughout the world .'}\n",
      "train. 1986_NBA_Finals. {'title': '1986 NBA Finals', 'text': \"The 1986 NBA Finals was the championship round of the 1985 -- 86 NBA season . It pitted the Eastern Conference champion Boston Celtics against the Western Conference champion Houston Rockets , in a rematch of the 1981 Finals ( only Allen Leavell and Robert Reid remained from the Rockets ' 1981 team ) . The Celtics defeated the Rockets four games to two to win their 16th NBA championship . The championship would be the Celtics ' last until the 2008 NBA Finals . Larry Bird was named the Finals MVP .   On another note , this series marked the first time the `` NBA Finals '' branding was officially used , as they dropped the `` NBA World Championship Series '' branding which had been in use since the beginning of the league , though it had been unofficially called the `` NBA Finals '' for years .   Until the 2011 series , this was the last time the NBA Finals had started before June . Since game three , all NBA Finals games have been played in June . Starting with the following year , the NBA Finals would be held exclusively in the month of June . It was also the last NBA Finals series to schedule a game on a Monday until 1999 and also the last NBA Finals game to be played on Memorial Day .   CBS Sports used Dick Stockton and Tom Heinsohn as the play-by-play man and color commentator respectively . Meanwhile , Brent Musburger was the host and Pat O'Brien ( the Rockets ' sideline ) and Lesley Visser ( the Celtics ' sideline ) were the sideline reporters .\"}\n",
      "dev. Docs: 5416568\n",
      "dev. 1928_in_association_football. {'title': '1928 in association football', 'text': 'The following are the football ( soccer ) events of the year 1928 throughout the world .'}\n",
      "dev. 1986_NBA_Finals. {'title': '1986 NBA Finals', 'text': \"The 1986 NBA Finals was the championship round of the 1985 -- 86 NBA season . It pitted the Eastern Conference champion Boston Celtics against the Western Conference champion Houston Rockets , in a rematch of the 1981 Finals ( only Allen Leavell and Robert Reid remained from the Rockets ' 1981 team ) . The Celtics defeated the Rockets four games to two to win their 16th NBA championship . The championship would be the Celtics ' last until the 2008 NBA Finals . Larry Bird was named the Finals MVP .   On another note , this series marked the first time the `` NBA Finals '' branding was officially used , as they dropped the `` NBA World Championship Series '' branding which had been in use since the beginning of the league , though it had been unofficially called the `` NBA Finals '' for years .   Until the 2011 series , this was the last time the NBA Finals had started before June . Since game three , all NBA Finals games have been played in June . Starting with the following year , the NBA Finals would be held exclusively in the month of June . It was also the last NBA Finals series to schedule a game on a Monday until 1999 and also the last NBA Finals game to be played on Memorial Day .   CBS Sports used Dick Stockton and Tom Heinsohn as the play-by-play man and color commentator respectively . Meanwhile , Brent Musburger was the host and Pat O'Brien ( the Rockets ' sideline ) and Lesley Visser ( the Celtics ' sideline ) were the sideline reporters .\"}\n",
      "test. Docs: 5416568\n",
      "test. 1928_in_association_football. {'title': '1928 in association football', 'text': 'The following are the football ( soccer ) events of the year 1928 throughout the world .'}\n",
      "test. 1986_NBA_Finals. {'title': '1986 NBA Finals', 'text': \"The 1986 NBA Finals was the championship round of the 1985 -- 86 NBA season . It pitted the Eastern Conference champion Boston Celtics against the Western Conference champion Houston Rockets , in a rematch of the 1981 Finals ( only Allen Leavell and Robert Reid remained from the Rockets ' 1981 team ) . The Celtics defeated the Rockets four games to two to win their 16th NBA championship . The championship would be the Celtics ' last until the 2008 NBA Finals . Larry Bird was named the Finals MVP .   On another note , this series marked the first time the `` NBA Finals '' branding was officially used , as they dropped the `` NBA World Championship Series '' branding which had been in use since the beginning of the league , though it had been unofficially called the `` NBA Finals '' for years .   Until the 2011 series , this was the last time the NBA Finals had started before June . Since game three , all NBA Finals games have been played in June . Starting with the following year , the NBA Finals would be held exclusively in the month of June . It was also the last NBA Finals series to schedule a game on a Monday until 1999 and also the last NBA Finals game to be played on Memorial Day .   CBS Sports used Dick Stockton and Tom Heinsohn as the play-by-play man and color commentator respectively . Meanwhile , Brent Musburger was the host and Pat O'Brien ( the Rockets ' sideline ) and Lesley Visser ( the Celtics ' sideline ) were the sideline reporters .\"}\n"
     ]
    }
   ],
   "source": [
    "print('splits:', list(fever.corpus.keys()))\n",
    "for split, docs in fever.corpus.items():\n",
    "    print(f'{split}. Docs: {len(docs)}')\n",
    "    docids = itertools.islice(docs.keys(), 2)\n",
    "    for doc_id in docids:\n",
    "        print(f'{split}. {doc_id}. {docs[doc_id]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert fever.corpus['train'] == fever.corpus['dev'] == fever.corpus['test']\n",
    "fever.corpus['dev'] = None\n",
    "fever.corpus['test'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train. Queries: 109810\n",
      "train. 75397: <class 'str'>. Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\n",
      "train. 150448: <class 'str'>. Roman Atwood is a content creator.\n",
      "dev. Queries: 6666\n",
      "dev. 137334: <class 'str'>. Fox 2000 Pictures released the film Soul Food.\n",
      "dev. 111897: <class 'str'>. Telemundo is a English-language television network.\n",
      "test. Queries: 6666\n",
      "test. 163803: <class 'str'>. Ukrainian Soviet Socialist Republic was a founding participant of the UN.\n",
      "test. 70041: <class 'str'>. 2 Hearts is a musical composition by Minogue.\n"
     ]
    }
   ],
   "source": [
    "for split, qs in fever.queries.items():\n",
    "    print(f'{split}. Queries: {len(qs)}')\n",
    "    qids = itertools.islice(qs.keys(), 2)\n",
    "    for qid in qids:\n",
    "        print(f'{split}. {qid}: {type(qid)}. {qs[qid]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Roman Atwood is a content creator.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fever.queries['train']['150448']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train. Reldocs: 109810\n",
      "train. 75397. Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\n",
      "    {'Fox_Broadcasting_Company': 1, 'Nikolaj_Coster-Waldau': 1}\n",
      "train. 150448. Roman Atwood is a content creator.\n",
      "    {'Roman_Atwood': 1}\n",
      "dev. Reldocs: 6666\n",
      "dev. 137334. Fox 2000 Pictures released the film Soul Food.\n",
      "    {'Soul_Food_(film)': 1}\n",
      "dev. 111897. Telemundo is a English-language television network.\n",
      "    {'Telemundo': 1, 'Hispanic_and_Latino_Americans': 1}\n",
      "test. Reldocs: 6666\n",
      "test. 163803. Ukrainian Soviet Socialist Republic was a founding participant of the UN.\n",
      "    {'Ukrainian_Soviet_Socialist_Republic': 1, 'United_Nations': 1}\n",
      "test. 70041. 2 Hearts is a musical composition by Minogue.\n",
      "    {'2_Hearts_(Kylie_Minogue_song)': 1}\n"
     ]
    }
   ],
   "source": [
    "for split, reldocs in fever.relevant_docs.items():\n",
    "    print(f'{split}. Reldocs: {len(reldocs)}')\n",
    "    qids = itertools.islice(reldocs.keys(), 2)\n",
    "    for qid in qids:\n",
    "        query = fever.queries[split][qid]\n",
    "        print(f'{split}. {qid}. {query}\\n    {reldocs[qid]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"The_\"\"Chirping\"\"_Crickets\"\n",
      "\"The_\"\"Chirping\"\"_Crickets\"\n",
      "\"\"\"Heroes\"\"_(David_Bowie_album)\"\n",
      "train. max_sz: 24. vals: {1}\n",
      "dev. max_sz: 16. vals: {1}\n",
      "test. max_sz: 15. vals: {1}\n"
     ]
    }
   ],
   "source": [
    "corpus = fever.corpus['train']\n",
    "for split in 'train', 'dev', 'test':\n",
    "    reldocs = fever.relevant_docs[split]\n",
    "    max_sz = 0\n",
    "    vals = set()\n",
    "    for reldoc in reldocs.values():\n",
    "        max_sz = max(max_sz, len(reldoc))\n",
    "        for docid, val in reldoc.items():\n",
    "            docid_src = docid\n",
    "            if docid not in corpus:\n",
    "                print(docid)\n",
    "            if docid[0] == '\"' and docid[-1] == '\"':\n",
    "                docid = docid[1:-1].replace('\"\"', '\"')\n",
    "            assert docid in corpus, f'`{docid_src}` -> `{docid}`'\n",
    "            vals.add(val)\n",
    "    print(f'{split}. max_sz: {max_sz}. vals: {vals}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 109810 queries into /home/misha/data/fever/queries_train.tsv\n",
      "Writing 6666 queries into /home/misha/data/fever/queries_dev.tsv\n",
      "Writing 6666 queries into /home/misha/data/fever/queries_test.tsv\n"
     ]
    }
   ],
   "source": [
    "def write_qs(queries: dict[str, str], fpath: Path) -> pd.DataFrame:\n",
    "    qids, qs = [], []\n",
    "    for qid, query in queries.items():\n",
    "        assert '\\t' not in query, query\n",
    "        qid = int(qid)\n",
    "        qids.append(qid)\n",
    "        qs.append(query)\n",
    "    df = pd.DataFrame({'queryid': qids, 'query': qs})\n",
    "    write_tsv(df, fpath)\n",
    "    return df\n",
    "\n",
    "for split, qs in fever.queries.items():\n",
    "    fname = FEVER_QS_FPATH.with_suffix('')\n",
    "    fname = f'{fname}_{split}.tsv'\n",
    "    fpath = FEVER_QS_FPATH.parent / fname\n",
    "    print(f'Writing {len(qs)} queries into {fpath}')\n",
    "    write_qs(qs, fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fever corpus dump: 100%|██████████| 5416568/5416568 [00:41<00:00, 131451.23doc/s]\n"
     ]
    }
   ],
   "source": [
    "def write_docs(docs: dict[str, dict[str, str]], docs_fpath: Path, docs_off_fpath: Path) -> tuple[pd.DataFrame, dict[str, int]]:\n",
    "    n_docs = len(docs)\n",
    "    docids = sorted(docs.keys())\n",
    "    pbar = tqdm(docids, total=n_docs, desc='Fever corpus dump', unit='doc')\n",
    "    docidn, docoff = np.arange(n_docs), np.full(n_docs, 0, dtype=int)\n",
    "    docid_to_num = {}\n",
    "    with open(docs_fpath, 'w', encoding='utf-8') as f:\n",
    "        for i, docid in enumerate(pbar):\n",
    "            docid_to_num[docid] = docidn[i]\n",
    "            doc = docs[docid]\n",
    "            off = f.tell()\n",
    "            docoff[i] = off\n",
    "            title, text = doc['title'], doc['text']\n",
    "            assert '\\t' not in title and '\\t' not in text\n",
    "            f.write(f'{docidn[i]}\\t{docid}\\t{title}\\t{text}\\n')\n",
    "    df_off = pd.DataFrame({'docidn': docidn, 'offset': docoff})\n",
    "    write_tsv(df_off, docs_off_fpath)\n",
    "    return df_off, docid_to_num\n",
    "\n",
    "df_off, docid_to_num = write_docs(corpus, FEVER_DOCS_FPATH, FEVER_DOCS_OFF_FPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 109810 qrels into /home/misha/data/fever/qrels_train.tsv\n",
      "Writing 6666 qrels into /home/misha/data/fever/qrels_dev.tsv\n",
      "Writing 6666 qrels into /home/misha/data/fever/qrels_test.tsv\n"
     ]
    }
   ],
   "source": [
    "def write_qrels(qrels: dict[str, dict[str, int]], docid_to_num: dict[str, int], fpath: Path) -> pd.DataFrame:\n",
    "    qids, dids = [], []\n",
    "    for qid, reldocs in qrels.items():\n",
    "        qid = int(qid)\n",
    "        for docid, num in reldocs.items():\n",
    "            assert num == 1\n",
    "            # This fix is needed to find docid in Fever corpus\n",
    "            if docid[0] == '\"' and docid[-1] == '\"':\n",
    "                docid = docid[1:-1].replace('\"\"', '\"')\n",
    "            docid_num = docid_to_num[docid]\n",
    "            qids.append(qid)\n",
    "            dids.append(docid_num)\n",
    "    df_qrels = pd.DataFrame({'queryid': qids, 'docidn': dids})\n",
    "    write_tsv(df_qrels, fpath)\n",
    "    return df_qrels\n",
    "\n",
    "for split, qrels in fever.relevant_docs.items():\n",
    "    fname = FEVER_QRELS_FPATH.with_suffix('')\n",
    "    fname = f'{fname}_{split}.tsv'\n",
    "    fpath = FEVER_QRELS_FPATH.parent / fname\n",
    "    print(f'Writing {len(qrels)} qrels into {fpath}')\n",
    "    write_qrels(qrels, docid_to_num, fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SadeemQuestionRetrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mteb import SadeemQuestionRetrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SadeemQuestionRetrieval(name='SadeemQuestionRetrieval', languages=['ara'])\n"
     ]
    }
   ],
   "source": [
    "sdm = SadeemQuestionRetrieval()\n",
    "print(sdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222fb807fdee49ab8b0831051a938ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48905ccc4d304bfb914fbc5741bca8fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/27.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad577ab621f4725a78f16201f727350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/9.89M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827c6c4ff1ba418d91c88180b3e3cc63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/152k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9ef842b7bd4d40915454c79f557e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating qrels split:   0%|          | 0/2089 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e971bf7b6afc42d8bf35f247a93e7689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating corpus split:   0%|          | 0/22979 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b6ffa10330b455481a28a3be0c06479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating queries split:   0%|          | 0/2089 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sdm.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = sdm\n",
    "list(ds.corpus.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splits: ['test']\n",
      "test. Docs: 22979\n",
      "test. 1. وتعد الضميرية من أهم مراكز المدينة المنورة وتقع في الجزء الجنوبي الشرقي من منطقة المدينة المنورة على بعد (90) كلم وهي تابعة لمحافظة الحناكية وتبعد عنها 166 كم . وتبعد عن محافظة مهد الذهب 85 كم\n",
      "test. 2. في الاحتفال بيوم النباتات الطلابية في هلسنكي في 13 مايو 1848، تم رفع علم اتحاد طلاب هلسنكي. كان علمًا مُخيطًا من قماش الحرير الأبيض للاحتفال، مع شعار الأسد لدوقية فنلندا الكبرى محاطًا بأوراق الغار. تم\n"
     ]
    }
   ],
   "source": [
    "print('splits:', list(ds.corpus.keys()))\n",
    "for split, docs in ds.corpus.items():\n",
    "    print(f'{split}. Docs: {len(docs)}')\n",
    "    docids = itertools.islice(docs.keys(), 2)\n",
    "    for doc_id in docids:\n",
    "        txt = docs[doc_id]['text'].replace('\\n', '\\\\n')\n",
    "        print(f'{split}. {doc_id}. {txt[:200]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', {'29': 1}), ('2', {'50': 1}), ('3', {'83': 1})]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ds.relevant_docs['test'].items())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StackOverflowQARetrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mteb import StackOverflowQARetrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackOverflowQARetrieval(name='StackOverflowQA', languages=['eng'])\n"
     ]
    }
   ],
   "source": [
    "soqa = StackOverflowQARetrieval()\n",
    "print(soqa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e896404df0e49faaf7381d96d432eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/2.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05bbcfb8f2a9486dae5ed288f701e25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/13.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674e8401cf51441d8e0c86d85dde1196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating corpus split:   0%|          | 0/19931 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0444a25a6e4df3b60eeb103010f989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/19931 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b2179091cc41e0914409cfe869ffd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/14.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e340cac83c41d2913ccf8f46270042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating queries split:   0%|          | 0/19931 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6249cee350a8434281f77c45a5dabb57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/19931 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674a7be80605485cb7469335f9c6dbff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/159k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3bb90d6e3b0410ea4a0d60401c37615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dace64a211849098f2f93671fa90961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/13951 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d314de7f847d4574b3613ff681291a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1994 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e7a7eef77f42fe99fdb4083e9f402a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1994 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a04703791c5477d91e9a6a3e02735d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1994 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2352b1f2e14848358536a4d03b02ba1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/19931 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "soqa.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splits: ['test']\n",
      "test. Docs: 19931\n",
      "test. d1.  The SearchDatabase class that SphinxSearch extends was changed from REL1_31 to REL1_32. It now requires you to define doSearchTextInDB and doSearchTitleInDB methods.\\nSee REL1_31 https://doc.wikimedi\n",
      "test. d2.  you have to write below way because CTE is part of the SELECT not the UPDATE\\nupdate work_request \\nset name = name || '_old'\\n\\n   where exists (\\n      with wr_double as\\n         (select...)\\n    \n"
     ]
    }
   ],
   "source": [
    "ds = soqa\n",
    "print('splits:', list(ds.corpus.keys()))\n",
    "for split, docs in ds.corpus.items():\n",
    "    print(f'{split}. Docs: {len(docs)}')\n",
    "    docids = itertools.islice(docs.keys(), 2)\n",
    "    for doc_id in docids:\n",
    "        txt = docs[doc_id].replace('\\n', '\\\\n')\n",
    "        print(f'{split}. {doc_id}. {txt[:200]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('q17938', {'d17938': 1}),\n",
       " ('q17939', {'d17939': 1}),\n",
       " ('q17940', {'d17940': 1})]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ds.relevant_docs['test'].items())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
