{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import re\n",
    "import requests\n",
    "import sys\n",
    "from typing import Optional\n",
    "\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pydantic_yaml import parse_yaml_file_as, to_yaml_file\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertGenerationEncoder, BertGenerationDecoder, EncoderDecoderModel, BertTokenizer, AutoTokenizer\n",
    "from transformers.modeling_outputs import Seq2SeqLMOutput, BaseModelOutputWithPastAndCrossAttentions, CausalLMOutputWithCrossAttentions\n",
    "\n",
    "from mllm.config.model import GenmixTrainDsType, TokensAggType, GenmixembBertCfg, copy_override_genmixemb_bert_cfg, \\\n",
    "    gen_prefpostfix_genmixemb_bert\n",
    "from mllm.exp.args import GENMIXEMB_BERT_MODEL_CFG_FNAME, create_bool_str_field, is_arg_true\n",
    "from mllm.model.genmixemb_bert import GenmixembBert\n",
    "from mllm.train.mask_utils import MaskCfg\n",
    "from mllm.train.utils import find_create_train_path, log_weights_grads_stats, SumTuple, QnaTuple\n",
    "from mllm.data.wiki.itwiki import WikiItem, get_wiki_batch_iterators, WikiBatch\n",
    "from mllm.utils.utils import rethrow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Generator model inference\n",
    "## Configs and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "n_toks_max = 100\n",
      "MaskCfg(sep_freq=0.5, sep_frac=0.15, seq_freq=0.5, seq_max_frac=0.2, seq_max_len=20)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(os.path.expandvars('$HOME')) / 'data'\n",
    "\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "random_seed = 111\n",
    "train_genmixemb_bert_path = DATA_PATH / 'train_mllm_genmixemb_bert'\n",
    "genmixemb_subdir = 'genmixemb-20250713_202718-bertbaseuncased-d768-mxo50-aggBrt-sub0-dsWki-tmax100-tragF'\n",
    "genmixemb_subdir = 'genmixemb-20250715_035750-bertbaseuncased-d768-mxo50-aggBrt-sub2-dsWki-tmax100-tragT'\n",
    "genmixemb_subdir = 'genmixemb-20250716_213252-bertbaseuncased-d768-mxo50-aggBrt-sub0-dsWki-tmax100-msk_sep_0.5/0.15_seq_0.5/0.2/20-tragF'\n",
    "\n",
    "genmixemb_train_path = train_genmixemb_bert_path / genmixemb_subdir\n",
    "genmixemb_snapshot_fpath = genmixemb_train_path / 'best.pth'\n",
    "\n",
    "device_name = 'cpu'\n",
    "# device_name = 'cuda'\n",
    "\n",
    "device = torch.device(device_name)\n",
    "print(device)\n",
    "\n",
    "parts = genmixemb_subdir.split('-')\n",
    "n_toks_max = 0\n",
    "mask_cfg = None\n",
    "for part in parts:\n",
    "    if part.startswith('tmax'):\n",
    "        n_toks_max = int(part[4:])\n",
    "    elif part.startswith('msk_'):\n",
    "        subparts = part.split('_')\n",
    "        # postfix_parts.append(f'msk_sep_{sep_freq}/{sep_frac}_seq_{seq_freq}/{seq_max_frac}/{mask_cfg.seq_max_len}')\n",
    "        sep_part, seq_part = subparts[2], subparts[4]\n",
    "        sep_freq, sep_frac = sep_part.split('/')\n",
    "        seq_freq, seq_max_frac, seq_max_len = seq_part.split('/')\n",
    "        sep_freq, sep_frac = float(sep_freq), float(sep_frac)\n",
    "        seq_freq, seq_max_frac, seq_max_len = float(seq_freq), float(seq_max_frac), int(seq_max_len)\n",
    "        mask_cfg = MaskCfg(\n",
    "            sep_freq=sep_freq, sep_frac=sep_frac, seq_freq=seq_freq, seq_max_frac=seq_max_frac,\n",
    "            seq_max_len=seq_max_len,\n",
    "        )\n",
    "\n",
    "print(f'n_toks_max = {n_toks_max}')\n",
    "print(mask_cfg)\n",
    "\n",
    "batch_size = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenmixembBertCfg(bert_model_name='bert-base-uncased', d_model=768, max_out_toks=50, toks_agg_type=<TokensAggType.Bert: 'brt'>, bert_agg_n_subseq_toks=0, pyr_agg_n_levels=0, pyr_agg_n_layers_per_level=0, train_agg_model=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cfg = parse_yaml_file_as(GenmixembBertCfg, genmixemb_train_path / GENMIXEMB_BERT_MODEL_CFG_FNAME)\n",
    "model_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models and dataset\n",
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type bert-generation. This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type bert to instantiate a model of type bert-generation. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of BertGenerationDecoder were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'lm_head.bias', 'lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = GenmixembBert(model_cfg, device=device)\n",
    "tkz = model.tkz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load /home/misha/data/train_mllm_genmixemb_bert/genmixemb-20250716_213252-bertbaseuncased-d768-mxo50-aggBrt-sub0-dsWki-tmax100-msk_sep_0.5/0.15_seq_0.5/0.2/20-tragF/best.pth\n"
     ]
    }
   ],
   "source": [
    "print(f'Load {genmixemb_snapshot_fpath}')\n",
    "checkpoint = torch.load(genmixemb_snapshot_fpath, map_location=device)\n",
    "model.load_state_dict(checkpoint['model'], strict=True)\n",
    "del checkpoint\n",
    "model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wiki dataset\n",
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bf85bfe64548cca1196631e5321b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia 20220301.en docs: 6458670\n"
     ]
    }
   ],
   "source": [
    "wiki_ds_name, wiki_ds_subdir = '20220301.en', 'wikipedia'\n",
    "dss_wiki = load_dataset(wiki_ds_subdir, wiki_ds_name, cache_dir=str(DATA_PATH))\n",
    "ds_wiki = dss_wiki['train']\n",
    "n_docs = len(ds_wiki)\n",
    "print(f'Wikipedia {wiki_ds_name} docs: {n_docs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wiki_batch(i_batch: int, batch_size: int = batch_size) -> WikiBatch:\n",
    "    i1 = i_batch * batch_size\n",
    "    i2 = i1 + batch_size\n",
    "    items = []\n",
    "    for i in range(i1, i2):\n",
    "        row = ds_wiki[i]\n",
    "        wiki_item = WikiItem(\n",
    "            tkz=tkz, ind=i, title=row['title'], text=row['text'], max_len=n_toks_max, mask_cfg=mask_cfg,\n",
    "        )\n",
    "        items.append(wiki_item)\n",
    "    batch = WikiBatch(items=items, device=device)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wiki inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8349 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "i_batch = 0\n",
    "batch = get_wiki_batch(i_batch)\n",
    "# [n_batch, max_len]\n",
    "b_toks, b_masked_toks, b_mask = batch.get_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000. anarchism is a political philosophy and movement that is sceptical of authority and rejects all involuntary, coercive forms of hierarchy. anarchism calls for the abolition of the state, which it holds to be unnecessary, undesirable, and harmful. as a historically left - wing movement, placed on the farthest left of the political spectrum, it is usually described alongside communalism and libertarian marxism as the libertarian wing ( libertarian socialism ) of the socialist movement, and has a strong\n",
      "000. anarchism is a political philosophy and movement that is sceptical of authority and rejects all involuntary, [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] to be unnecessary, undesirable, and harmful. as a historically left - wing movement, placed on the farthest left of the political spectrum, it is usually described alongside communalism and libertarian marxism as the libertarian wing ( libertarian socialism ) of the socialist movement, and has a strong\n",
      "000. [CLS] anarchism is a political philosophy and movement that is sceptical of authority and rejected all involuntary, non - profit, non - profit, non - profit, non - profit, non - profit, considered to be obsolete, undesirable\n",
      "001. autism is a neurodevelopmental disorder characterized by difficulties with social interaction and communication, and by restricted and repetitive behavior. parents often notice signs during the first three years of their child's life. these signs often develop gradually, though some autistic children experience regression in their communication and social skills after reaching developmental milestones at a normal pace. autism is associated with a combination of genetic and environmental factors. risk factors during pregnancy include certain infections, such as rubella, toxins including\n",
      "001. autism is a neurodevelopmental disorder characterized by difficulties with social interaction and communication, and by restricted and repetitive behavior. parents often notice signs during the first three years of their child's life. these signs often develop gradually, though some autistic children experience regression in their communication and social skills after reaching developmental milestones at a normal pace. autism is associated [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK], toxins including\n",
      "001. [CLS] autism is a neurodevelopmental disorder characterized by difficulties with social interaction and communication, and by restricted and repetitive behavior. parents often notice signs during the first three years of their child's life. these signs often develop gradually, though some\n",
      "002. albedo ( ; ) is the measure of the diffuse reflection of solar radiation out of the total solar radiation and measured on a scale from 0, corresponding to a black body that absorbs all incident radiation, to 1, corresponding to a body that reflects all incident radiation. surface albedo is defined as the ratio of radiosity je to the irradiance ee ( flux per unit area ) received by a surface. the proportion reflected is not only determined by properties of the surface itself, but also by\n",
      "002. albedo ( ; ) is the measure of the diffuse [MASK] of solar radiation out of the total solar radiation and measured on a scale [MASK] 0 [MASK] corresponding to a [MASK] [MASK] that [MASK] [MASK] all incident radiation, to 1, corresponding to [MASK] body that reflects all incident radiation [MASK] surface [MASK] [MASK] is defined as the ratio [MASK] radiosity je [MASK] [MASK] [MASK] [MASK] [MASK] ee ( flux per unit area ) received by a surface. the [MASK] reflected [MASK] not only determined by properties of the surface itself, but also [MASK]\n",
      "002. [CLS] albedo ( ; ) is the measure of the diffuse intensity of solar radiation out of the total solar radiation and measured on a scale of 0, corresponding to a mollusc that reflects all incident radiation, to 1, corresponding to a body that reflects\n",
      "003. a, or a, is the first letter and the first vowel of the modern english alphabet and the iso basic latin alphabet. its name in english is a ( pronounced ), plural aes. it is similar in shape to the ancient greek letter alpha, from which it derives. the uppercase version consists of the two slanting sides of a triangle, crossed in the middle by a horizontal bar. the lowercase version can be written in two forms : the double - storey a and single - storey\n",
      "003. a, or a [MASK] is the first letter and the first [MASK] of [MASK] modern english [MASK] and the iso basic [MASK] alphabet. [MASK] name in english is a ( pronounced ), plural aes. it is similar in shape [MASK] the ancient [MASK] letter alpha, from which it derives. the [MASK] [MASK] version consists of the two [MASK] [MASK] sides of a triangle, [MASK] in the middle by a [MASK] bar [MASK] [MASK] lowercase version [MASK] [MASK] written in two forms : the double - storey a and single - storey\n",
      "003. [CLS] a, or a, is the first letter and the first letter of the modern english alphabet and the iso basic english alphabet. its name in english is a ( pronounced ), plural aes. it is similar in shape to the ancient greek letter alpha\n",
      "004. alabama ( ) is a state in the southeastern region of the united states, bordered by tennessee to the north ; georgia to the east ; florida and the gulf of mexico to the south ; and mississippi to the west. alabama is the 30th largest by area and the 24th - most populous of the u. s. states. with a total of of inland waterways, alabama has among the most of any state. alabama is nicknamed the yellowhammer state, after the state bird. alabama is also known as the\n",
      "004. alabama ( ) is a state in the southeastern region of the united states, bordered by tennessee to the north ; georgia to the east ; florida and the gulf of mexico to the south ; and mississippi to the west. alabama [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] with a total of of inland waterways, alabama has among the most of any state. alabama is nicknamed the yellowhammer state, after the state bird. alabama is also known as the\n",
      "004. [CLS] alabama ( ) is a state in the southeastern region of the united states, bordered by tennessee to the north ; georgia to the east ; florida and the gulf of mexico to the south ; and mississippi to the west. alabama has a total area of,\n"
     ]
    }
   ],
   "source": [
    "# with_mask = False\n",
    "with_mask = True\n",
    "for i in range(batch_size):\n",
    "    toks, masked_toks, mask = b_toks[i], b_masked_toks[i], b_mask[i]\n",
    "    toks_inp = masked_toks if with_mask else toks\n",
    "    toks_out = model.gen_on_wiki(toks=toks_inp)\n",
    "    toks_out = toks_out.squeeze(0)\n",
    "    s_inp = tkz.decode(toks_inp)\n",
    "    s_out = tkz.decode(toks_out)\n",
    "    if with_mask:\n",
    "        s_src = tkz.decode(toks)\n",
    "        print(f'{i:03d}. {s_src}')\n",
    "    print(f'{i:03d}. {s_inp}')\n",
    "    print(f'{i:03d}. {s_out}')\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(100)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(b_masked_toks == tkz.mask_token_id).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
