{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import re\n",
    "import requests\n",
    "import sys\n",
    "from typing import Optional\n",
    "\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pydantic_yaml import parse_yaml_file_as, to_yaml_file\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertGenerationEncoder, BertGenerationDecoder, EncoderDecoderModel, BertTokenizer, AutoTokenizer\n",
    "from transformers.modeling_outputs import Seq2SeqLMOutput, BaseModelOutputWithPastAndCrossAttentions, CausalLMOutputWithCrossAttentions\n",
    "\n",
    "from mllm.config.model import GenmixTrainDsType, TokensAggType, GenmixembBertCfg, copy_override_genmixemb_bert_cfg, \\\n",
    "    gen_prefpostfix_genmixemb_bert\n",
    "from mllm.exp.args import GENMIXEMB_BERT_MODEL_CFG_FNAME, create_bool_str_field, is_arg_true\n",
    "from mllm.model.genmixemb_bert import GenmixembBert\n",
    "from mllm.train.mask_utils import MaskCfg\n",
    "from mllm.train.utils import find_create_train_path, log_weights_grads_stats, SumTuple, QnaTuple\n",
    "from mllm.data.wiki.itwiki import WikiItem, get_wiki_batch_iterators, WikiBatch\n",
    "from mllm.utils.utils import rethrow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Generator model inference\n",
    "## Configs and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "n_toks_max = 256\n",
      "None\n",
      "pred_next_sent = True\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(os.path.expandvars('$HOME')) / 'data'\n",
    "\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "random_seed = 111\n",
    "train_genmixemb_bert_path = DATA_PATH / 'train_mllm_genmixemb_bert'\n",
    "genmixemb_subdir = 'genmixemb-20250713_202718-bertbaseuncased-d768-mxo50-aggBrt-sub0-dsWki-tmax100-tragF'\n",
    "genmixemb_subdir = 'genmixemb-20250715_035750-bertbaseuncased-d768-mxo50-aggBrt-sub2-dsWki-tmax100-tragT'\n",
    "genmixemb_subdir = 'genmixemb-20250716_213252-bertbaseuncased-d768-mxo50-aggBrt-sub0-dsWki-tmax100-msk_sep_0.5/0.15_seq_0.5/0.2/20-tragF'\n",
    "genmixemb_subdir = 'genmixemb-20250718_220105-bertbaseuncased-d768-mxo50-aggBrt-sub2-dsWki-tmax100-tragT'\n",
    "genmixemb_subdir = 'genmixemb-20250721_083250-bertbaseuncased-d768-mxo50-aggPyr-agtDecim-stp0-lvl1-lrs2-dsWki-tmax256-tragF-nxtsnt'\n",
    "\n",
    "genmixemb_train_path = train_genmixemb_bert_path / genmixemb_subdir\n",
    "genmixemb_snapshot_fpath = genmixemb_train_path / 'best.pth'\n",
    "\n",
    "device_name = 'cpu'\n",
    "# device_name = 'cuda'\n",
    "\n",
    "device = torch.device(device_name)\n",
    "print(device)\n",
    "\n",
    "parts = genmixemb_subdir.split('-')\n",
    "n_toks_max = 0\n",
    "mask_cfg = None\n",
    "pred_next_sent = False\n",
    "for part in parts:\n",
    "    if part.startswith('tmax'):\n",
    "        n_toks_max = int(part[4:])\n",
    "    elif part.startswith('msk_'):\n",
    "        subparts = part.split('_')\n",
    "        # postfix_parts.append(f'msk_sep_{sep_freq}/{sep_frac}_seq_{seq_freq}/{seq_max_frac}/{mask_cfg.seq_max_len}')\n",
    "        sep_part, seq_part = subparts[2], subparts[4]\n",
    "        sep_freq, sep_frac = sep_part.split('/')\n",
    "        seq_freq, seq_max_frac, seq_max_len = seq_part.split('/')\n",
    "        sep_freq, sep_frac = float(sep_freq), float(sep_frac)\n",
    "        seq_freq, seq_max_frac, seq_max_len = float(seq_freq), float(seq_max_frac), int(seq_max_len)\n",
    "        mask_cfg = MaskCfg(\n",
    "            sep_freq=sep_freq, sep_frac=sep_frac, seq_freq=seq_freq, seq_max_frac=seq_max_frac,\n",
    "            seq_max_len=seq_max_len,\n",
    "        )\n",
    "    elif part == 'nxtsnt':\n",
    "        pred_next_sent = True\n",
    "\n",
    "print(f'n_toks_max = {n_toks_max}')\n",
    "print(mask_cfg)\n",
    "print(f'pred_next_sent = {pred_next_sent}')\n",
    "\n",
    "batch_size = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bert_agg_n_subseq_toks': 2,\n",
      " 'bert_model_name': 'bert-base-uncased',\n",
      " 'd_model': 768,\n",
      " 'max_out_toks': 50,\n",
      " 'pyr_agg_n_layers_per_level': 2,\n",
      " 'pyr_agg_n_levels': 1,\n",
      " 'pyr_agg_step': 0,\n",
      " 'pyr_agg_type': <HgReductType.Decim: 'decim'>,\n",
      " 'toks_agg_type': <TokensAggType.Pyramid: 'pyr'>,\n",
      " 'train_agg_model': False}\n"
     ]
    }
   ],
   "source": [
    "model_cfg = parse_yaml_file_as(GenmixembBertCfg, genmixemb_train_path / GENMIXEMB_BERT_MODEL_CFG_FNAME)\n",
    "pprint(model_cfg.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models and dataset\n",
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type bert-generation. This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type bert to instantiate a model of type bert-generation. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of BertGenerationDecoder were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'lm_head.bias', 'lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = GenmixembBert(model_cfg, device=device)\n",
    "tkz = model.tkz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load /home/misha/data/train_mllm_genmixemb_bert/genmixemb-20250721_083250-bertbaseuncased-d768-mxo50-aggPyr-agtDecim-stp0-lvl1-lrs2-dsWki-tmax256-tragF-nxtsnt/best.pth\n"
     ]
    }
   ],
   "source": [
    "print(f'Load {genmixemb_snapshot_fpath}')\n",
    "checkpoint = torch.load(genmixemb_snapshot_fpath, map_location=device)\n",
    "model.load_state_dict(checkpoint['model'], strict=True)\n",
    "del checkpoint\n",
    "model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wiki dataset\n",
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed5ef8e09b245fb994ad49ed149c20a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia 20220301.en docs: 6458670\n"
     ]
    }
   ],
   "source": [
    "wiki_ds_name, wiki_ds_subdir = '20220301.en', 'wikipedia'\n",
    "dss_wiki = load_dataset(wiki_ds_subdir, wiki_ds_name, cache_dir=str(DATA_PATH))\n",
    "ds_wiki = dss_wiki['train']\n",
    "n_docs = len(ds_wiki)\n",
    "print(f'Wikipedia {wiki_ds_name} docs: {n_docs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wiki_batch(i_batch: int, batch_size: int = batch_size) -> WikiBatch:\n",
    "    i1 = i_batch * batch_size\n",
    "    i2 = i1 + batch_size\n",
    "    items = []\n",
    "    for i in range(i1, i2):\n",
    "        row = ds_wiki[i]\n",
    "        wiki_item = WikiItem(\n",
    "            tkz=tkz, ind=i, title=row['title'], text=row['text'], max_len=n_toks_max, mask_cfg=mask_cfg, pred_next_sent=pred_next_sent,\n",
    "            max_pred_len=model_cfg.max_out_toks,\n",
    "        )\n",
    "        items.append(wiki_item)\n",
    "    batch = WikiBatch(items=items, device=device)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wiki inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_batch = 0\n",
    "batch = get_wiki_batch(i_batch)\n",
    "# [n_batch, max_len]\n",
    "b_toks, b_masked_toks, b_mask, b_tgt_toks = batch.get_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000. this argument is true in following both authorities'successful and mistaken instruction. anarchists reject this criticism because challenging or disobeying authority does not entail the disappearance of its advantages by acknowledging authority such as doctors or lawyers as reliable, nor does it involve a complete surrender of independent judgment. anarchist perception of human nature, rejection of the state, and commitment to social revolution has been criticised by academics as naive, overly simplistic, and unrealistic, respectively. classical anarchism has been criticised for relying too heavily on the belief that the abolition of the state will lead to human cooperation prospering. friedrich engels, considered to be one of the principal founders of marxism, criticised anarchism's anti - authoritarianism as inherently counter - revolutionary because in his view a revolution is by itself authoritarian. academic john molyneux writes in his book anarchism : a marxist criticism that \" anarchism cannot win \", believing that it lacks the ability to properly implement its ideas. the marxist criticism of anarchism is that it has a utopian character because all individuals should have anarchist views and values. according to the marxist view, that a social idea would follow directly from this human ideal and out of the free will of every individual formed its essence.\n",
      "000. Out: [CLS] the marxist criticism of anarchism is a critique of the theory of the state, which is a critique of the self - defense of the people. the marxist criticism of anarchism is a critique of the self - defense of the people. the\n",
      "000. Target: marxists state that this contradiction was responsible for their inability to act. in the anarchist vision, the conflict between liberty and equality was resolved through coexistence and intertwining. see also anarchism by country governance without government list of\n",
      "001. ##chological reports are often poorly communicated to educators, resulting in a gap between what a report recommends and what education is provided. it is not known whether treatment programs for children lead to significant improvements after the children grow up, and the limited research on the effectiveness of adult residential programs shows mixed results. the appropriateness of including children with varying severity of autism spectrum disorders in the general education population is a subject of current debate among educators and researchers. medication medications may be used to treat asd symptoms that interfere with integrating a child into home or school when behavioral treatment fails. they may also be used for associated health problems, such as adhd or anxiety. more than half of us children diagnosed with asd are prescribed psychoactive drugs or anticonvulsants, with the most common drug classes being antidepressants, stimulants, and antipsychotics. the atypical antipsychotic drugs risperidone and aripiprazole are fda - approved for treating associated aggressive and self - injurious behaviors. however, their side effects must be weighed against their potential benefits, and autistic people may respond atypically. side effects, for example, may include weight gain, tiredness, drooling, and aggression.\n",
      "001. Out: [CLS] the use of asd symptoms may be used to reduce the effects of the effects of asd. the use of asd symptoms may be used to reduce the effects of asd. the use of asd symptoms may be used to reduce the effects\n",
      "001. Target: ssri antidepressants, such as fluoxetine and fluvoxamine, have been shown to be effective in reducing repetitive and ritualistic behaviors, while the stimulant medication methylphenidate is beneficial for some children with\n",
      "002. light, waviness results in reduced reflectivity because of the steepness of the reflectivity - vs. - incident - angle curve and a locally increased average incident angle. although the reflectivity of water is very low at low and medium angles of incident light, it becomes very high at high angles of incident light such as those that occur on the illuminated side of earth near the terminator ( early morning, late afternoon, and near the poles ). however, as mentioned above, waviness causes an appreciable reduction. because light specularly reflected from water does not usually reach the viewer, water is usually considered to have a very low albedo in spite of its high reflectivity at high angles of incident light. note that white caps on waves look white ( and have high albedo ) because the water is foamed up, so there are many superimposed bubble surfaces which reflect, adding up their reflectivities. fresh'black'ice exhibits fresnel reflection. snow on top of this sea ice increases the albedo to 0. 9. clouds cloud albedo has substantial influence over atmospheric temperatures. different types of clouds exhibit different reflectivity, theoretically ranging in albedo from a minimum of near 0 to a maximum approaching 0. 8.\n",
      "002. Out: [CLS] the cloud albedo is generally higher than the average of the solar system. the cloud albedo is higher than the solar system, and the cloud albedo is higher than the solar system. the cloud albedo is less than the solar system. the\n",
      "002. Target: \" on any given day, about half of earth is covered by clouds, which reflect more sunlight than land and water. clouds keep earth cool by reflecting sunlight, but they can also serve as blankets to trap warmth. \" albedo and climate in some\n",
      "003. x - sampa, is used for the open front unrounded vowel and is used for the open back unrounded vowel. other uses in algebra, the letter a along with various other letters of the alphabet is often used to denote a variable, with various conventional meanings in different areas of mathematics. moreover, in 1637, rene descartes \" invented the convention of representing unknowns in equations by x, y, and z, and knowns by a, b, and c \", and this convention is still often followed, especially in elementary algebra. in geometry, capital a, b, c etc. are used to denote segments, lines, rays, etc. a capital a is also typically used as one of the letters to represent an angle in a triangle, the lowercase a representing the side opposite angle a. \" a \" is often used to denote something or someone of a better or more prestigious quality or status : a -, a or a +, the best grade that can be assigned by teachers for students'schoolwork ; \" a grade \" for clean restaurants ; a - list celebrities, etc. such associations can have a motivating effect, as exposure to the letter a has been found to improve performance, when compared with other letters.\n",
      "003. Out: [CLS] the letter a is used to refer to a letter a, which is used to refer to a letter a. the letter a is used to refer to a letter a. the letter a is used to refer to a letter a. the letter a is\n",
      "003. Target: \" a \" is used as a prefix on some words, such as asymmetry, to mean \" not \" or \" without \" ( from greek ). in english grammar, \" a \", and its variant \" an \", is an indefinite\n",
      "004. ##ized. the current chief justice of the alabama supreme court is republican tom parker. all sitting justices on the alabama supreme court are members of the republican party. there are two intermediate appellate courts, the court of civil appeals and the court of criminal appeals, and four trial courts : the circuit court ( trial court of general jurisdiction ), and the district, probate, and municipal courts. some critics believe the election of judges has contributed to an exceedingly high rate of executions. alabama has the highest per capita death penalty rate in the country. in some years, it imposes more death sentences than does texas, a state which has a population five times larger. however, executions per capita are significantly higher in texas. some of its cases have been highly controversial ; the u. s. supreme court has overturned 24 convictions in death penalty cases. it was the only state to allow judges to override jury decisions in whether or not to use a death sentence ; in 10 cases judges overturned sentences of life imprisonment without parole that were voted unanimously by juries. this judicial authority was removed in april 2017. taxes taxes are collected by the alabama department of revenue. alabama levies a 2 %, 4 %, or5 % personal income tax, depending on the amount earned and filing status.\n",
      "004. Out: [CLS] the tax system is also used by the alabama department of revenue. the alabama department of revenue ( u. s. ) is the only state to pay the tax. the alabama department of revenue ( u. s. ) is the only state to pay\n",
      "004. Target: taxpayers are allowed to deduct their federal income tax from their alabama state tax, even if taking the standard deduction ; those who itemize can also deduct fica ( the social security and medicare tax ). the state's general\n"
     ]
    }
   ],
   "source": [
    "with_mask = False\n",
    "# with_mask = True\n",
    "for i in range(batch_size):\n",
    "    toks, masked_toks, mask = b_toks[i], b_masked_toks[i], b_mask[i]\n",
    "    tgt_toks = None\n",
    "    if b_tgt_toks is not None:\n",
    "        tgt_toks = b_tgt_toks[i]\n",
    "    toks_inp = masked_toks if with_mask else toks\n",
    "    toks_out = model.gen_on_wiki(toks=toks_inp)\n",
    "    toks_out = toks_out.squeeze(0)\n",
    "    s_inp = tkz.decode(toks_inp)\n",
    "    s_out = tkz.decode(toks_out)\n",
    "    if with_mask:\n",
    "        s_src = tkz.decode(toks)\n",
    "        print(f'{i:03d}. Msk: {s_src}')\n",
    "    print(f'{i:03d}. Inp: {s_inp}')\n",
    "    if tgt_toks is not None:\n",
    "        s_tgt = tkz.decode(tgt_toks)\n",
    "        print(f'{i:03d}. Tgt: {s_tgt}')\n",
    "    print(f'{i:03d}. Out: {s_out}')\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(100)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(b_masked_toks == tkz.mask_token_id).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try nltk for sentence splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/misha/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43985 559 Anarchism is a political philosophy and movement that is sceptical of authority and rejects all involuntary, coercive forms of hierarchy. Anarchism calls for the abolition of the state, which it holds to be unnecessary, undesirable, and harmful. As a historically left-wing movement, placed on the farthest left of the political spectrum, it is usually described alongside communalism and libertarian Marxism as the libertarian wing (libertarian socialism) of the socialist movement, and has a strong historical association with anti-capitalism and socialism.\n"
     ]
    }
   ],
   "source": [
    "item = ds_wiki[0]\n",
    "txt = item['text']\n",
    "s = txt.split('\\n')[0]\n",
    "print(len(txt), len(s), s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anarchism is a political philosophy and movement that is sceptical of authority and rejects all involuntary, coercive forms of hierarchy.\n",
      "Anarchism calls for the abolition of the state, which it holds to be unnecessary, undesirable, and harmful.\n",
      "As a historically left-wing movement, placed on the farthest left of the political spectrum, it is usually described alongside communalism and libertarian Marxism as the libertarian wing (libertarian socialism) of the socialist movement, and has a strong historical association with anti-capitalism and socialism.\n"
     ]
    }
   ],
   "source": [
    "sents = sent_tokenize(s)\n",
    "for sent in sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent_tokenize avg time: 0.005308\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "t1 = timer()\n",
    "for i in range(N):\n",
    "    sents = sent_tokenize(txt)\n",
    "t2 = timer()\n",
    "delta = (t2 - t1) / N\n",
    "print(f'sent_tokenize avg time: {delta:0.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=10, out_features=20, bias=True)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.Linear(10, 20)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=10, out_features=20, bias=True)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
