{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misha/miniconda3/envs/mllm/lib/python3.10/site-packages/torchtext/datasets/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/misha/miniconda3/envs/mllm/lib/python3.10/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import Optional\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets.arrow_dataset import Dataset\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pydantic_yaml import parse_yaml_file_as\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import GPT2Tokenizer, AddedToken, PreTrainedTokenizer\n",
    "\n",
    "from mllm.data.wiki.dswiki import WikiDsLoader\n",
    "from mllm.exp.args import TOKENIZER_CFG_FNAME, ENCDEC_HG_MODEL_CFG_FNAME\n",
    "from mllm.model.encdec_ranker_hg import EncdecHg\n",
    "from mllm.config.model import TokenizerCfg, EncdecHgCfg\n",
    "from mllm.tokenization.chunk_tokenizer import tokenizer_from_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(os.path.expandvars('$HOME')) / 'data'\n",
    "WIKI_DS_NAME = '20200501.en'\n",
    "\n",
    "TRAIN_ENCDEC_HG_PATH = DATA_PATH / 'train_mllm_encdec_hg'\n",
    "encdec_subdir = 'encdechg-20241216_224415-inp128-pos_emb-lrs7x1-rdc_avg-enh_mmbeg-step2-d512-h8-t1'\n",
    "encdec_subdir = 'encdechg-20250107_232630-inp128-pos_emb-lrs7x1-rdc_avg-enh_mmbeg-step2-d768-h12-dp0-t0'\n",
    "\n",
    "encdec_train_path = TRAIN_ENCDEC_HG_PATH / encdec_subdir\n",
    "encdec_snapshot_fpath = encdec_train_path / 'best.pth'\n",
    "encdec_model_cfg_fpath = encdec_train_path / ENCDEC_HG_MODEL_CFG_FNAME\n",
    "encdec_tkz_cfg_fpath = encdec_train_path / TOKENIZER_CFG_FNAME\n",
    "\n",
    "device_name = 'cpu'\n",
    "# device_name = 'cuda'\n",
    "\n",
    "device = torch.device(device_name)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikipedia (/home/misha/data/wikipedia/20200501.en/1.0.0/009f923d9b6dd00c00c8cdc7f408f2b47f45dd4f5fb7982a21f9448f4afbe475)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5def6fd76748431787fd0a775d0e1ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia 20200501.en docs: 6078422\n"
     ]
    }
   ],
   "source": [
    "dss = load_dataset('wikipedia', WIKI_DS_NAME, beam_runner='DirectRunner', cache_dir=str(DATA_PATH))\n",
    "ds: Dataset = dss['train']\n",
    "n_docs = len(ds)\n",
    "print(f'Wikipedia {WIKI_DS_NAME} docs: {n_docs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkz_cfg = parse_yaml_file_as(TokenizerCfg, encdec_tkz_cfg_fpath)\n",
    "tkz = tokenizer_from_config(tkz_cfg)\n",
    "model_cfg = parse_yaml_file_as(EncdecHgCfg, encdec_model_cfg_fpath)\n",
    "inp_len = model_cfg.enc_pyr.inp_len\n",
    "pad_tok = tkz_cfg.custom_tokens['pad'].ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncdecHg(\n",
       "  (enc_pyr): EncoderPyramid(\n",
       "    (vocab_encoder): VocabEncoder(\n",
       "      (src_word_emb): Embedding(50271, 768, padding_idx=50267)\n",
       "      (position_enc): Embedding(128, 768)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (enc_layers): ModuleList(\n",
       "      (0-6): 7 x EncoderLayer(\n",
       "        (slf_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (w_ks): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (w_vs): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (fc): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (rdc_layers): ModuleList(\n",
       "      (0-6): 7 x ReduceLayer()\n",
       "    )\n",
       "  )\n",
       "  (dec_pyr): DecoderPyramid(\n",
       "    (enc_layers): ModuleList(\n",
       "      (0-6): 7 x EncoderLayer(\n",
       "        (slf_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (w_ks): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (w_vs): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (fc): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (w_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (enh_beg_layer): Linear(in_features=768, out_features=98304, bias=False)\n",
       "    (vocab_decoder): VocabDecoder(\n",
       "      (word_prj): Linear(in_features=768, out_features=50271, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chkpt = torch.load(encdec_snapshot_fpath, map_location=device)\n",
    "model = EncdecHg(model_cfg).to(device)\n",
    "strict = True\n",
    "# strict = False\n",
    "model.load_state_dict(chkpt['model'], strict=strict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_tokens(doc_inds: list[int], randomize: bool = False) -> torch.Tensor:\n",
    "    docs_toks = np.full((len(doc_inds), inp_len), pad_tok)\n",
    "    for i, doc_ind in enumerate(doc_inds):\n",
    "        doc = ds[doc_ind]\n",
    "        title, text = doc['title'], doc['text']\n",
    "        doc_txt = f'{title} {text}'\n",
    "        doc_toks: list[int] = tkz(doc_txt)['input_ids']\n",
    "        n_toks = len(doc_toks)\n",
    "        if n_toks > inp_len:\n",
    "            i_off = np.random.randint(n_toks - inp_len + 1) if randomize else 0\n",
    "            doc_toks = doc_toks[i_off:i_off + inp_len]\n",
    "        docs_toks[i, :len(doc_toks)] = doc_toks\n",
    "    docs_toks_t = torch.from_numpy(docs_toks).to(device)\n",
    "    return docs_toks_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000 \"Yangliuqing\" Yangliuqing () is a market town in Xiqing District, in the western suburbs of Tianjin, People's Republic of China. Despite its relatively small size, it has been named since 2006 in the \"famous historical and cultural market towns in China\".\\n\\nIt is best known in China for creating nianhua or Yangl\n",
      "001 \"Orana Australia Ltd\" Orana Australia Ltd is a not-for-profit organisation that provides a diverse range of training and support services to over 650 people with disabilities and their families in South Australia.\\n\\nHistory\\nThe Mentally Retarded Children’s Society of SA Inc. was established in 1950 by a group of parent\n",
      "002 \"St. Mary's Church, Sønderborg\" The St. Mary's Church is a church owned by the Church of Denmark in Sønderborg, Denmark and the church of the parish with the same name. Thanks to its location on a hill, the church building is very iconic for the city.\\n\\nHistory \\nIn the Middle Ages there was a leper colony on a hill just outside \n",
      "003 \"Kalitta\" Kalitta may refer to:\\n\\nConnie Kalitta (born 1938), a retired American drag racer and CEO of the eponymous Kallita Air.\\nDoug Kalitta (born 1964), an American drag racer, nephew of Connie Kalitta and owner of Kalitta Charters.\\nScott Kalitta (1962-2008), an American drag racer and son of Connie Kal\n",
      "004 \"Where Is Freedom?\" Where Is Freedom? () is a 1954 Italian comedy-drama film directed by Roberto Rossellini. \\n \\nThe film had a troubled production because, after shooting some scenes, Rossellini lost interest in the film and abandoned the set. The work was completed after about a year, mainly from Mario Monicelli, wi\n"
     ]
    }
   ],
   "source": [
    "doc_inds = np.arange(5)\n",
    "# doc_inds += 5\n",
    "doc_inds = [x.item() for x in doc_inds]\n",
    "for doc_ind in doc_inds:\n",
    "    doc = ds[doc_ind]\n",
    "    title, text = doc['title'], doc['text'].replace('\\n', '\\\\n')\n",
    "    print(f'{doc_ind:03d} \"{title}\" {text[:300]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 128, 50271])\n",
      "torch.Size([5, 128])\n"
     ]
    }
   ],
   "source": [
    "docs_toks_in = get_batch_tokens(doc_inds)\n",
    "logits_pred = model(docs_toks_in)\n",
    "probs_pred = torch.softmax(logits_pred, dim=-1)\n",
    "# probs_pred = torch.sigmoid(logits_pred)\n",
    "print(probs_pred.shape)\n",
    "docs_toks_out = torch.argmax(probs_pred, dim=-1)\n",
    "print(docs_toks_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000 Yang Tianuqing Yangliuqing () is a market town in Tianqing District, in the western suburbs of Tianjin, People's Republic of China. Despite its relatively small size, it has been named since 2006 in the \"largest historical and cultural cultural newspaper in China\".\\n\\nIt is best known in China for about Lianhua or Yangliuqing Lianhua. For more than 400 years, Yangliuqing has in recent special success in the middle of some wood mines for the New countries.  Modern historical prints using colorful carscunges to support traditional pictures of children's paintings\n",
      "001  Cookana Australia Singapore Orana Service Singapore is a not-for-profit organisation that provides a diverse range of training and support services to over cultural groups with disabilities and their families in South Australia.\\n\\nHistory\\nThe Visally Outitable Children’s Office of Health Inc. was established in 1950 by a group of parents who provide education, community and cultural opportunities for their children within the local community at a time when sustainable care community in Adelaide was their only choice.\\n\\nThe society’s aims on to create education or local facilities for people with health disabilities, to enhance job skills, and to establish farm hostees.\n",
      "002 St. Mary's Church, Søleborg The St. Mary's Church is a church owned by the Church of Denmark in Sønesborg, Denmark and the church of the parish with the same name. Thanks to its location on a hill, the church building is very east for the city.\\n\\nHistory \\nIn the Middle Ages there was a lered castle on a hill just outside the city. It was named after Saint people and grantedstood the chapel of this leper estate formed in the place of the present St. Mary's Church. After the old parish church of the city, the St. Mary Church,\n",
      "003 Kalmi Kalmi may refer to:\\n\\nAndwin Kalmi (born 1938), a retired American thorough racer and husband of the eponymous Kallani Dam.\\nTed Kalmi (born 1964), an American thorough racer, nephew of Ike Kalmi and owner of Kalmi Sager.\\nScott Kalmi (1962-2008), an American thorough racer and son of Michele Kalmi.\\nKalmi Dam, a luxurybred flying bicyclehound aircraft.\\nKalmi Sager, a cargobred flying medium-sized aircraft.<|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|>\n",
      "004  Have Is Our? What Is Our? () is a 1954 Italian comedy-drama film directed by Alberto Rosiglini. \\n \\nThe film had a constant success because, after shooting's films, Rosiglini suffered interest in the film and by the set. The play was completed after almost a year, together from Mario Romicelli, with some scenes also written by Lucio Fici and Federico Donini. Despite that, Rosiglini is the composer between out of the film.\\n\\nPlot \\nLindiculties and memories of an ex-convict. Sheperate and disillusioned by life, he\n"
     ]
    }
   ],
   "source": [
    "for i, doc_ind in enumerate(doc_inds):\n",
    "    s = tkz.decode(docs_toks_out[i])\n",
    "    s = s.replace('\\n', '\\\\n')\n",
    "    print(f'{doc_ind:03d} {s}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training gradients calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encdec_prob_loss_softmax(logits_pred: torch.Tensor, tokens_gt: torch.Tensor) -> torch.Tensor:\n",
    "    tokens_gt = tokens_gt.to(torch.int64).unsqueeze(-1)\n",
    "    probs_pred = torch.softmax(logits_pred, dim=-1)\n",
    "    probs_gt = torch.gather(probs_pred, dim=2, index=tokens_gt)\n",
    "    loss = -torch.mean(torch.log(probs_gt))\n",
    "    return loss\n",
    "\n",
    "loss_fn = encdec_prob_loss_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_batch_size = 5\n",
    "\n",
    "\n",
    "def get_batch_tokens(doc_inds: list[int]) -> torch.Tensor:\n",
    "    docs_toks = np.full((len(doc_inds), inp_len), pad_tok)\n",
    "    for i, doc_ind in enumerate(doc_inds):\n",
    "        doc = ds[doc_ind]\n",
    "        title, text = doc['title'], doc['text']\n",
    "        doc_txt = f'{title} {text}'\n",
    "        doc_toks = tkz(doc_txt)['input_ids']\n",
    "        n_toks = len(doc_toks)\n",
    "        if n_toks > inp_len:\n",
    "            i_off = np.random.randint(n_toks - inp_len + 1)\n",
    "            doc_toks = doc_toks[i_off:i_off + inp_len]\n",
    "        docs_toks[i, :len(doc_toks)] = doc_toks\n",
    "    docs_toks_t = torch.from_numpy(docs_toks).to(device)\n",
    "    return docs_toks_t\n",
    "\n",
    "def get_batch(inds: list[int], i_batch: int) -> tuple[torch.Tensor, int]:\n",
    "    i1 = i_batch * docs_batch_size\n",
    "    i2 = i1 + docs_batch_size\n",
    "    batch_inds = inds[i1:i2]\n",
    "    rest_batch_size = docs_batch_size - len(batch_inds)\n",
    "    if rest_batch_size > 0:\n",
    "        batch_inds = batch_inds + inds[:rest_batch_size * docs_batch_size]\n",
    "    if i2 >= len(batch_inds):\n",
    "        i_batch = 0\n",
    "        np.random.shuffle(inds)\n",
    "    batch_toks = get_batch_tokens(batch_inds)\n",
    "    return batch_toks, i_batch\n",
    "\n",
    "docs_inds = list(range(len(ds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64 torch.Size([5, 128])\n"
     ]
    }
   ],
   "source": [
    "tokens_inp, _ = get_batch(docs_inds, 0)\n",
    "print(tokens_inp.dtype, tokens_inp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "out_logits = model(tokens_inp)\n",
    "loss = loss_fn(out_logits, tokens_inp)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_pyr.vocab_encoder.src_word_emb.weight (-2.7574906198424287e-06, 1.0002703666687012) (1.5332831592519735e-15, 2.1249656128929928e-05)\n",
      "enc_pyr.vocab_encoder.layer_norm.weight (0.9618587493896484, 0.01780407875776291) (8.019902452360839e-06, 0.004944556392729282)\n",
      "enc_pyr.vocab_encoder.layer_norm.bias (-0.0004760617157444358, 0.009908275678753853) (7.112050661817193e-05, 0.011260643601417542)\n",
      "enc_pyr.enc_layers.0.slf_attn.w_qs.weight (3.763933273148723e-05, 0.03625566139817238) (4.7372861899930285e-07, 0.0033385928254574537)\n",
      "enc_pyr.enc_layers.0.slf_attn.w_ks.weight (-0.0001073815074050799, 0.03647030144929886) (3.275928293078323e-07, 0.0034606929402798414)\n",
      "enc_pyr.enc_layers.0.slf_attn.w_vs.weight (8.182486635632813e-05, 0.04236489534378052) (1.4093603795117815e-07, 0.002324572065845132)\n",
      "enc_pyr.enc_layers.0.slf_attn.fc.weight (-7.319550786633044e-05, 0.04345853999257088) (2.2737367544323206e-13, 0.0012499691220000386)\n",
      "enc_pyr.enc_layers.0.slf_attn.layer_norm.weight (1.0012891292572021, 0.015036910772323608) (-1.5809122487553395e-05, 0.00283384183421731)\n",
      "enc_pyr.enc_layers.0.slf_attn.layer_norm.bias (-0.00037130987038835883, 0.005736524239182472) (5.818490171805024e-05, 0.004693114664405584)\n",
      "enc_pyr.enc_layers.0.pos_ffn.w_1.weight (0.00010121573723154142, 0.039638932794332504) (1.4894320088387758e-07, 0.000599419407080859)\n",
      "enc_pyr.enc_layers.0.pos_ffn.w_1.bias (-0.020412258803844452, 0.03570499271154404) (-7.844981882954016e-05, 0.0007913688896223903)\n",
      "enc_pyr.enc_layers.0.pos_ffn.w_2.weight (-5.026670987717807e-05, 0.023110471665859222) (-4.547473508864641e-12, 0.0005450324388220906)\n",
      "enc_pyr.enc_layers.0.pos_ffn.w_2.bias (6.189827399794012e-05, 0.018746158108115196) (0.0, 0.0038952031172811985)\n",
      "enc_pyr.enc_layers.0.pos_ffn.layer_norm.weight (0.9729182720184326, 0.015297472476959229) (0.00011563630687305704, 0.0025948917027562857)\n",
      "enc_pyr.enc_layers.0.pos_ffn.layer_norm.bias (0.0003648654092103243, 0.005172697827219963) (0.0001263987214770168, 0.004182574339210987)\n",
      "enc_pyr.enc_layers.1.slf_attn.w_qs.weight (0.000129346051835455, 0.036292366683483124) (-1.0169600273002288e-08, 0.0011147159384563565)\n",
      "enc_pyr.enc_layers.1.slf_attn.w_ks.weight (3.0351566238095984e-05, 0.0368647463619709) (5.9140234043297824e-08, 0.001290731830522418)\n",
      "enc_pyr.enc_layers.1.slf_attn.w_vs.weight (-0.0001996457576751709, 0.040169037878513336) (7.338627483477467e-08, 0.0016144737601280212)\n",
      "enc_pyr.enc_layers.1.slf_attn.fc.weight (-0.00015474238898605108, 0.04020688310265541) (-7.958078640513122e-13, 0.0011679615126922727)\n",
      "enc_pyr.enc_layers.1.slf_attn.layer_norm.weight (1.0001155138015747, 0.013547444716095924) (-5.3526855481322855e-06, 0.0022019515745341778)\n",
      "enc_pyr.enc_layers.1.slf_attn.layer_norm.bias (-0.00010359945008531213, 0.0075109838508069515) (-1.2054002581862733e-05, 0.002399232005700469)\n",
      "enc_pyr.enc_layers.1.pos_ffn.w_1.weight (1.3602344552055001e-05, 0.038810793310403824) (3.1116091037119986e-08, 0.000384095823392272)\n",
      "enc_pyr.enc_layers.1.pos_ffn.w_1.bias (-0.02090437524020672, 0.03674264997243881) (1.743060965964105e-05, 0.0003877193375956267)\n",
      "enc_pyr.enc_layers.1.pos_ffn.w_2.weight (-4.380272002890706e-06, 0.022406606003642082) (2.0463630789890885e-12, 0.00029909881413914263)\n",
      "enc_pyr.enc_layers.1.pos_ffn.w_2.bias (-0.0018747954163700342, 0.01830136775970459) (3.8198777474462986e-11, 0.0021066791377961636)\n",
      "enc_pyr.enc_layers.1.pos_ffn.layer_norm.weight (0.9916518330574036, 0.014588389545679092) (8.699396857991815e-06, 0.0020423117093741894)\n",
      "enc_pyr.enc_layers.1.pos_ffn.layer_norm.bias (-0.0001881519128801301, 0.0036155690904706717) (-9.257903002435341e-06, 0.0022571547888219357)\n",
      "enc_pyr.enc_layers.2.slf_attn.w_qs.weight (5.090556078357622e-05, 0.03754499927163124) (-5.808246328342648e-09, 0.00035436704638414085)\n",
      "enc_pyr.enc_layers.2.slf_attn.w_ks.weight (-0.00011774494487326592, 0.03785116598010063) (-1.5964261024237203e-08, 0.00040129086119122803)\n",
      "enc_pyr.enc_layers.2.slf_attn.w_vs.weight (-3.9309117710217834e-05, 0.03893592581152916) (-9.782786491996376e-08, 0.001174543984234333)\n",
      "enc_pyr.enc_layers.2.slf_attn.fc.weight (8.249960228567943e-05, 0.03858925402164459) (6.821210263296962e-13, 0.0011602934682741761)\n",
      "enc_pyr.enc_layers.2.slf_attn.layer_norm.weight (0.9984511137008667, 0.014316405169665813) (-3.698667569551617e-06, 0.002409819047898054)\n",
      "enc_pyr.enc_layers.2.slf_attn.layer_norm.bias (0.00014367233961820602, 0.00812755711376667) (6.454709364334121e-06, 0.0023688108194619417)\n",
      "enc_pyr.enc_layers.2.pos_ffn.w_1.weight (-6.065401976229623e-06, 0.03834010660648346) (-2.1132352756580985e-08, 0.0003240911173634231)\n",
      "enc_pyr.enc_layers.2.pos_ffn.w_1.bias (-0.026125634089112282, 0.036002956330776215) (-2.641670471348334e-05, 0.0003594331501517445)\n",
      "enc_pyr.enc_layers.2.pos_ffn.w_2.weight (7.340880983974785e-06, 0.021550482138991356) (6.536993168992922e-13, 0.0002588297938928008)\n",
      "enc_pyr.enc_layers.2.pos_ffn.w_2.bias (0.001492747338488698, 0.019460076466202736) (2.3646862246096134e-11, 0.002113120164722204)\n",
      "enc_pyr.enc_layers.2.pos_ffn.layer_norm.weight (0.9887095093727112, 0.014151294715702534) (-4.947875640937127e-05, 0.002342506544664502)\n",
      "enc_pyr.enc_layers.2.pos_ffn.layer_norm.bias (0.0002708313404582441, 0.005121105350553989) (6.494147964986041e-05, 0.002252048347145319)\n",
      "enc_pyr.enc_layers.3.slf_attn.w_qs.weight (-8.535707456758246e-05, 0.03677129000425339) (2.2304433855424577e-08, 0.0005067730089649558)\n",
      "enc_pyr.enc_layers.3.slf_attn.w_ks.weight (-2.3622022126801312e-05, 0.03702660650014877) (2.8153962716714886e-08, 0.0005225843051448464)\n",
      "enc_pyr.enc_layers.3.slf_attn.w_vs.weight (-2.663407940417528e-05, 0.03772328421473503) (6.266967034207482e-08, 0.001219851546920836)\n",
      "enc_pyr.enc_layers.3.slf_attn.fc.weight (0.00014388312411028892, 0.037768129259347916) (-1.9326762412674725e-12, 0.001167132519185543)\n",
      "enc_pyr.enc_layers.3.slf_attn.layer_norm.weight (0.9980658292770386, 0.013321658596396446) (4.734902177006006e-06, 0.0026813792064785957)\n",
      "enc_pyr.enc_layers.3.slf_attn.layer_norm.bias (-0.00035887843114323914, 0.008458827622234821) (5.106116077513434e-06, 0.0022344586905092)\n",
      "enc_pyr.enc_layers.3.pos_ffn.w_1.weight (0.00017739518079906702, 0.03790507838129997) (5.023352400712611e-09, 0.0002666094806045294)\n",
      "enc_pyr.enc_layers.3.pos_ffn.w_1.bias (-0.026458870619535446, 0.03700967878103256) (-1.5976094800862484e-05, 0.0002599110594019294)\n",
      "enc_pyr.enc_layers.3.pos_ffn.w_2.weight (-3.324890712974593e-05, 0.020643381401896477) (-2.8421709430404007e-13, 0.0002590236545074731)\n",
      "enc_pyr.enc_layers.3.pos_ffn.w_2.bias (-0.0013082106597721577, 0.018487222492694855) (-3.092281986027956e-11, 0.0021461197175085545)\n",
      "enc_pyr.enc_layers.3.pos_ffn.layer_norm.weight (0.9895630478858948, 0.012693090364336967) (-1.6869453247636557e-05, 0.002665538340806961)\n",
      "enc_pyr.enc_layers.3.pos_ffn.layer_norm.bias (-0.00013110024156048894, 0.005533821415156126) (9.024269820656627e-05, 0.0022324577439576387)\n",
      "enc_pyr.enc_layers.4.slf_attn.w_qs.weight (-3.5642726288642734e-05, 0.03679466247558594) (2.0578632131673658e-09, 0.0005794962053187191)\n",
      "enc_pyr.enc_layers.4.slf_attn.w_ks.weight (-0.00018027302576228976, 0.03721843287348747) (2.001063847956175e-08, 0.0006446024053730071)\n",
      "enc_pyr.enc_layers.4.slf_attn.w_vs.weight (-0.00013726725592277944, 0.03733343258500099) (-4.419979404701735e-08, 0.0014914536150172353)\n",
      "enc_pyr.enc_layers.4.slf_attn.fc.weight (-0.00023589890042785555, 0.03708925470709801) (1.1368683772161603e-13, 0.000928239431232214)\n",
      "enc_pyr.enc_layers.4.slf_attn.layer_norm.weight (0.9986223578453064, 0.011548261158168316) (2.5798362912610173e-06, 0.0024405927397310734)\n",
      "enc_pyr.enc_layers.4.slf_attn.layer_norm.bias (-0.00021828239550814033, 0.008784264326095581) (-5.112417056807317e-06, 0.0022816662676632404)\n",
      "enc_pyr.enc_layers.4.pos_ffn.w_1.weight (0.00013034690346103162, 0.03777367249131203) (5.68360469799245e-10, 0.00020575076632667333)\n",
      "enc_pyr.enc_layers.4.pos_ffn.w_1.bias (-0.028840981423854828, 0.03575517609715462) (8.645555681141559e-06, 0.00019876258738804609)\n",
      "enc_pyr.enc_layers.4.pos_ffn.w_2.weight (8.728467219043523e-05, 0.02022073045372963) (4.689582056016661e-13, 0.00020054059859830886)\n",
      "enc_pyr.enc_layers.4.pos_ffn.w_2.bias (-0.0013434395659714937, 0.018654854968190193) (8.185452315956354e-11, 0.002196952234953642)\n",
      "enc_pyr.enc_layers.4.pos_ffn.layer_norm.weight (0.9932422637939453, 0.011300275102257729) (-6.238464993657544e-05, 0.002512709703296423)\n",
      "enc_pyr.enc_layers.4.pos_ffn.layer_norm.bias (0.00010011357517214492, 0.005750914104282856) (7.905592792667449e-05, 0.0022561573423445225)\n",
      "enc_pyr.enc_layers.5.slf_attn.w_qs.weight (2.6811561838258058e-05, 0.03710155934095383) (4.05045241791413e-09, 0.0009141474729403853)\n",
      "enc_pyr.enc_layers.5.slf_attn.w_ks.weight (-4.285810064175166e-05, 0.037608835846185684) (-1.3061480785836466e-09, 0.0012897367123514414)\n",
      "enc_pyr.enc_layers.5.slf_attn.w_vs.weight (0.0001454003795515746, 0.03718046098947525) (1.498719370829349e-09, 0.0012217044131830335)\n",
      "enc_pyr.enc_layers.5.slf_attn.fc.weight (-0.00014232698595151305, 0.03700236231088638) (4.547473508864641e-13, 0.000788189354352653)\n",
      "enc_pyr.enc_layers.5.slf_attn.layer_norm.weight (0.9988494515419006, 0.008728032931685448) (3.493158146739006e-06, 0.0021623470820486546)\n",
      "enc_pyr.enc_layers.5.slf_attn.layer_norm.bias (-0.0003549634711816907, 0.008354974910616875) (6.979034878895618e-07, 0.0018561369506642222)\n",
      "enc_pyr.enc_layers.5.pos_ffn.w_1.weight (9.545288048684597e-05, 0.03773295506834984) (-6.759346860008009e-09, 0.00013399457384366542)\n",
      "enc_pyr.enc_layers.5.pos_ffn.w_1.bias (-0.028223037719726562, 0.03588114306330681) (6.361834493873175e-06, 0.0001413826539646834)\n",
      "enc_pyr.enc_layers.5.pos_ffn.w_2.weight (-5.988655175315216e-06, 0.02009706385433674) (1.4921397450962104e-13, 0.00010615000792313367)\n",
      "enc_pyr.enc_layers.5.pos_ffn.w_2.bias (-0.0019077438628301024, 0.020172961056232452) (8.185452315956354e-12, 0.0018608270911499858)\n",
      "enc_pyr.enc_layers.5.pos_ffn.layer_norm.weight (0.9984878301620483, 0.009333118796348572) (4.666668246500194e-06, 0.0021476037800312042)\n",
      "enc_pyr.enc_layers.5.pos_ffn.layer_norm.bias (0.0001980917586479336, 0.006157037802040577) (-3.3296919355052523e-06, 0.0018725305562838912)\n",
      "enc_pyr.enc_layers.6.slf_attn.w_qs.weight (-0.00024477049009874463, 0.04033519700169563) (-2.9783588928466997e-09, 4.103259925614111e-05)\n",
      "enc_pyr.enc_layers.6.slf_attn.w_ks.weight (2.7041591238230467e-05, 0.040386952459812164) (1.6107217781780037e-09, 5.271572808851488e-05)\n",
      "enc_pyr.enc_layers.6.slf_attn.w_vs.weight (-0.0001832840935094282, 0.03645719587802887) (-7.61265823712165e-08, 0.0007823256892152131)\n",
      "enc_pyr.enc_layers.6.slf_attn.fc.weight (7.030261622276157e-05, 0.036355290561914444) (0.0, 0.0007561076781712472)\n",
      "enc_pyr.enc_layers.6.slf_attn.layer_norm.weight (0.9973924160003662, 0.0096095846965909) (-5.374458851292729e-07, 0.002174487104639411)\n",
      "enc_pyr.enc_layers.6.slf_attn.layer_norm.bias (-0.0005771167343482375, 0.007364640478044748) (-8.994987183541525e-06, 0.0018613686552271247)\n",
      "enc_pyr.enc_layers.6.pos_ffn.w_1.weight (0.00021248581469990313, 0.037719666957855225) (8.005036633562668e-10, 0.00012576016888488084)\n",
      "enc_pyr.enc_layers.6.pos_ffn.w_1.bias (-0.0329267792403698, 0.03591061383485794) (1.2223575822645216e-06, 0.00012557041191030294)\n",
      "enc_pyr.enc_layers.6.pos_ffn.w_2.weight (-3.0671246349811554e-05, 0.019996164366602898) (-1.4210854715202004e-14, 7.209878822322935e-05)\n",
      "enc_pyr.enc_layers.6.pos_ffn.w_2.bias (0.0006617575418204069, 0.02017936296761036) (-4.274625098332763e-11, 0.00186656485311687)\n",
      "enc_pyr.enc_layers.6.pos_ffn.layer_norm.weight (0.9964277744293213, 0.010313736274838448) (2.3228058125823736e-06, 0.0021724561229348183)\n",
      "enc_pyr.enc_layers.6.pos_ffn.layer_norm.bias (-0.00010782113531604409, 0.0087247584015131) (6.835745443822816e-05, 0.0018746457062661648)\n",
      "dec_pyr.enc_layers.0.slf_attn.w_qs.weight (0.00017871898307930678, 0.03888098523020744) (-7.724626271965462e-09, 5.878318461327581e-06)\n",
      "dec_pyr.enc_layers.0.slf_attn.w_ks.weight (0.00023764546494930983, 0.03875930979847908) (-5.375078160341218e-09, 5.85364841754199e-06)\n",
      "dec_pyr.enc_layers.0.slf_attn.w_vs.weight (0.00036779409856535494, 0.03549901396036148) (-1.8176515368395485e-06, 0.0007199820247478783)\n",
      "dec_pyr.enc_layers.0.slf_attn.fc.weight (0.00015092699322849512, 0.035541832447052) (4.547473508864641e-13, 0.0006510027451440692)\n",
      "dec_pyr.enc_layers.0.slf_attn.layer_norm.weight (0.9975054264068604, 0.011077066883444786) (-8.590632205596194e-07, 0.00168526207562536)\n",
      "dec_pyr.enc_layers.0.slf_attn.layer_norm.bias (0.000491482496727258, 0.01114586554467678) (7.691494829487056e-06, 0.0017899475060403347)\n",
      "dec_pyr.enc_layers.0.pos_ffn.w_1.weight (-0.0001795839925762266, 0.03752298653125763) (1.219054368561956e-08, 0.00014942137931939214)\n",
      "dec_pyr.enc_layers.0.pos_ffn.w_1.bias (-0.04078671336174011, 0.035460878163576126) (8.408961548411753e-06, 0.00015278953651431948)\n",
      "dec_pyr.enc_layers.0.pos_ffn.w_2.weight (5.6602657423354685e-05, 0.020307427272200584) (-5.115907697472721e-13, 0.00011179935972904786)\n",
      "dec_pyr.enc_layers.0.pos_ffn.w_2.bias (4.1222592699341476e-05, 0.018838470801711082) (-4.18367562815547e-11, 0.0017965687438845634)\n",
      "dec_pyr.enc_layers.0.pos_ffn.layer_norm.weight (0.9955092072486877, 0.011919252574443817) (1.1072381312260404e-05, 0.0016793367685750127)\n",
      "dec_pyr.enc_layers.0.pos_ffn.layer_norm.bias (-0.000659481156617403, 0.008485163561999798) (-5.732001591240987e-05, 0.0017947197193279862)\n",
      "dec_pyr.enc_layers.1.slf_attn.w_qs.weight (0.00011379364150343463, 0.03858841210603714) (-5.923190826706559e-08, 0.0001789531233953312)\n",
      "dec_pyr.enc_layers.1.slf_attn.w_ks.weight (9.209982817992568e-05, 0.038503386080265045) (-3.4936647352878936e-08, 0.00018520835146773607)\n",
      "dec_pyr.enc_layers.1.slf_attn.w_vs.weight (5.399037399911322e-05, 0.03589348495006561) (3.637327381511568e-07, 0.000700460106600076)\n",
      "dec_pyr.enc_layers.1.slf_attn.fc.weight (-0.00014383875532075763, 0.03592079505324364) (-9.094947017729282e-13, 0.0006391830975189805)\n",
      "dec_pyr.enc_layers.1.slf_attn.layer_norm.weight (0.9965236783027649, 0.011894302442669868) (-3.1759263947606087e-06, 0.0016250234330073)\n",
      "dec_pyr.enc_layers.1.slf_attn.layer_norm.bias (-0.00036191646358929574, 0.011995956301689148) (-1.4956003724364564e-06, 0.0016413029516115785)\n",
      "dec_pyr.enc_layers.1.pos_ffn.w_1.weight (0.00012794160284101963, 0.03765827417373657) (7.737588347822566e-09, 0.00020440570369828492)\n",
      "dec_pyr.enc_layers.1.pos_ffn.w_1.bias (-0.038649484515190125, 0.03658632934093475) (-5.513124506251188e-06, 0.00020434934413060546)\n",
      "dec_pyr.enc_layers.1.pos_ffn.w_2.weight (-5.6340082664974034e-05, 0.020819928497076035) (-2.2737367544323206e-13, 0.0001874990266514942)\n",
      "dec_pyr.enc_layers.1.pos_ffn.w_2.bias (-0.0018465113826096058, 0.020024564117193222) (1.8189894035458565e-11, 0.0015791172627359629)\n",
      "dec_pyr.enc_layers.1.pos_ffn.layer_norm.weight (0.9942851066589355, 0.011846722103655338) (1.0895810191868804e-06, 0.001598087721504271)\n",
      "dec_pyr.enc_layers.1.pos_ffn.layer_norm.bias (-0.00020348370890133083, 0.008133649826049805) (-4.3604159145615995e-05, 0.001621425966732204)\n",
      "dec_pyr.enc_layers.2.slf_attn.w_qs.weight (2.9015791369602084e-06, 0.03857288509607315) (7.121272460608452e-08, 0.00033331470331177115)\n",
      "dec_pyr.enc_layers.2.slf_attn.w_ks.weight (1.773759868228808e-05, 0.038691405206918716) (-1.7249453776457813e-06, 0.00041458403575234115)\n",
      "dec_pyr.enc_layers.2.slf_attn.w_vs.weight (-8.365503890672699e-05, 0.035965848714113235) (3.991780772594211e-07, 0.0005722639616578817)\n",
      "dec_pyr.enc_layers.2.slf_attn.fc.weight (-2.839955413946882e-06, 0.03607972338795662) (-2.8421709430404007e-13, 0.0005440565291792154)\n",
      "dec_pyr.enc_layers.2.slf_attn.layer_norm.weight (0.9974004030227661, 0.01212312187999487) (-8.907016308512539e-06, 0.0014144161250442266)\n",
      "dec_pyr.enc_layers.2.slf_attn.layer_norm.bias (-2.1218860638327897e-05, 0.012699268758296967) (1.3599760677607264e-05, 0.0013924801023676991)\n",
      "dec_pyr.enc_layers.2.pos_ffn.w_1.weight (-6.621447028010152e-06, 0.03788883984088898) (6.599380597549498e-09, 0.00018319030641578138)\n",
      "dec_pyr.enc_layers.2.pos_ffn.w_1.bias (-0.03878513351082802, 0.03548683598637581) (-1.3008779205847532e-05, 0.00018389140313956887)\n",
      "dec_pyr.enc_layers.2.pos_ffn.w_2.weight (-7.523866952396929e-05, 0.021386027336120605) (-5.684341886080801e-13, 0.00015773603809066117)\n",
      "dec_pyr.enc_layers.2.pos_ffn.w_2.bias (0.00018516366253606975, 0.019286969676613808) (-3.8198777474462986e-11, 0.0012836502864956856)\n",
      "dec_pyr.enc_layers.2.pos_ffn.layer_norm.weight (0.993767261505127, 0.011428319849073887) (3.0265055102063343e-06, 0.0014209236251190305)\n",
      "dec_pyr.enc_layers.2.pos_ffn.layer_norm.bias (0.00011360691860318184, 0.00789652019739151) (-8.531533239874989e-05, 0.0013461083872243762)\n",
      "dec_pyr.enc_layers.3.slf_attn.w_qs.weight (0.00010970883158734068, 0.03848333656787872) (-4.3467147747833224e-07, 0.00023394598974846303)\n",
      "dec_pyr.enc_layers.3.slf_attn.w_ks.weight (0.00013830559328198433, 0.03848082572221756) (-1.4595232187275542e-06, 0.00034818550921045244)\n",
      "dec_pyr.enc_layers.3.slf_attn.w_vs.weight (5.506816887645982e-05, 0.03647525981068611) (1.6291068050122703e-08, 0.0005818741046823561)\n",
      "dec_pyr.enc_layers.3.slf_attn.fc.weight (3.0073460948187858e-06, 0.0365351140499115) (-3.126388037344441e-13, 0.0005697360029444098)\n",
      "dec_pyr.enc_layers.3.slf_attn.layer_norm.weight (0.997948169708252, 0.010837900452315807) (-4.960606020176783e-06, 0.0013250169577077031)\n",
      "dec_pyr.enc_layers.3.slf_attn.layer_norm.bias (0.0005576148978434503, 0.01342935860157013) (3.7707131923525594e-06, 0.0013535235775634646)\n",
      "dec_pyr.enc_layers.3.pos_ffn.w_1.weight (-0.00010249079787172377, 0.038347337394952774) (-9.787036958641693e-09, 0.00022022494522389024)\n",
      "dec_pyr.enc_layers.3.pos_ffn.w_1.bias (-0.03542545810341835, 0.03689884394407272) (-1.0239373295917176e-05, 0.0002210000529885292)\n",
      "dec_pyr.enc_layers.3.pos_ffn.w_2.weight (-3.6169742088532075e-05, 0.02221355028450489) (-2.2737367544323206e-13, 0.00016695963859092444)\n",
      "dec_pyr.enc_layers.3.pos_ffn.w_2.bias (0.0015141653129830956, 0.0191587395966053) (-3.637978807091713e-12, 0.0011619544820860028)\n",
      "dec_pyr.enc_layers.3.pos_ffn.layer_norm.weight (0.992974042892456, 0.010957974009215832) (-5.406437776400708e-05, 0.0012452458031475544)\n",
      "dec_pyr.enc_layers.3.pos_ffn.layer_norm.bias (-0.0006164780934341252, 0.0074498592875897884) (-3.268452928750776e-05, 0.001262991689145565)\n",
      "dec_pyr.enc_layers.4.slf_attn.w_qs.weight (-8.961041748989373e-05, 0.038346219807863235) (9.192073093799991e-07, 0.0003686200943775475)\n",
      "dec_pyr.enc_layers.4.slf_attn.w_ks.weight (-5.816298653371632e-06, 0.038431648164987564) (3.4893423617177177e-06, 0.0003728908486664295)\n",
      "dec_pyr.enc_layers.4.slf_attn.w_vs.weight (0.00017270338139496744, 0.03700900077819824) (-2.197873982368037e-06, 0.0005424609407782555)\n",
      "dec_pyr.enc_layers.4.slf_attn.fc.weight (0.0001762537140166387, 0.037034839391708374) (-1.3642420526593924e-12, 0.0005770019488409162)\n",
      "dec_pyr.enc_layers.4.slf_attn.layer_norm.weight (0.9983171820640564, 0.010669159702956676) (-7.038142939563841e-07, 0.0011080998228862882)\n",
      "dec_pyr.enc_layers.4.slf_attn.layer_norm.bias (-0.0011455169878900051, 0.014507696032524109) (-2.3090295144356787e-05, 0.0011357555631548166)\n",
      "dec_pyr.enc_layers.4.pos_ffn.w_1.weight (0.00020339462207630277, 0.03889232501387596) (5.996769303351357e-09, 0.0002271610137540847)\n",
      "dec_pyr.enc_layers.4.pos_ffn.w_1.bias (-0.03572122007608414, 0.03568059206008911) (-3.6860524232906755e-06, 0.00022121751680970192)\n",
      "dec_pyr.enc_layers.4.pos_ffn.w_2.weight (7.147726137191057e-05, 0.02324467897415161) (2.2737367544323206e-13, 0.00020163366571068764)\n",
      "dec_pyr.enc_layers.4.pos_ffn.w_2.bias (-0.00043137080501765013, 0.018497928977012634) (2.637534635141492e-11, 0.0010436109732836485)\n",
      "dec_pyr.enc_layers.4.pos_ffn.layer_norm.weight (0.9910646080970764, 0.01130713801831007) (2.5821391318459064e-05, 0.0011420244118198752)\n",
      "dec_pyr.enc_layers.4.pos_ffn.layer_norm.bias (0.0005055195069871843, 0.007476030848920345) (-2.8283066058065742e-05, 0.001213621348142624)\n",
      "dec_pyr.enc_layers.5.slf_attn.w_qs.weight (0.0001220012127305381, 0.0381242111325264) (-1.0023932190961204e-06, 0.00034819223219528794)\n",
      "dec_pyr.enc_layers.5.slf_attn.w_ks.weight (0.00016006812802515924, 0.03825867548584938) (1.342063455922471e-07, 0.000415517803048715)\n",
      "dec_pyr.enc_layers.5.slf_attn.w_vs.weight (-7.730097422609106e-05, 0.03822626546025276) (-1.9247472948791255e-07, 0.0006075880955904722)\n",
      "dec_pyr.enc_layers.5.slf_attn.fc.weight (0.00012610296835191548, 0.038161855190992355) (-4.547473508864641e-13, 0.0006734214839525521)\n",
      "dec_pyr.enc_layers.5.slf_attn.layer_norm.weight (0.999973475933075, 0.011653405614197254) (-6.632635631831363e-06, 0.0010974748292937875)\n",
      "dec_pyr.enc_layers.5.slf_attn.layer_norm.bias (-0.0003279897791799158, 0.01392876636236906) (-3.095658030360937e-06, 0.0011591606307774782)\n",
      "dec_pyr.enc_layers.5.pos_ffn.w_1.weight (0.00014667022333014756, 0.040296223014593124) (9.871495620927817e-09, 0.0002769298735074699)\n",
      "dec_pyr.enc_layers.5.pos_ffn.w_1.bias (-0.02794761396944523, 0.036043718457221985) (-2.940943159046583e-05, 0.000270796095719561)\n",
      "dec_pyr.enc_layers.5.pos_ffn.w_2.weight (-8.820965376798995e-06, 0.024852260947227478) (0.0, 0.0002840902889147401)\n",
      "dec_pyr.enc_layers.5.pos_ffn.w_2.bias (-0.0001071651277015917, 0.01837039552628994) (-1.1823431123048067e-11, 0.0009535475401207805)\n",
      "dec_pyr.enc_layers.5.pos_ffn.layer_norm.weight (0.995715320110321, 0.014950918033719063) (-1.5513487596763298e-05, 0.0011316005839034915)\n",
      "dec_pyr.enc_layers.5.pos_ffn.layer_norm.bias (0.0003409638302400708, 0.008843476884067059) (-4.165674181422219e-05, 0.0011720283655449748)\n",
      "dec_pyr.enc_layers.6.slf_attn.w_qs.weight (-6.417764234356582e-05, 0.03862069174647331) (-3.2564028629167296e-07, 0.0002626814239192754)\n",
      "dec_pyr.enc_layers.6.slf_attn.w_ks.weight (3.354451109771617e-05, 0.038857318460941315) (-8.392655104216828e-07, 0.0002894038043450564)\n",
      "dec_pyr.enc_layers.6.slf_attn.w_vs.weight (0.00023159303236752748, 0.040186312049627304) (-1.9153562789142597e-06, 0.0007574132760055363)\n",
      "dec_pyr.enc_layers.6.slf_attn.fc.weight (6.126408698037267e-05, 0.040033336728811264) (-1.8189894035458565e-12, 0.0009834616212174296)\n",
      "dec_pyr.enc_layers.6.slf_attn.layer_norm.weight (0.9998993873596191, 0.014791230671107769) (2.52254176302813e-06, 0.0018575811991468072)\n",
      "dec_pyr.enc_layers.6.slf_attn.layer_norm.bias (0.00016015369328670204, 0.017104381695389748) (3.3635042200330645e-06, 0.0020069279707968235)\n",
      "dec_pyr.enc_layers.6.pos_ffn.w_1.weight (-0.00011816411279141903, 0.044204771518707275) (3.3704232293985115e-08, 0.00048567081103101373)\n",
      "dec_pyr.enc_layers.6.pos_ffn.w_1.bias (-0.02224215678870678, 0.03729663044214249) (-6.625752575928345e-05, 0.0004825211362913251)\n",
      "dec_pyr.enc_layers.6.pos_ffn.w_2.weight (-4.636047378880903e-05, 0.028239795938134193) (3.183231456205249e-12, 0.0008111316710710526)\n",
      "dec_pyr.enc_layers.6.pos_ffn.w_2.bias (-0.0002099903067573905, 0.01901034079492092) (0.0, 0.0022199645172804594)\n",
      "dec_pyr.enc_layers.6.pos_ffn.layer_norm.weight (1.2862046957015991, 0.1457892805337906) (-0.0004947080742567778, 0.00195140833966434)\n",
      "dec_pyr.enc_layers.6.pos_ffn.layer_norm.bias (0.0012903190217912197, 0.1284601241350174) (5.747621617047116e-05, 0.002596329664811492)\n",
      "dec_pyr.enh_layers.0.enhancer.weight (-7.850988913560286e-05, 0.03884364292025566) (4.8640416139278386e-08, 0.0012040729634463787)\n",
      "dec_pyr.enh_layers.1.enhancer.weight (6.852340447949246e-05, 0.038679689168930054) (-4.7975845518521965e-11, 0.0010974154574796557)\n",
      "dec_pyr.enh_layers.2.enhancer.weight (0.00011603439634200186, 0.03883671760559082) (-8.166978204826592e-10, 0.0009851863142102957)\n",
      "dec_pyr.enh_layers.3.enhancer.weight (0.00016133948520291597, 0.038771048188209534) (3.081608213051368e-08, 0.0009014667011797428)\n",
      "dec_pyr.enh_layers.4.enhancer.weight (0.00020874725305475295, 0.03868723660707474) (1.6068753438958083e-08, 0.0008590664365328848)\n",
      "dec_pyr.enh_layers.5.enhancer.weight (-0.00013677043898496777, 0.038625914603471756) (-2.963602696581802e-10, 0.0008437621290795505)\n",
      "dec_pyr.enh_layers.6.enhancer.weight (7.046411337796599e-05, 0.0390237420797348) (9.475513707002392e-09, 0.0009292172617278993)\n",
      "dec_pyr.vocab_decoder.word_prj.weight (9.900881559588015e-05, 0.053776007145643234) (1.9799705494941144e-13, 0.00020662310998886824)\n"
     ]
    }
   ],
   "source": [
    "def calc_params_grads_stats(params: torch.nn.Parameter) -> tuple[tuple[float, float], Optional[tuple[float, float]]]:\n",
    "    gres = None\n",
    "    pres = params.mean().detach().cpu().item(), params.std().detach().cpu().item()\n",
    "    if params.grad is not None:\n",
    "        gres = params.grad.mean().detach().cpu().item(), params.grad.std().detach().cpu().item()\n",
    "    return pres, gres\n",
    "\n",
    "for pname, params in model.named_parameters():\n",
    "    pms, gms = calc_params_grads_stats(params)\n",
    "    print(pname, pms, gms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder embedding evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(txts: list[str]) -> torch.Tensor:\n",
    "    batch_toks = np.full((len(txts), inp_len), pad_tok)\n",
    "    for i, txt in enumerate(txts):\n",
    "        toks: list[int] = tkz(txt)['input_ids']\n",
    "        n_toks = len(toks)\n",
    "        if n_toks > inp_len:\n",
    "            i_off = np.random.randint(n_toks - inp_len + 1)\n",
    "            toks = toks[i_off:i_off + inp_len]\n",
    "        batch_toks[i, :len(toks)] = toks\n",
    "    batch_toks_t = torch.from_numpy(batch_toks).to(device)\n",
    "    return batch_toks_t\n",
    "\n",
    "model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 768])\n"
     ]
    }
   ],
   "source": [
    "txts = [\n",
    "    '\"Orana Australia Ltd\" Orana Australia Ltd is a not-for-profit organisation that provides a diverse range of training and support services to over 650 people with disabilities and their families in South Australia.\\n\\nHistory\\nThe Mentally Retarded Children’s Society of SA Inc. was established in 1950 by a group of parent',\n",
    "    'Australia',\n",
    "    'Orana Australia Ltd',\n",
    "    'Hello Kitty',\n",
    "]\n",
    "batch_toks = get_tokens(txts)\n",
    "embs = model.enc_pyr(batch_toks)\n",
    "# embs = embs.detach().cpu().numpy()\n",
    "embs = embs.detach().cpu()\n",
    "print(embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Australia [0.22261377] tensor(32.4214)\n",
      "Orana Australia Ltd [0.16103858] tensor(33.4885)\n",
      "Hello Kitty [0.17609353] tensor(33.3606)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(embs)):\n",
    "    cos_dist = F.cosine_similarity(embs[0], embs[i])\n",
    "    norm_dist = torch.norm(embs[0] - embs[i])\n",
    "    print(txts[i], cos_dist.numpy(), norm_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
