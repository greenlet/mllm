{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import Optional\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pydantic_yaml import parse_yaml_file_as\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import GPT2Tokenizer, AddedToken, PreTrainedTokenizer\n",
    "\n",
    "from mllm.data.wiki.dswiki import WikiDsLoader\n",
    "from mllm.exp.args import TOKENIZER_CFG_FNAME, ENCDEC_MODEL_CFG_FNAME, RANKER_MODEL_CFG_FNAME\n",
    "from mllm.model.mllm_encdec import MllmEncdecLevel\n",
    "from mllm.model.mllm_ranker import MllmRankerLevel\n",
    "from mllm.config.model import TokenizerCfg, MllmEncdecCfg, MllmRankerCfg\n",
    "from mllm.tokenization.chunk_tokenizer import calc_max_inp_size, gen_all_tokens, ChunkTokenizer, tokenizer_from_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(os.path.expandvars('$HOME')) / 'data'\n",
    "DS_DIR_PATH = DATA_PATH / 'wiki_20200501_en' / 'ch_100_fixed'\n",
    "\n",
    "TRAIN_ENCDEC_0_PATH = DATA_PATH / 'train_mllm_encdec_0'\n",
    "TRAIN_ENCDEC_1_PATH = DATA_PATH / 'train_mllm_encdec_1'\n",
    "encdec_0_subdir = 'encdec-lvl0-20241028_093737-wiki_20200501_en-ch_100_fixed-enc-lrs3-embmatFalse-d256-h8-dec-lrs3-seqlen100-d256-h8-vocdecTrue'\n",
    "encdec_1_subdir = 'encdec-lvl1-20241022_224217-msmarco-fever-enc-lrs2-embmatTrue-d256-h8-dec-lrs2-seqlen100-d256-h8'\n",
    "\n",
    "encdec_0_train_path = TRAIN_ENCDEC_0_PATH / encdec_0_subdir\n",
    "encdec_1_train_path = TRAIN_ENCDEC_1_PATH / encdec_1_subdir\n",
    "encdec_0_snapshot_fpath = encdec_0_train_path / 'best.pth'\n",
    "encdec_1_snapshot_fpath = encdec_1_train_path / 'best.pth'\n",
    "encdec_0_tkz_cfg_fpath = encdec_0_train_path / TOKENIZER_CFG_FNAME\n",
    "encdec_0_model_cfg_fpath = encdec_0_train_path / ENCDEC_MODEL_CFG_FNAME\n",
    "encdec_1_model_cfg_fpath = encdec_1_train_path / ENCDEC_MODEL_CFG_FNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encdec_tkz_cfg = parse_yaml_file_as(TokenizerCfg, encdec_0_tkz_cfg_fpath)\n",
    "tokenizer = tokenizer_from_config(encdec_tkz_cfg)\n",
    "tok_dict = encdec_tkz_cfg.custom_tokens\n",
    "pad_tok, qbeg_tok, qend_tok = tok_dict['pad'].ind, tok_dict['query_begin'].ind, tok_dict['query_end'].ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "docs_batch_size = 5\n",
    "max_chunks_per_doc = 3\n",
    "model_level = 0\n",
    "device_name = 'cpu'\n",
    "# device_name = 'cuda'\n",
    "\n",
    "device = torch.device(device_name)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cache from /home/misha/data/wiki_20200501_en/ch_100_fixed/.mllm/ds.csv\n",
      "Loaded dataset size: 50989207\n"
     ]
    }
   ],
   "source": [
    "ds_loader = WikiDsLoader(\n",
    "    ds_path=DS_DIR_PATH, docs_batch_size=docs_batch_size, max_chunks_per_doc=max_chunks_per_doc,\n",
    "    pad_tok=pad_tok, qbeg_tok=qbeg_tok, qend_tok=qend_tok, device=device,\n",
    ")\n",
    "ds_loader.shuffle(train=True)\n",
    "ds_loader.shuffle(train=False)\n",
    "inp_len = ds_loader.emb_chunk_size if ds_loader.fixed_size else calc_max_inp_size(ds_loader.emb_chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_text(tokens: torch.Tensor) -> str:\n",
    "    tokens = tokens.flatten()\n",
    "    tokens = tokens[tokens != pad_tok]\n",
    "    tokens = list(tokens)\n",
    "    s = tokenizer.decode(tokens)\n",
    "    return s\n",
    "\n",
    "def distance(x: np.ndarray, y: np.ndarray, cosine: bool = False):\n",
    "    if not cosine:\n",
    "        return np.linalg.norm(x - y)\n",
    "    x_norm, y_norm = np.linalg.norm(x), np.linalg.norm(y)\n",
    "    return np.sum(x * y) / (x_norm * y_norm)\n",
    "\n",
    "def text_to_tokens(s: str, qbeg_tok: Optional[int] = None, qend_tok: Optional[int] = None) -> torch.Tensor:\n",
    "    tokens = tokenizer(s)['input_ids']\n",
    "    if qbeg_tok is not None:\n",
    "        assert qend_tok is not None\n",
    "        tokens = [qbeg_tok, *tokens, qend_tok]\n",
    "    n_tokens = len(tokens)\n",
    "    n_padded = n_tokens // inp_len + (n_tokens % inp_len > 0)\n",
    "    res = np.full((n_padded * inp_len, ), pad_tok, dtype=np.int32)\n",
    "    res[:n_tokens] = tokens\n",
    "    res = torch.from_numpy(res).to(device)\n",
    "    res = res.reshape(n_padded, inp_len)\n",
    "    return res\n",
    "\n",
    "def print_dist(target_embs: torch.Tensor, docs_embs: torch.Tensor, target_mask: torch.Tensor, cosine: bool = True):\n",
    "    for i, docs_emb in enumerate(docs_embs.detach().numpy()):\n",
    "        for target_emb in target_embs.detach().numpy():\n",
    "            dist = distance(target_emb, docs_emb, cosine)\n",
    "            print(f'{dist:0.6f} ', end='')\n",
    "        sfx = 'T' if target_mask[i] else 'F'\n",
    "        print(sfx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_encoder.src_word_emb.weight (50271, 256) -0.010897174 -8.7604326e-07 0.010897173\n",
      "vocab_encoder.layer_norm.weight (256,) -0.09980767 0.0057643503 0.09948851\n",
      "vocab_encoder.layer_norm.bias (256,) -0.09884226 0.0011206635 0.098379485\n",
      "vocab_decoder.word_prj.weight (50271, 256) -0.010897174 4.4291858e-07 0.010897167\n",
      "encoder.a_em () -0.04112512 -0.04112512 -0.04112512\n",
      "encoder.layer_stack.0.slf_attn.w_qs.weight (256, 256) -0.10824676 0.00018859553 0.108249635\n",
      "encoder.layer_stack.0.slf_attn.w_ks.weight (256, 256) -0.10825236 -9.765843e-05 0.10825259\n",
      "encoder.layer_stack.0.slf_attn.w_vs.weight (256, 256) -0.10825161 -8.1947765e-05 0.108248875\n",
      "encoder.layer_stack.0.slf_attn.fc.weight (256, 256) -0.108251005 1.5149781e-05 0.10825272\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.weight (256,) -0.099994875 0.00016797625 0.09996452\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.bias (256,) -0.09980128 -0.0029777153 0.09829161\n",
      "encoder.layer_stack.0.pos_ffn.w_1.weight (1024, 256) -0.06846519 7.760219e-05 0.068465225\n",
      "encoder.layer_stack.0.pos_ffn.w_1.bias (1024,) -0.09991731 -0.0005095204 0.09979731\n",
      "encoder.layer_stack.0.pos_ffn.w_2.weight (256, 1024) -0.06846474 -3.9361115e-05 0.06846517\n",
      "encoder.layer_stack.0.pos_ffn.w_2.bias (256,) -0.0992996 -0.0051490255 0.09702168\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.weight (256,) -0.09993378 0.0034266734 0.099734716\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.bias (256,) -0.09973283 -0.0044198926 0.099347845\n",
      "encoder.layer_stack.1.slf_attn.w_qs.weight (256, 256) -0.108252525 1.2805678e-05 0.10825099\n",
      "encoder.layer_stack.1.slf_attn.w_ks.weight (256, 256) -0.10825245 0.00037993625 0.108250864\n",
      "encoder.layer_stack.1.slf_attn.w_vs.weight (256, 256) -0.10825271 -0.00023131027 0.10824587\n",
      "encoder.layer_stack.1.slf_attn.fc.weight (256, 256) -0.10825159 0.00021252132 0.108250685\n",
      "encoder.layer_stack.1.slf_attn.layer_norm.weight (256,) -0.098973475 0.0043452447 0.09964875\n",
      "encoder.layer_stack.1.slf_attn.layer_norm.bias (256,) -0.09965005 0.0014012037 0.099037364\n",
      "encoder.layer_stack.1.pos_ffn.w_1.weight (1024, 256) -0.06846499 -9.418086e-05 0.06846508\n",
      "encoder.layer_stack.1.pos_ffn.w_1.bias (1024,) -0.09972673 -0.001132353 0.099844635\n",
      "encoder.layer_stack.1.pos_ffn.w_2.weight (256, 1024) -0.068465166 -7.308832e-05 0.06846519\n",
      "encoder.layer_stack.1.pos_ffn.w_2.bias (256,) -0.09977978 0.0015129858 0.09973513\n",
      "encoder.layer_stack.1.pos_ffn.layer_norm.weight (256,) -0.09889406 -0.002374169 0.0994074\n",
      "encoder.layer_stack.1.pos_ffn.layer_norm.bias (256,) -0.09872192 -0.0009083771 0.09876237\n",
      "encoder.layer_norm.weight (256,) -0.09814785 -0.0036098957 0.09943644\n",
      "encoder.layer_norm.bias (256,) -0.09941792 0.0037170532 0.09996443\n",
      "decoder.A_emb2sec (100, 256, 256) -0.008113919 -2.8949792e-06 0.008113918\n",
      "decoder.att_layers.0.slf_attn.w_qs.weight (256, 256) -0.10825164 -0.00011040383 0.10824586\n",
      "decoder.att_layers.0.slf_attn.w_ks.weight (256, 256) -0.10823049 -0.00022186307 0.10825095\n",
      "decoder.att_layers.0.slf_attn.w_vs.weight (256, 256) -0.1082516 2.758611e-05 0.1082452\n",
      "decoder.att_layers.0.slf_attn.fc.weight (256, 256) -0.10825108 -0.00018091452 0.10824045\n",
      "decoder.att_layers.0.slf_attn.layer_norm.weight (256,) -0.09758768 0.0062840316 0.09994191\n",
      "decoder.att_layers.0.slf_attn.layer_norm.bias (256,) -0.099793114 -0.0032444966 0.09956586\n",
      "decoder.att_layers.0.pos_ffn.w_1.weight (1024, 256) -0.068464346 -1.5532398e-05 0.06846405\n",
      "decoder.att_layers.0.pos_ffn.w_1.bias (1024,) -0.09990789 -0.0011812059 0.09998126\n",
      "decoder.att_layers.0.pos_ffn.w_2.weight (256, 1024) -0.06846517 -4.372964e-05 0.06846471\n",
      "decoder.att_layers.0.pos_ffn.w_2.bias (256,) -0.09859377 0.0026157338 0.099923566\n",
      "decoder.att_layers.0.pos_ffn.layer_norm.weight (256,) -0.09961306 -0.0013842201 0.099655285\n",
      "decoder.att_layers.0.pos_ffn.layer_norm.bias (256,) -0.097278334 0.0018593847 0.09965809\n",
      "decoder.att_layers.1.slf_attn.w_qs.weight (256, 256) -0.10824983 0.00023837975 0.10824832\n",
      "decoder.att_layers.1.slf_attn.w_ks.weight (256, 256) -0.108246475 -0.00023016678 0.10825294\n",
      "decoder.att_layers.1.slf_attn.w_vs.weight (256, 256) -0.108250104 -5.8799113e-05 0.10824584\n",
      "decoder.att_layers.1.slf_attn.fc.weight (256, 256) -0.10825132 -1.4337662e-05 0.10824884\n",
      "decoder.att_layers.1.slf_attn.layer_norm.weight (256,) -0.09917933 -0.0016004062 0.098781824\n",
      "decoder.att_layers.1.slf_attn.layer_norm.bias (256,) -0.099096335 -0.0069711544 0.09925164\n",
      "decoder.att_layers.1.pos_ffn.w_1.weight (1024, 256) -0.06846483 2.833952e-05 0.068464324\n",
      "decoder.att_layers.1.pos_ffn.w_1.bias (1024,) -0.09997677 -0.0021640789 0.09995874\n",
      "decoder.att_layers.1.pos_ffn.w_2.weight (256, 1024) -0.06846487 6.750479e-05 0.068465\n",
      "decoder.att_layers.1.pos_ffn.w_2.bias (256,) -0.09916122 0.001474866 0.096876934\n",
      "decoder.att_layers.1.pos_ffn.layer_norm.weight (256,) -0.098020665 0.004113703 0.09960768\n",
      "decoder.att_layers.1.pos_ffn.layer_norm.bias (256,) -0.09787537 0.0014387997 0.09789109\n"
     ]
    }
   ],
   "source": [
    "model_encdec_0_cfg = parse_yaml_file_as(MllmEncdecCfg, encdec_0_model_cfg_fpath)\n",
    "model_encdec_0 = MllmEncdecLevel(model_encdec_0_cfg, 0).to(device)\n",
    "checkpoint_encdec_0 = torch.load(encdec_0_snapshot_fpath)\n",
    "model_encdec_0.load_state_dict(checkpoint_encdec_0['model'], strict=False)\n",
    "model_encdec_0.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ParsingModel[MllmEncdecCfg]\n__root__ -> with_vocab_decoder\n  field required (type=value_error.missing)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_encdec_1_cfg \u001b[38;5;241m=\u001b[39m \u001b[43mparse_yaml_file_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMllmEncdecCfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencdec_1_model_cfg_fpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m model_encdec_1 \u001b[38;5;241m=\u001b[39m MllmEncdecLevel(model_encdec_1_cfg, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m checkpoint_encdec_1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(encdec_1_snapshot_fpath)\n",
      "File \u001b[0;32m~/miniconda3/envs/mllm/lib/python3.10/site-packages/pydantic_yaml/_internals/v1.py:74\u001b[0m, in \u001b[0;36mparse_yaml_file_as\u001b[0;34m(model_type, file)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected Path, str or IO, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file\u001b[38;5;241m.\u001b[39mopen(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparse_yaml_raw_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mllm/lib/python3.10/site-packages/pydantic_yaml/_internals/v1.py:49\u001b[0m, in \u001b[0;36mparse_yaml_raw_as\u001b[0;34m(model_type, raw)\u001b[0m\n\u001b[1;32m     47\u001b[0m reader \u001b[38;5;241m=\u001b[39m YAML(typ\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, pure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# YAML 1.2 support\u001b[39;00m\n\u001b[1;32m     48\u001b[0m objects \u001b[38;5;241m=\u001b[39m reader\u001b[38;5;241m.\u001b[39mload(stream)\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparse_obj_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mllm/lib/python3.10/site-packages/pydantic/tools.py:38\u001b[0m, in \u001b[0;36mpydantic.tools.parse_obj_as\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/mllm/lib/python3.10/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ParsingModel[MllmEncdecCfg]\n__root__ -> with_vocab_decoder\n  field required (type=value_error.missing)"
     ]
    }
   ],
   "source": [
    "model_encdec_1_cfg = parse_yaml_file_as(MllmEncdecCfg, encdec_1_model_cfg_fpath)\n",
    "model_encdec_1 = MllmEncdecLevel(model_encdec_1_cfg, 1).to(device)\n",
    "checkpoint_encdec_1 = torch.load(encdec_1_snapshot_fpath)\n",
    "model_encdec_1.load_state_dict(checkpoint_encdec_1['model'], strict=False)\n",
    "model_encdec_1.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11, 100]),\n",
       " torch.Size([3, 100]),\n",
       " tensor([False,  True,  True,  True, False, False, False, False, False, False,\n",
       "         False]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 10\n",
    "batch = ds_loader.get_batch(i, train=False)\n",
    "docs_chunks, target_chunks, target_mask = batch.gen_tensors()\n",
    "docs_chunks.shape, target_chunks.shape, target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|query_begin|> Benoni, GautengBenoni is a town in Ekurhuleni municipality, Gauteng, South Africa.\\n\\nBenoni was also the setting for the MTV-inspired movie Crazy Monkey: Straight Outta Benoni, released internationally in 2005.\\n\\nPeople from Benoni\\n\\nCharlene, Princess of Monaco, (née Charlene Wittstock), swimmer, and consort of Prince Albert II of Monaco\\nBryan Habana, former Springboks rugby player\\nPhilip Holiday, IBF World Champion Boxer\\nMorris Kahn (born 1930), Israeli billionaire, founder and chairman of Aurec Group\\nMildred Mangxola, singer and member of the Mahotella Queens\\n Frith van der Merwe, schoolteacher at Benoni High and the most prolific female runner in the history of the Comrades Marathon\\nGenevieve Morton, top model \\nGrace Mugabe, former First Lady of Zimbabwe\\n Bradley Player, cricketer\\n Oliver Reginald Tambo, ANC, ANCYL and SACP hero during the Apartheid regime.\\nCharlize Theron, Oscar-winning actress (Academy Awards: Best Actress Monster (2003 film))\\nVic Toweel, former undisputed World bantamweight champion and South African boxing champion. <|query_end|>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_target = tokens_to_text(target_chunks)\n",
    "s_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|doc_begin|> <|doc_id_begin|> 5853387 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Marivirga atlantica <|doc_title_end|> <|doc_body_begin|> Marivirga atlantica is a Gram-negative, aerobic and rod-shaped bacterium from the genus of Marivirga which has been isolated from seawater from the Atlantic Ocean.\\n\\nReferences\\n\\nCategory:Sphingobacteriia\\nCategory:Bacteria described in 2015 <|doc_body_end|> <|doc_end|>\n",
      "<|doc_begin|> <|doc_id_begin|> 6064729 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Benoni, Gauteng <|doc_title_end|> <|doc_body_begin|> Benoni is a town in Ekurhuleni municipality, Gauteng, South Africa.\\n\\nBenoni was also the setting for the MTV-inspired movie Crazy Monkey: Straight Outta Benoni, released internationally in 2005.\\n\\nPeople from Benoni\\n\\nCharlene, Princess of Monaco, (née Charlene Wittstock), swimmer, and consort of Prince Albert II of\n",
      "<|doc_begin|> <|doc_id_begin|> 6064729 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  Monaco\\nBryan Habana, former Springboks rugby player\\nPhilip Holiday, IBF World Champion Boxer\\nMorris Kahn (born 1930), Israeli billionaire, founder and chairman of Aurec Group\\nMildred Mangxola, singer and member of the Mahotella Queens\\n Frith van der Merwe, schoolteacher at Benoni High and the most prolific female runner in the history of the Comrades Marathon\\nGene\n",
      "<|doc_begin|> <|doc_id_begin|> 6064729 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|> vieve Morton, top model \\nGrace Mugabe, former First Lady of Zimbabwe\\n Bradley Player, cricketer\\n Oliver Reginald Tambo, ANC, ANCYL and SACP hero during the Apartheid regime.\\nCharlize Theron, Oscar-winning actress (Academy Awards: Best Actress Monster (2003 film))\\nVic Toweel, former undisputed World bantamweight champion and South African boxing champion.\n",
      "<|doc_begin|> <|doc_id_begin|> 5854801 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Mark Bulkeley <|doc_title_end|> <|doc_body_begin|> Mark Bulkeley (born 3 April 1979) is a British sailor who competed in the 2004 Summer Olympics.\\n\\nReferences\\n\\nExternal links \\n \\n\\nCategory:1979 births\\nCategory:Living people\\nCategory:Olympic sailors of Great Britain\\nCategory:British male sailors (sport)\\nCategory:Sailors at the 2004 Summer Olympics – Tornado\\nCategory:Extreme Sailing Series sailors <|doc_body_end|> <|doc_end|>\n",
      "<|doc_begin|> <|doc_id_begin|> 6033746 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>. She for a time had a career as a dental technician. She married army officer Bohumir Zemanek in 1933. In 1948, she moved to Prague with her husband, where she became a housewife and cared for their natural and adopted children. Suffering from an unhappy marriage, a lack of direction once her children were grown, and the long-term effects of the death of her first-born son in 1939, Zemankova\n",
      "<|doc_begin|> <|doc_id_begin|> 6033746 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  endured long periods of depression throughout the 1950s.\\n\\nTo combat her depression, Zemánková's second son, Bohumil Zemánek, a sculptor, suggested she try drawing. At the age of fifty-two, she started creating \"swirling, luminous drawings\" which evolved into a \"repertoire of abstracted floral and insectlike forms set against flat, softly atmospheric backgrounds.\" Although some have\n",
      "<|doc_begin|> <|doc_id_begin|> 6033746 <|doc_id_end|> <|doc_offset_begin|> 273 <|doc_offset_end|>  argued she was in some sort of trance state as she worked in the early morning hours, Zemánková herself spoke only of an unpremeditated process: \"There was no need to reflect or erase--the drawing drew itself in a very delightful manner.\"\\n\\nLate in life, both of Zemánková's legs had to be amputated due to complications from diabetes.\\n\\nFurther reading \\nCavin-Morris Gallery\n",
      "<|doc_begin|> <|doc_id_begin|> 6029813 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Manikantana Mahime <|doc_title_end|> <|doc_body_begin|> Manikantana Mahime (Kannada: ಮಣಿಕಂಠನ ಮಹಿಮೆ) is a 1993 Indian Kannada film,  directed by K. Shankar and produced by V. Swaminathan. The film stars Vishnuvardhan\n",
      "<|doc_begin|> <|doc_id_begin|> 6029813 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>, Sarath Babu, Sreekanth and Srinivasa Murthy in the lead roles. The film has musical score by M. S. Viswanathan. The film was dubbed into Tamil as Varuvaan Manikandan.\\n\\nCast\\n\\nVishnuvardhan\\nSarath Babu\\nSreekanth\\nSrinivasa Murthy\\nSrinath\\nM. N. Nambiar\\nSh\n",
      "<|doc_begin|> <|doc_id_begin|> 6029813 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|> ivaram\\nSeetharam\\nM. D. Kaushik\\nJayapradha\\nTara\\nPandari Bai\\nMynavathi\\nB. V. Radha\\nVaishali Kasaravalli\\nM. S. Karanth\\nBharath Bhagavathar\\n\\nReferences\\n\\nExternal links\\n \\n \\n\\nCategory:1993 films\\nCategory:Indian films\\nCategory:1990s Kann\n"
     ]
    }
   ],
   "source": [
    "for toks in docs_chunks:\n",
    "    s = tokens_to_text(toks)\n",
    "    print(s[:600].replace('\\n', '\\\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11, 100, 50271]), torch.float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_chunks_pred = model_encdec_0(docs_chunks)\n",
    "# docs_chunks_pred = torch.sigmoid(docs_chunks_pred)\n",
    "docs_chunks_pred = torch.softmax(docs_chunks_pred, dim=-1)\n",
    "docs_chunks_pred.shape, docs_chunks_pred.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 100])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_toks_pred = torch.argmax(docs_chunks_pred, dim=-1)\n",
    "dc_toks_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 729 Debug <|doc_end|> Runtime JPM <|doc_body_end|>  EthereumforeseenCategory <|query_end|> Args Ibid Ibidusterityusterity <|query_end|> <|query_end|> HopefullyHopefully\"} falsehood falsehood falsehood,\",\",\",\" NEED NEED wedd],\"foreseenforeseenforeseenforeseenforeseenforeseen!=!= unfocusedforeseenforeseenforeseenforeseenforeseenforeseenforeseenforeseenforeseenforeseen weddSettingsvPforeseenforeseenCONTforeseenSettings)\\SettingsclaimerforeseenArgsArgsArgsArgsArgsArgsArgsArgsArgsArgsArgsArgsArgsArgsArgsArgsoths��� <|doc_id_begin|> <|doc_id_begin|> <|doc_id_begin|> <|doc_id_begin|> <|doc_id_begin|> <|doc_id_begin|> <|doc_id_begin|> <|doc_id_begin|> <|doc_id_begin|> <|doc_id_begin|> <|doc_begin|> <|doc_id_begin|> <|doc_id_begin|>\n",
      "100 813 Debug <|doc_end|>  SLIforeseen <|doc_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> Args\"}\"}\"}\"}\"}\"}\"}\"}\"}\"}\"},\",\"ombies,\"],\"],\"],\"],\"],\"\"} <|doc_end|> <|doc_end|> <|doc_end|> <|doc_end|> <|doc_end|> <|doc_end|> ],\" <|doc_end|> <|doc_end|> ],\"\"}],\"],\"],\"],\"],\"\"} <|doc_end|> <|doc_end|> <|doc_end|> <|doc_end|> <|doc_end|> <|doc_end|> <|doc_end|> <|doc_end|> <|doc_end|> <|doc_title_begin|> <|doc_title_begin|> ,\",\" <|query_begin|>  confounding reperto reperto reperto reperto reperto reperto reperto reperto reperto reperto reperto reperto reperto <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|>  reperto repertoDeviceDeviceregorregorregor advant advant\n",
      "100 805  THANK <|doc_body_end|> Runtime Dou <|doc_body_end|> <|doc_body_end|> <|doc_offset_begin|> <|query_end|> <|query_end|> <|doc_body_end|> <|doc_body_end|> <|doc_body_end|> \\n\\n\\n\\nSEE <|query_end|> <|doc_body_end|> ControllerController Open <|query_begin|>  nodd <|doc_id_begin|> <|doc_id_begin|> <|doc_end|> <|doc_end|> <|doc_end|> <|doc_end|> <|doc_end|> <|doc_end|> <|doc_end|> <|doc_end|>  to to also station to to to to to their <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|doc_offset_end|>, <|query_begin|>,,,,,,, <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|doc_offset_end|> <|doc_offset_end|> <|doc_offset_end|> <|doc_offset_end|>,,, House House House <|query_end|> <|query_end|> <|query_end|>\n",
      "100 907  THANK <|doc_end|> Runtime JPM <|doc_id_begin|> <|doc_end|> <|doc_offset_begin|> 184 <|doc_id_end|> <|query_end|> Optional Ibid###\\n\\n\\n\\n <|query_end|> <|doc_body_end|> <|doc_body_end|> <|doc_body_end|> <|doc_body_end|> <|doc_body_end|> ],\"rieving <|doc_id_begin|> rievingrievingrieving <|doc_id_begin|> <|doc_id_begin|> <|doc_id_begin|> <|doc_id_begin|> ControllerControllerControllerController falsehood falsehoodController fridge <|doc_offset_begin|> <|doc_offset_begin|> <|doc_offset_begin|> 184184 <|doc_offset_begin|> 184 <|doc_offset_begin|>, in,0 WANT WANT WANT WANT WANT <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|doc_offset_end|> <|doc_offset_end|> <|doc_offset_end|> <|doc_offset_end|> <|doc_offset_end|> <|doc_offset_end|> <|doc_offset_end|> <|doc_offset_end|> <|doc_body_begin|> <|doc_offset_end|>, ( ( (::: ( ( (: (::::::::: MUST::::Tags\n",
      "100 1099  SLI <|doc_end|>  SLI JPM <|doc_begin|> {\" <|doc_id_end|> <|doc_id_begin|> <|doc_id_end|> <|query_end|> <|doc_body_end|>  Korra <|doc_id_begin|> <|doc_body_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> foreseen pandemonium pandemonium falsehood pandemonium pandemonium pandemoniumforeseen <|doc_end|> <|doc_end|> <|doc_end|> <|doc_end|> <|doc_end|> <|doc_end|> <|doc_end|> <|doc_end|> <|doc_id_end|> <|doc_id_end|> <|doc_id_end|> <|doc_id_end|> <|doc_id_end|> <|doc_id_end|> <|doc_id_end|> <|doc_id_end|> <|doc_id_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|doc_end|> <|doc_end|> <|doc_end|> <|doc_end|>  had themTHIS had <|query_begin|>  also also <|doc_id_end|> <|doc_begin|> <|doc_begin|> <|doc_begin|> <|doc_begin|>  also also also alsoographyographyographyographyographyographyographyographyographyographyographyographyographyographyArgsArgs <|doc_begin|> <|doc_begin|> <|doc_begin|> <|doc_begin|> <|doc_begin|> regor Warranty PATH <|doc_begin|> <|doc_id_end|>\n",
      "100 1128  THANK <|doc_end|> -------------------------------- JPM!] <|doc_end|> <|doc_offset_begin|> 184 <|doc_id_end|>._._ Ibid born bornusterityusterityusterityusterity <|doc_end|> <|doc_body_end|>._�Settings],\"Settings LuffySettingsSettingsSettings],\"cms noddcms nodd nodd nodd <|doc_title_begin|> <|doc_offset_begin|> <|doc_offset_begin|> <|doc_offset_begin|> ##claimerclaimerSettingsSettingsSettingsSettingsSettingsDebugDebugDebugDebugDebugDebug Xiaomi WANTreenshots <|query_begin|> <|query_begin|> <|doc_title_begin|> <|doc_title_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|doc_offset_end|> <|doc_offset_end|> <|doc_offset_end|>. <|doc_offset_end|>., <|doc_body_begin|> <|doc_body_begin|> <|doc_body_begin|> <|doc_body_begin|> <|doc_body_begin|> <|doc_body_begin|> <|doc_title_end|> <|doc_title_end|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|doc_offset_end|> <|doc_offset_end|> <|doc_offset_end|> <|doc_offset_end|> <|doc_offset_end|> <|doc_offset_end|> <|doc_offset_end|> <|doc_offset_end|>.. and\n",
      "100 863  THANK <|doc_end|>  didnt JPM <|doc_body_end|> <|doc_body_end|> <|doc_offset_begin|> 184 <|doc_id_end|> Filename Chocobo Ibid Ibidusterityusterityusterityusterity pandemonium\"}\"} falsehood falsehood],\"cms suggSettingsSettingsSettingsSettings <|doc_id_begin|> cms Belichick falsehood falsehood falsehood falsehoodcmsclaimerattr hrefSettingsSettingsSettingsSettingsSettingsSettingsSettingsSettingsSettingsSettingsSettingsSettingsSettingscmsSettingsSettingsSettingsSettingsctldqtiletiletiledebug Izan Izan Izan Izan Izan Izan Izan HAS HAS HAS Izan HAS <|query_begin|> <|query_begin|> : <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> ::: MUST\n",
      "100 1019  THANK <|doc_end|> -------------------------------- JPM!] <|query_end|> <|doc_offset_begin|> 184 <|doc_id_end|>._._ Ibid bornusterityusterityusterityusteritydxusterityusterityusterityusterity/+ falsehood/+/+SettingsSettingsSettings falsehood falsehood falsehood falsehood falsehood falsehood falsehoodclaimer <|doc_id_begin|> <|doc_id_begin|> <|doc_id_begin|> <|doc_id_begin|> <|doc_id_begin|> claimer NRS000 concess concessregor installer installer installer installer installer installer concess concess <|query_begin|>  concess concess <|query_begin|>  concess <|query_begin|> workshopworkshop Wrapworkshop Wrapworkshop Wrapworkshop <|doc_title_end|> ULTSTags <|doc_title_end|> <|doc_title_end|> ULTS <|doc_title_end|> ULTS <|doc_title_end|> <|doc_title_end|> ULTS <|query_begin|> ULTSTags <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|doc_id_begin|> <|doc_id_begin|> <|doc_id_begin|>\n",
      "100 976 Debug <|doc_end|>  SLI JPM <|doc_body_end|> <|query_end|>  PRESS was <|query_end|> <|query_end|> \"}\"}\"}����,\",\",\",\",\"ombiesombiesombiesombiesombiesombiesombies],\"],\"],\"],\" falsehood <|doc_end|> <|doc_end|> <|doc_end|> <|doc_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> <|query_end|> �� <|query_end|> ����ombiesombiesombiesombies Warranty Warranty Warrantyworkshop Warrantyworkshopworkshopworkshopworkshop <|query_begin|> <|query_begin|> advertisement <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|query_begin|> <|doc_begin|> <|doc_begin|> advertisementpaio)\\ Warranty Warrantyworkshop advant\n",
      "100 850  THANK <|doc_end|> -------------------------------- JPM!] <|query_end|> <|doc_offset_begin|> 184 <|doc_id_end|> <|query_end|> ULTS Ibid born bornusterityusterityusterity <|query_end|> <|query_end|> HopefullyHopefullyusterity falsehood falsehood falsehood falsehood falsehood falsehood falsehood falsehood falsehood falsehood falsehood falsehood falsehood falsehood falsehood falsehood falsehood falsehood falsehood thankfully obsess obsess <|doc_end|> <|doc_end|> <|doc_end|> <|doc_end|>  of ofRECTdxdxdxdx MOT concess concess concess concess concess concess REL REL REL REL REL RELTHIS REL REL REL <|doc_title_end|> <|doc_title_end|>  REL <|doc_title_end|> <|doc_title_end|>  Luffy <|doc_title_end|> <|doc_title_end|> <|doc_title_end|> <|doc_title_end|>  Luffy Luffy Luffy Luffy Luffy Luffy Luffy LuffyReferences Luffy Luffy Luffy Luffy:::inc SHOULD\n",
      "100 920  THANK <|doc_end|> Runtimeforeseen <|doc_id_begin|> Category <|doc_offset_begin|> <|query_end|> <|query_end|> ULTS Ibid Ibid <|doc_offset_end|> <|doc_offset_end|> <|query_begin|> <|doc_offset_end|> ControllerControllerControllerControllerController <|doc_offset_end|> <|doc_offset_end|> <|doc_offset_end|> <|doc_offset_end|>  Dumbledore Dumbledore <|doc_id_begin|> <|doc_id_begin|> <|doc_id_begin|> <|doc_id_begin|>  Belichick Belichick <|doc_offset_end|> <|doc_offset_end|> <|doc_title_begin|> <|doc_offset_begin|> 184 to <|doc_id_begin|> <|doc_id_begin|> <|doc_offset_begin|> <|doc_offset_begin|>  to of of <|doc_id_begin|> <|doc_id_end|> <|doc_id_begin|> <|doc_id_begin|> 0 <|doc_id_begin|> <|doc_id_begin|>  to to to to <|doc_offset_end|> <|doc_offset_end|> <|doc_offset_end|> <|doc_offset_end|> <|doc_offset_end|> <|doc_offset_end|> <|doc_offset_end|>,,,,,,,,,,\\n,::::::::::::::::: <|doc_id_begin|> <|doc_id_begin|>\n"
     ]
    }
   ],
   "source": [
    "for toks in dc_toks_pred:\n",
    "    s = tokens_to_text(toks)\n",
    "    s = s.replace('\\n', '\\\\n')\n",
    "    print(len(toks), len(s), s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "txts = [\n",
    "    '<|doc_begin|> 20 <|doc_id_begin|> 733860 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>Hello, my name is Mikhail<|doc_end|>',\n",
    "    'Malaga is a city in Spain',\n",
    "    'LLM stands for Large <|mask|> Model',\n",
    "    'You\\'d better learn new modeling approaches first, Mikhail from Malaga, Spain!',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "<|doc_begin|>  20  <|doc_id_begin|>  733860  <|doc_id_end|>   <|doc_offset_begin|>  91  <|doc_offset_end|> Hello, my name is Mikhail <|doc_end|>\n",
      "Malaga is a city in Spain\n",
      "LLM stands for Large  <|mask|>  Model\n",
      "You'd better learn new modeling approaches first, Mikhail from Malaga, Spain!\n"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "for txt in txts:\n",
    "    toks = text_to_tokens(txt)\n",
    "    print(toks.shape)\n",
    "    chunks.append(toks)\n",
    "\n",
    "chunks = torch.concat(chunks)\n",
    "for toks in chunks:\n",
    "    s = tokens_to_text(toks)\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 100, 50271]) torch.float32\n",
      "torch.Size([4, 100])\n"
     ]
    }
   ],
   "source": [
    "chunks_pred = model_encdec_0(chunks)\n",
    "# chunks_pred = torch.sigmoid(chunks_pred)\n",
    "chunks_pred = torch.softmax(chunks_pred, dim=-1)\n",
    "print(chunks_pred.shape, chunks_pred.dtype)\n",
    "toks_pred = torch.argmax(chunks_pred, dim=-1)\n",
    "print(toks_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|doc_begin|> <|doc_id_begin|> 111181, <|doc_offset_begin|> <|doc_offset_begin|> . ..\\n., my name is <|doc_body_end|>  \"\n",
      "Moo of Santao, <|query_end|>\n",
      ":Clms of by <|query_end|> <|query_end|>\n",
      ",,, a the,, TV, singer of Maraga, Serbia <|query_end|>\n"
     ]
    }
   ],
   "source": [
    "for toks in toks_pred:\n",
    "    s = tokens_to_text(toks)\n",
    "    s = s.replace('\\n', '\\\\n')\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1149, 0.7758], grad_fn=<IndexBackward0>)\n",
      "['.', '.']\n"
     ]
    }
   ],
   "source": [
    "probs = chunks_pred[0][8]\n",
    "inds = torch.arange(len(probs))\n",
    "prob_thres = 0.95\n",
    "prob_thres = 0.1\n",
    "probs_mask = probs >= prob_thres\n",
    "print(probs[probs_mask])\n",
    "toks = inds[probs_mask]\n",
    "strs = []\n",
    "for tok in toks:\n",
    "    toks_ = torch.Tensor([tok])\n",
    "    s = tokens_to_text(toks_)\n",
    "    strs.append(s)\n",
    "print(strs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\d{8}_\\d{6} re.compile('^[\\\\w-]+?\\\\-(\\\\d{8}_\\\\d{6})-.+$')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "DT_PAT_RE = r'\\d{8}_\\d{6}'\n",
    "pat = re.compile(r'^[\\w-]+?\\-(%s)-.+$' % DT_PAT_RE)\n",
    "print(DT_PAT_RE, pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encdec-20241018_092135-wiki_20 20241018_092135\n",
      "encdec-lvl0-20241026_120743-wi 20241026_120743\n",
      "encdec-33337128_001122-2024101 33337128_001122\n"
     ]
    }
   ],
   "source": [
    "paths = [\n",
    "    'encdec-20241018_092135-wiki_20200501_en-ch_100_fixed',\n",
    "    'encdec-lvl0-20241026_120743-wiki_20200501_en-ch_100_fixed-enc-lrs2-embmatFalse-d256-h8-dec-lrs2-seqlen100-d256-h8',\n",
    "    'encdec-33337128_001122-20241018_092135-wiki_20200501_en-ch_100_fixed',\n",
    "]\n",
    "for p in paths:\n",
    "    m = pat.match(p)\n",
    "    dt = None\n",
    "    if m:\n",
    "        dt = m.group(1)\n",
    "    print(p[:30], dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
