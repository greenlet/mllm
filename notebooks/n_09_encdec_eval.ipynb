{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import Optional\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pydantic_yaml import parse_yaml_file_as\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import GPT2Tokenizer, AddedToken, PreTrainedTokenizer\n",
    "\n",
    "from mllm.data.wiki.dswiki import WikiDsLoader\n",
    "from mllm.exp.args import TOKENIZER_CFG_FNAME, ENCDEC_MODEL_CFG_FNAME, RANKER_MODEL_CFG_FNAME\n",
    "from mllm.model.mllm_encdec import MllmEncdecLevel\n",
    "from mllm.model.mllm_ranker import MllmRankerLevel\n",
    "from mllm.config.model import TokenizerCfg, MllmEncdecCfg, MllmRankerCfg\n",
    "from mllm.tokenization.chunk_tokenizer import calc_max_inp_size, gen_all_tokens, ChunkTokenizer, tokenizer_from_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(os.path.expandvars('$HOME')) / 'data'\n",
    "DS_DIR_PATH = DATA_PATH / 'wiki_20200501_en' / 'ch_100_fixed'\n",
    "\n",
    "TRAIN_ENCDEC_0_PATH = DATA_PATH / 'train_mllm_encdec_0'\n",
    "TRAIN_ENCDEC_1_PATH = DATA_PATH / 'train_mllm_encdec_1'\n",
    "encdec_0_subdir = 'encdec-lvl0-20241028_093737-wiki_20200501_en-ch_100_fixed-enc-lrs3-embmatFalse-d256-h8-dec-lrs3-seqlen100-d256-h8-vocdecTrue'\n",
    "# encdec_0_subdir = 'encdec-lvl0-20241028_212210-wiki_20200501_en-ch_100_fixed-enc-lrs2-embmatFalse-d256-h8-dec-lrs2-seqlen100-d256-h8-vocdecTrue'\n",
    "encdec_0_subdir = 'encdec-lvl0-20241029_140645-wiki_20200501_en-ch_100_fixed-enc-lrs3-embmatFalse-d256-h8-dec-lrs3-seqlen100-d256-h8-vocdecTrue'\n",
    "encdec_1_subdir = 'encdec-lvl1-20241022_224217-msmarco-fever-enc-lrs2-embmatTrue-d256-h8-dec-lrs2-seqlen100-d256-h8'\n",
    "\n",
    "encdec_0_train_path = TRAIN_ENCDEC_0_PATH / encdec_0_subdir\n",
    "encdec_1_train_path = TRAIN_ENCDEC_1_PATH / encdec_1_subdir\n",
    "encdec_0_snapshot_fpath = encdec_0_train_path / 'last.pth'\n",
    "encdec_1_snapshot_fpath = encdec_1_train_path / 'best.pth'\n",
    "encdec_0_tkz_cfg_fpath = encdec_0_train_path / TOKENIZER_CFG_FNAME\n",
    "encdec_0_model_cfg_fpath = encdec_0_train_path / ENCDEC_MODEL_CFG_FNAME\n",
    "encdec_1_model_cfg_fpath = encdec_1_train_path / ENCDEC_MODEL_CFG_FNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "encdec_tkz_cfg = parse_yaml_file_as(TokenizerCfg, encdec_0_tkz_cfg_fpath)\n",
    "tokenizer = tokenizer_from_config(encdec_tkz_cfg)\n",
    "tok_dict = encdec_tkz_cfg.custom_tokens\n",
    "pad_tok, qbeg_tok, qend_tok = tok_dict['pad'].ind, tok_dict['query_begin'].ind, tok_dict['query_end'].ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "docs_batch_size = 5\n",
    "max_chunks_per_doc = 3\n",
    "model_level = 0\n",
    "device_name = 'cpu'\n",
    "# device_name = 'cuda'\n",
    "\n",
    "device = torch.device(device_name)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cache from /home/misha/data/wiki_20200501_en/ch_100_fixed/.mllm/ds.csv\n",
      "Loaded dataset size: 50989207\n"
     ]
    }
   ],
   "source": [
    "ds_loader = WikiDsLoader(\n",
    "    ds_path=DS_DIR_PATH, docs_batch_size=docs_batch_size, max_chunks_per_doc=max_chunks_per_doc,\n",
    "    pad_tok=pad_tok, qbeg_tok=qbeg_tok, qend_tok=qend_tok, device=device,\n",
    ")\n",
    "ds_loader.shuffle(train=True)\n",
    "ds_loader.shuffle(train=False)\n",
    "inp_len = ds_loader.emb_chunk_size if ds_loader.fixed_size else calc_max_inp_size(ds_loader.emb_chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_text(tokens: torch.Tensor) -> str:\n",
    "    tokens = tokens.flatten()\n",
    "    tokens = tokens[tokens != pad_tok]\n",
    "    tokens = list(tokens)\n",
    "    s = tokenizer.decode(tokens)\n",
    "    return s\n",
    "\n",
    "def distance(x: np.ndarray, y: np.ndarray, cosine: bool = False):\n",
    "    if not cosine:\n",
    "        return np.linalg.norm(x - y)\n",
    "    x_norm, y_norm = np.linalg.norm(x), np.linalg.norm(y)\n",
    "    return np.sum(x * y) / (x_norm * y_norm)\n",
    "\n",
    "def text_to_tokens(s: str, qbeg_tok: Optional[int] = None, qend_tok: Optional[int] = None) -> torch.Tensor:\n",
    "    tokens = tokenizer(s)['input_ids']\n",
    "    if qbeg_tok is not None:\n",
    "        assert qend_tok is not None\n",
    "        tokens = [qbeg_tok, *tokens, qend_tok]\n",
    "    n_tokens = len(tokens)\n",
    "    n_padded = n_tokens // inp_len + (n_tokens % inp_len > 0)\n",
    "    res = np.full((n_padded * inp_len, ), pad_tok, dtype=np.int32)\n",
    "    res[:n_tokens] = tokens\n",
    "    res = torch.from_numpy(res).to(device)\n",
    "    res = res.reshape(n_padded, inp_len)\n",
    "    return res\n",
    "\n",
    "def print_dist(target_embs: torch.Tensor, docs_embs: torch.Tensor, target_mask: torch.Tensor, cosine: bool = True):\n",
    "    for i, docs_emb in enumerate(docs_embs.detach().numpy()):\n",
    "        for target_emb in target_embs.detach().numpy():\n",
    "            dist = distance(target_emb, docs_emb, cosine)\n",
    "            print(f'{dist:0.6f} ', end='')\n",
    "        sfx = 'T' if target_mask[i] else 'F'\n",
    "        print(sfx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_encoder.src_word_emb.weight (50271, 256) -0.010897174 1.5427413e-06 0.010897168\n",
      "vocab_encoder.layer_norm.weight (256,) -0.09921918 -0.003043096 0.099875726\n",
      "vocab_encoder.layer_norm.bias (256,) -0.09917181 0.0022953348 0.09969459\n",
      "vocab_decoder.word_prj.weight (50271, 256) -0.010897173 1.249524e-06 0.010897166\n",
      "encoder.a_em () -0.05204276 -0.05204276 -0.05204276\n",
      "encoder.layer_stack.0.slf_attn.w_qs.weight (256, 256) -0.10825004 -7.579685e-05 0.1082439\n",
      "encoder.layer_stack.0.slf_attn.w_ks.weight (256, 256) -0.10825174 0.00032259405 0.108252816\n",
      "encoder.layer_stack.0.slf_attn.w_vs.weight (256, 256) -0.1082516 -0.000522124 0.108248696\n",
      "encoder.layer_stack.0.slf_attn.fc.weight (256, 256) -0.10824873 -9.985498e-05 0.10824885\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.weight (256,) -0.099781476 -0.00779331 0.09986692\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.bias (256,) -0.09984988 -0.0019489429 0.09859269\n",
      "encoder.layer_stack.0.pos_ffn.w_1.weight (1024, 256) -0.06846496 1.7575618e-05 0.06846507\n",
      "encoder.layer_stack.0.pos_ffn.w_1.bias (1024,) -0.099757016 -0.00046816928 0.09992883\n",
      "encoder.layer_stack.0.pos_ffn.w_2.weight (256, 1024) -0.06846461 -0.00011024914 0.06846512\n",
      "encoder.layer_stack.0.pos_ffn.w_2.bias (256,) -0.098712325 -0.0015645853 0.097608306\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.weight (256,) -0.09931391 0.003395395 0.099713705\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.bias (256,) -0.09993358 -0.0016298692 0.09988355\n",
      "encoder.layer_stack.1.slf_attn.w_qs.weight (256, 256) -0.10825261 -0.00012579461 0.10824975\n",
      "encoder.layer_stack.1.slf_attn.w_ks.weight (256, 256) -0.10825241 -0.00031562947 0.10825048\n",
      "encoder.layer_stack.1.slf_attn.w_vs.weight (256, 256) -0.10825115 -0.0002558769 0.10824765\n",
      "encoder.layer_stack.1.slf_attn.fc.weight (256, 256) -0.108247496 -0.0004016749 0.108251326\n",
      "encoder.layer_stack.1.slf_attn.layer_norm.weight (256,) -0.09944592 -0.0015137858 0.09978564\n",
      "encoder.layer_stack.1.slf_attn.layer_norm.bias (256,) -0.097427405 -0.0040646507 0.09880251\n",
      "encoder.layer_stack.1.pos_ffn.w_1.weight (1024, 256) -0.06846532 3.2869117e-05 0.06846449\n",
      "encoder.layer_stack.1.pos_ffn.w_1.bias (1024,) -0.09995997 -0.00039824843 0.09981827\n",
      "encoder.layer_stack.1.pos_ffn.w_2.weight (256, 1024) -0.06846529 1.7537746e-05 0.06846385\n",
      "encoder.layer_stack.1.pos_ffn.w_2.bias (256,) -0.099822104 0.0019751436 0.09935713\n",
      "encoder.layer_stack.1.pos_ffn.layer_norm.weight (256,) -0.0984476 -0.0041699223 0.09989474\n",
      "encoder.layer_stack.1.pos_ffn.layer_norm.bias (256,) -0.099667646 -0.005266523 0.09971096\n",
      "encoder.layer_stack.2.slf_attn.w_qs.weight (256, 256) -0.1082516 -0.00032271125 0.108252026\n",
      "encoder.layer_stack.2.slf_attn.w_ks.weight (256, 256) -0.10825155 0.00019168406 0.108252555\n",
      "encoder.layer_stack.2.slf_attn.w_vs.weight (256, 256) -0.10824672 0.00014976108 0.10825286\n",
      "encoder.layer_stack.2.slf_attn.fc.weight (256, 256) -0.108252525 0.00010599768 0.10825272\n",
      "encoder.layer_stack.2.slf_attn.layer_norm.weight (256,) -0.097991146 -0.004244564 0.09968767\n",
      "encoder.layer_stack.2.slf_attn.layer_norm.bias (256,) -0.09997519 0.0015940139 0.099323824\n",
      "encoder.layer_stack.2.pos_ffn.w_1.weight (1024, 256) -0.06846466 9.180451e-05 0.06846496\n",
      "encoder.layer_stack.2.pos_ffn.w_1.bias (1024,) -0.09989285 0.0019295784 0.09994712\n",
      "encoder.layer_stack.2.pos_ffn.w_2.weight (256, 1024) -0.068465315 5.8987483e-05 0.0684652\n",
      "encoder.layer_stack.2.pos_ffn.w_2.bias (256,) -0.09999742 -0.0038737403 0.09993799\n",
      "encoder.layer_stack.2.pos_ffn.layer_norm.weight (256,) -0.09941744 -0.0028127707 0.09644945\n",
      "encoder.layer_stack.2.pos_ffn.layer_norm.bias (256,) -0.09978423 -0.0026355977 0.09991735\n",
      "encoder.layer_norm.weight (256,) -0.09995007 0.0024693874 0.09940236\n",
      "encoder.layer_norm.bias (256,) -0.098349646 -0.0073449025 0.09915364\n",
      "decoder.A_emb2sec (100, 256, 256) -0.008113918 -1.0837837e-06 0.008113916\n",
      "decoder.att_layers.0.slf_attn.w_qs.weight (256, 256) -0.10825146 -0.0003841661 0.108249985\n",
      "decoder.att_layers.0.slf_attn.w_ks.weight (256, 256) -0.10825174 -0.00010569562 0.10824138\n",
      "decoder.att_layers.0.slf_attn.w_vs.weight (256, 256) -0.108241156 4.7788017e-06 0.108252764\n",
      "decoder.att_layers.0.slf_attn.fc.weight (256, 256) -0.10824977 9.150026e-05 0.10825312\n",
      "decoder.att_layers.0.slf_attn.layer_norm.weight (256,) -0.09956994 -0.00053709163 0.09990954\n",
      "decoder.att_layers.0.slf_attn.layer_norm.bias (256,) -0.0982412 -0.0006762729 0.099478416\n",
      "decoder.att_layers.0.pos_ffn.w_1.weight (1024, 256) -0.068464674 2.7037371e-05 0.06846531\n",
      "decoder.att_layers.0.pos_ffn.w_1.bias (1024,) -0.099992715 0.0017628947 0.09988556\n",
      "decoder.att_layers.0.pos_ffn.w_2.weight (256, 1024) -0.0684646 4.464821e-05 0.06846521\n",
      "decoder.att_layers.0.pos_ffn.w_2.bias (256,) -0.09948682 0.00042675497 0.09862719\n",
      "decoder.att_layers.0.pos_ffn.layer_norm.weight (256,) -0.099285446 0.0032424394 0.099218644\n",
      "decoder.att_layers.0.pos_ffn.layer_norm.bias (256,) -0.096793175 0.0034675582 0.09944963\n",
      "decoder.att_layers.1.slf_attn.w_qs.weight (256, 256) -0.108246826 0.00021762785 0.10825298\n",
      "decoder.att_layers.1.slf_attn.w_ks.weight (256, 256) -0.10825243 -0.00025148975 0.1082512\n",
      "decoder.att_layers.1.slf_attn.w_vs.weight (256, 256) -0.10824721 0.00011927931 0.10824614\n",
      "decoder.att_layers.1.slf_attn.fc.weight (256, 256) -0.108253054 0.00020628044 0.10824752\n",
      "decoder.att_layers.1.slf_attn.layer_norm.weight (256,) -0.09931296 0.0028034071 0.098591186\n",
      "decoder.att_layers.1.slf_attn.layer_norm.bias (256,) -0.09991906 -0.00018904079 0.0994543\n",
      "decoder.att_layers.1.pos_ffn.w_1.weight (1024, 256) -0.06846396 3.1219213e-05 0.06846316\n",
      "decoder.att_layers.1.pos_ffn.w_1.bias (1024,) -0.099783935 -0.00043926766 0.09985936\n",
      "decoder.att_layers.1.pos_ffn.w_2.weight (256, 1024) -0.06846477 -2.1709206e-05 0.06846502\n",
      "decoder.att_layers.1.pos_ffn.w_2.bias (256,) -0.098745994 0.0021790536 0.0995659\n",
      "decoder.att_layers.1.pos_ffn.layer_norm.weight (256,) -0.09462086 0.005202964 0.09948943\n",
      "decoder.att_layers.1.pos_ffn.layer_norm.bias (256,) -0.09710367 0.0031217653 0.09966908\n",
      "decoder.att_layers.2.slf_attn.w_qs.weight (256, 256) -0.10825285 -0.000373042 0.10825127\n",
      "decoder.att_layers.2.slf_attn.w_ks.weight (256, 256) -0.10823958 0.00013547535 0.108244285\n",
      "decoder.att_layers.2.slf_attn.w_vs.weight (256, 256) -0.10825241 0.00029020038 0.1082513\n",
      "decoder.att_layers.2.slf_attn.fc.weight (256, 256) -0.10825289 -0.00030761788 0.10825113\n",
      "decoder.att_layers.2.slf_attn.layer_norm.weight (256,) -0.0988845 0.0011477277 0.09976981\n",
      "decoder.att_layers.2.slf_attn.layer_norm.bias (256,) -0.09900657 0.003637786 0.09973361\n",
      "decoder.att_layers.2.pos_ffn.w_1.weight (1024, 256) -0.06846398 8.23013e-06 0.06846515\n",
      "decoder.att_layers.2.pos_ffn.w_1.bias (1024,) -0.09981888 0.0003653394 0.09998603\n",
      "decoder.att_layers.2.pos_ffn.w_2.weight (256, 1024) -0.068465315 9.952419e-07 0.0684638\n",
      "decoder.att_layers.2.pos_ffn.w_2.bias (256,) -0.09905922 0.0012875624 0.0990265\n",
      "decoder.att_layers.2.pos_ffn.layer_norm.weight (256,) -0.099995516 -0.0050511453 0.09741422\n",
      "decoder.att_layers.2.pos_ffn.layer_norm.bias (256,) -0.09942477 0.00091118296 0.09917742\n"
     ]
    }
   ],
   "source": [
    "model_encdec_0_cfg = parse_yaml_file_as(MllmEncdecCfg, encdec_0_model_cfg_fpath)\n",
    "model_encdec_0 = MllmEncdecLevel(model_encdec_0_cfg, 0).to(device)\n",
    "checkpoint_encdec_0 = torch.load(encdec_0_snapshot_fpath)\n",
    "model_encdec_0.load_state_dict(checkpoint_encdec_0['model'], strict=False)\n",
    "model_encdec_0.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ParsingModel[MllmEncdecCfg]\n__root__ -> with_vocab_decoder\n  field required (type=value_error.missing)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_encdec_1_cfg \u001b[38;5;241m=\u001b[39m \u001b[43mparse_yaml_file_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMllmEncdecCfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencdec_1_model_cfg_fpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m model_encdec_1 \u001b[38;5;241m=\u001b[39m MllmEncdecLevel(model_encdec_1_cfg, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m checkpoint_encdec_1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(encdec_1_snapshot_fpath)\n",
      "File \u001b[0;32m~/miniconda3/envs/mllm/lib/python3.10/site-packages/pydantic_yaml/_internals/v1.py:74\u001b[0m, in \u001b[0;36mparse_yaml_file_as\u001b[0;34m(model_type, file)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected Path, str or IO, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file\u001b[38;5;241m.\u001b[39mopen(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparse_yaml_raw_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mllm/lib/python3.10/site-packages/pydantic_yaml/_internals/v1.py:49\u001b[0m, in \u001b[0;36mparse_yaml_raw_as\u001b[0;34m(model_type, raw)\u001b[0m\n\u001b[1;32m     47\u001b[0m reader \u001b[38;5;241m=\u001b[39m YAML(typ\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, pure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# YAML 1.2 support\u001b[39;00m\n\u001b[1;32m     48\u001b[0m objects \u001b[38;5;241m=\u001b[39m reader\u001b[38;5;241m.\u001b[39mload(stream)\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparse_obj_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mllm/lib/python3.10/site-packages/pydantic/tools.py:38\u001b[0m, in \u001b[0;36mpydantic.tools.parse_obj_as\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/mllm/lib/python3.10/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ParsingModel[MllmEncdecCfg]\n__root__ -> with_vocab_decoder\n  field required (type=value_error.missing)"
     ]
    }
   ],
   "source": [
    "model_encdec_1_cfg = parse_yaml_file_as(MllmEncdecCfg, encdec_1_model_cfg_fpath)\n",
    "model_encdec_1 = MllmEncdecLevel(model_encdec_1_cfg, 1).to(device)\n",
    "checkpoint_encdec_1 = torch.load(encdec_1_snapshot_fpath)\n",
    "model_encdec_1.load_state_dict(checkpoint_encdec_1['model'], strict=False)\n",
    "model_encdec_1.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([13, 100]),\n",
       " torch.Size([3, 100]),\n",
       " tensor([False, False, False, False, False, False,  True,  True,  True, False,\n",
       "         False, False, False]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 10\n",
    "batch = ds_loader.get_batch(i, train=False)\n",
    "docs_chunks, target_chunks, target_mask = batch.gen_tensors()\n",
    "docs_chunks.shape, target_chunks.shape, target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|query_begin|> Sapri Tama\" (Ben-Amram, Shabazi, Traditional) - 5:44\\n\\nSide B: \\n\"Galbi\" (Amram, Shabazi)  4:14\\n\"Ode Le-Eli\" (Shabazi, Traditional) - 3:31\\n\"Lefelach Harimon\" (Shabazi, Traditional)  5:08\\n\"Ayelet Chen\" (Shabazi) - 6:30\\n\\nPersonnel\\n Ofra Haza - lead vocals\\n Benny Nagari - arranger, conductor, music producer\\n Lesli Lishinski, Marvin Feinshmit - bassoon\\n Ilan School - clarinet, bass clarinet\\n Eli Magen - double bass\\n Iki Levy - drums, congas, metal and wooden percussion, timbales\\n Abigail Erenheim, Benny Nagari - flute, piccolo\\n Shlomo Shochat - French horn\\n Meril Grinberg, Herman Openstein - oboe, English horn\\n Chaim Gispan - percussion (Yemenite tin & tambala)\\n Strings: Avraham Rosenblatt, Elchanan Bregman, Israel Berkowitch, Israela Wisser, Rima Kaminkowski, Yig <|query_end|>'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_target = tokens_to_text(target_chunks)\n",
    "s_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|doc_begin|> <|doc_id_begin|> 5836746 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  Albínói. He has also appeared in films such as Snowpiercer, X-Men: Apocalypse and Blade Runner 2049.\\n\\nPersonal life\\nTómas resides in Paris. He is fluent in Danish, English, French, and Icelandic.\\n\\nFilmography\\n\\nVilliljós (2001)\\nNói Albínói (2003) \\nLa maison de Nina (2005)\\nCold\n",
      "<|doc_begin|> <|doc_id_begin|> 5836746 <|doc_id_end|> <|doc_offset_begin|> 273 <|doc_offset_end|>  Trail (2006)\\nWie Schwefel in der Luft (short film, 2008) \\nLuftbusiness (2008)  \\nIch Bombe (short film, 2008) \\nDesember (2009)\\nMushrooms (2011) \\nErrors of the Human Body (2012) \\nInsensibles (2012) \\nAm Himmel der Tag (2012) \\nFrau Ella\n",
      "<|doc_begin|> <|doc_id_begin|> 5836746 <|doc_id_end|> <|doc_offset_begin|> 364 <|doc_offset_end|>  (2013) \\nSnowpiercer (2013) \\n3 Days to Kill (2014)\\nX-Men: Apocalypse (2016)\\nStefan Zweig: Farewell to Europe (2016)\\nSophia Awakens (2016)\\nBlade Runner 2049 (2017)\\nTouch Me Not (2018)\\nUndir Halastjörnu (2018)\\n\\nReferences\\n\\nExternal links\\n\\nTómas Lem\n",
      "<|doc_begin|> <|doc_id_begin|> 6014549 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Friendly-index set <|doc_title_end|> <|doc_body_begin|> In graph theory,  a friendly-index set is a finite set of integers associated with a given undirected graph and generated by a type of graph labeling called a friendly labeling.\\n\\nA friendly labeling of an -vertex undirected graph  is defined to be an assignment of the values 0 and 1 to the vertices of  with the property that the number of vertices labeled 0 is as\n",
      "<|doc_begin|> <|doc_id_begin|> 6014549 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  close as possible to the number of vertices labeled 1: they should either be equal (for graphs with an even number of vertices) or differ by one (for graphs with an odd number of vertices).\\n\\nGiven a friendly labeling of the vertices of, one may also label the edges: a given edge  is labeled with a 0 if its endpoints  and  have equal labels, and it is labeled with a 1 if its\n",
      "<|doc_begin|> <|doc_id_begin|> 6014549 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  endpoints have different labels. The friendly index of the labeling is the absolute value of the difference between the number of edges labeled 0 and the number of edges labeled 1.\\n\\nThe friendly index set of, denoted, is the set of numbers that can arise as friendly indexes of friendly labelings of.\\n\\nThe Dynamic Survey of Graph Labeling contains a list of papers that examines the friendly indices of various graphs.\\n\\nReferences\\n\\nExternal\n",
      "<|doc_begin|> <|doc_id_begin|> 6018912 <|doc_id_end|> <|doc_offset_begin|> 364 <|doc_offset_end|> Sapri Tama\" (Ben-Amram, Shabazi, Traditional) - 5:44\\n\\nSide B: \\n\"Galbi\" (Amram, Shabazi)  4:14\\n\"Ode Le-Eli\" (Shabazi, Traditional) - 3:31\\n\"Lefelach Harimon\" (Shabazi, Traditional)  5:08\\n\"Ayelet Chen\n",
      "<|doc_begin|> <|doc_id_begin|> 6018912 <|doc_id_end|> <|doc_offset_begin|> 455 <|doc_offset_end|> \" (Shabazi) - 6:30\\n\\nPersonnel\\n Ofra Haza - lead vocals\\n Benny Nagari - arranger, conductor, music producer\\n Lesli Lishinski, Marvin Feinshmit - bassoon\\n Ilan School - clarinet, bass clarinet\\n Eli Magen - double bass\\n Iki Levy - drums, congas, metal and wooden percussion, timbales\\n Abigail Eren\n",
      "<|doc_begin|> <|doc_id_begin|> 6018912 <|doc_id_end|> <|doc_offset_begin|> 546 <|doc_offset_end|> heim, Benny Nagari - flute, piccolo\\n Shlomo Shochat - French horn\\n Meril Grinberg, Herman Openstein - oboe, English horn\\n Chaim Gispan - percussion (Yemenite tin & tambala)\\n Strings: Avraham Rosenblatt, Elchanan Bregman, Israel Berkowitch, Israela Wisser, Rima Kaminkowski, Yig\n",
      "<|doc_begin|> <|doc_id_begin|> 6021329 <|doc_id_end|> <|doc_offset_begin|> 2620 <|doc_offset_end|>  highlight the wisdom and sparkling ideas of oversea countries and build a bridge connecting the West and East. Nova Monthly contains 5 interdisciplinary columns: \"Living\", \"Sports\", \"Entertainment\", \"Technology,\" and \"Column X\".\\n\\nNirvana News \\nNirvana News (涅槃新闻) is an independent campus news outlet established and run exclusively by students. It reports on various campus events, and\n",
      "<|doc_begin|> <|doc_id_begin|> 6021329 <|doc_id_end|> <|doc_offset_begin|> 2710 <|doc_offset_end|>  aims to provide an impartial and objective portrait of campus affairs in Shenzhen Middle School. \\n\\nNirvana News has emerged from Nirvana Weekly (涅槃周刊), which was a comprehensive Chinese magazine first published by Shenzhen Middle School students in November 2009. Being an unaffiliated and non-profit magazine, Nirvana Weekly aimed to deliver intramural and extramural information with fine quality, spread contemporary citizen ideals,\n",
      "<|doc_begin|> <|doc_id_begin|> 6021329 <|doc_id_end|> <|doc_offset_begin|> 2800 <|doc_offset_end|>  and solicit consideration and discussion among its readers. The magazine's motto was \"Through the darkest dark, may we see the light. (越万里之溟濛兮，见凤之流光)\"  In a report published in June 2011, it was dubbed the most daring publication in China, and that most of the mainstream publications couldn't match its outspokenness.\\n\n",
      "<|doc_begin|> <|doc_id_begin|> 5991676 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Saint-Léger-le-Petit <|doc_title_end|> <|doc_body_begin|> Saint-Léger-le-Petit  is a commune in the Cher department in central France.\\n\\nPopulation\\n\\nSee also\\nCommunes of the Cher department\\n\\nReferences\\nINSEE\\n\\nCategory:Communes of Cher (department) <|doc_body_end|> <|doc_end|>\n"
     ]
    }
   ],
   "source": [
    "for toks in docs_chunks:\n",
    "    s = tokens_to_text(toks)\n",
    "    print(s[:600].replace('\\n', '\\\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([13, 100, 50271]), torch.float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_chunks_pred = model_encdec_0(docs_chunks)\n",
    "# docs_chunks_pred = torch.sigmoid(docs_chunks_pred)\n",
    "docs_chunks_pred = torch.softmax(docs_chunks_pred, dim=-1)\n",
    "docs_chunks_pred.shape, docs_chunks_pred.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 100])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_toks_pred = torch.argmax(docs_chunks_pred, dim=-1)\n",
    "dc_toks_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 381 <|doc_begin|> <|doc_id_begin|> 141742 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  Guínói. He has also appeared in films such as e lorers, X-Men: Legend and La ages 20 2013.\\n\\nPersonal life\\nTugra participated in actor. He is fluent in France, Spanish, television, and cinema.\\n\\nFilmography\\n\\nManelvós (2001)\\nNói Guínói (2003) \\nLa Antonzo de Franco (2005)\\nPaul\n",
      "100 323 <|doc_begin|> <|doc_id_begin|> 141745 <|doc_id_end|> <|doc_offset_begin|> 273 <|doc_offset_end|>  Room (2006)\\nWie Yefel in der Deft (2009 film, 2008) \\nLeftker (2008)  \\nIchungbe (Art film, 2008) \\nCentters (2009)\\nMengker (2011) \\n Eaughters of the High Woman (2012) \\nFreurrics (2012) \\nThwunel der Art (2012) \\n Mau Bea\n",
      "100 325 <|doc_begin|> <|doc_id_begin|> 141746 <|doc_id_end|> <|doc_offset_begin|> 364 <|doc_offset_end|>  (2013) \\nDie Kuers (2013) \\n3 Love at Sky (2014)\\n2-TV:2014 (2016)\\nIfan Adunl: Mixte to Life (2016)\\nSortia Mama (2016)\\n2014 Line 20've (2017)\\nSoul Mex (2018)\\nNeiru tjreelle (2018)\\n\\nReferences\\n\\nExternal links\\n\\nTudraou\n",
      "100 516 <|doc_begin|> <|doc_id_begin|> 141649 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Signly-part set <|doc_title_end|> <|doc_body_begin|> In graph theory,  a mathematics-part), is a finite set of graphs associated with a given uniform graphed graph and defined by a type of graph graphs with a valid algorithm.\\n\\nA mathematics graphs of an - Igebra ex graphizes graph  is defined to be an effect of the AC* and 1 to the vertices of  with the table that the number of vertices - 0 is as\n",
      "100 480 <|doc_begin|> <|doc_id_begin|> 143049 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  one as addition to the number of vertices - 1  They is depending be fixed (for graphs with for or number of vertices) or differ by one (for graphs with an approximate number of vertices).\\n\\nGiven a variable vertex of the vertices of each one may also fixed the edges: a the edge  is grouped with a 0 if its top graph  and  have these variations, and it is inserted with a it are its\n",
      "100 562 <|doc_begin|> <|doc_id_begin|> 141649 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  end symbols have different pairs. The random dimensions of the weights is the minimum value of the difference between the number of values when copies and the number of context measuring it.\\n\\nThe variable index set a only digit value, is the set of size that can observed as random instances of randomi system of.\\n\\nThe Test Book of Poid algorithm contains a list of individuals that defines the variable registers of various contexts.\\n\\nReferences\\n\\nExternal\n",
      "100 293 <|doc_begin|> <|doc_id_begin|> 144514 <|doc_id_end|> <|doc_offset_begin|> 364 <|doc_offset_end|> Sajaghlama\" (Me-Shram, Shabiri, Kurdistan) - 5:04\\n\\nInternational B  \\n\"Humple\" (Amud, Shabati)  4:14\\n\"Omaral-Eli\" (Shabati, Kurdistan) - 3:31\\n\"Lahesh Nāq\" (Shabiri, Georgia).13:04\\n\"Aye Marala\n",
      "100 401 <|doc_begin|> <|doc_id_begin|> 141713 <|doc_id_end|> <|doc_offset_begin|> 455 <|doc_offset_end|> \" (Vabinsky) - 6:30\\n\\nPersonnel\\n John Algiddle - lead vocals\\n Stefan Doren - arranger, rhythm, music producer\\n Kim De Rino Suzuki, Stefan Bozchanger - bass violin\\n Iuerto - clarinet, bass clarinet\\n Michauen - drums bass\\n Iin Jensen - drums, drumgas, rhythm and jazz percussion, timbro\\n Paragel ll\n",
      "100 358 <|doc_begin|> <|doc_id_begin|> 141714 <|doc_id_end|> <|doc_offset_begin|> 546 <|doc_offset_end|> ling, bass Johen - flak, harolin\\n Shiborus Shachat - Russian horn\\n Kamakkinberg, Gun White White - Holter, electric horn\\n Cheklisen - percussion (Welkyhorn & tambolin)\\n Muser: Nesten Kunkut, Elmenan Binnman, Frank Krekier, Franka Worner, Rima Kalzowski, Yig\n",
      "100 468 <|doc_begin|> <|doc_id_begin|> 141721 <|doc_id_end|> <|doc_offset_begin|> 2620 <|doc_offset_end|>  change the premise and vibrant footage of over internet countries and over a project inside the City and China. Daily Tribune with I OMedia website\". \"T\", \"Media\", \"Entertainment\", \"platform\", and \"IsraelY\".\\n\\nNoy Media News \\nNah Media News \" \"�-��댑l\" is an independent news news forum established and other distributed by 2012. It reports on various news events, and\n",
      "100 516 <|doc_begin|> <|doc_id_begin|> 141721 <|doc_id_end|> <|doc_offset_begin|> 2729 <|doc_offset_end|>  aims to provide an entrepreneurship and industrial aspects of Ali media in Sha Aviv Science School. \\n\\nNetju News has featured from Tehran Studies (C�-���� �), which was a small high magazine, published by Tel Aviv Science School Foundation in November 2009. Being for teleivity and non-profit magazine, undergrad Weekly aimed to discuss upllations and intubural programs with large quality, their large user trends,\n",
      "100 410 <|doc_begin|> <|doc_id_begin|> 141730 <|doc_id_end|> <|doc_offset_begin|> 2800 <|doc_offset_end|>  and transcripting and images within its readers. The novel's blog was \"from the storytelling experiences, although we see the humans. \"猊����子栟��������矌��的�的\"). In a article published in June 2011, it was discussed the most manga event in China, and that most of the Earth website don't images of auditoryness.\\n\n",
      "100 404 <|doc_begin|> <|doc_id_begin|> 141777 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Saint-Léau-le-Comit <|doc_title_end|> <|doc_body_begin|> Saint-Léme-le-Comign  is a commune in the commun department in central France.\\n\\nPopulation\\n\\nSee also\\nCommunes of the Cher department\\n\\nReferences\\nINSEE\\n\\nCategory:Communes of Austria (department) <|doc_body_end|> <|doc_end|>\n"
     ]
    }
   ],
   "source": [
    "for toks in dc_toks_pred:\n",
    "    s = tokens_to_text(toks)\n",
    "    s = s.replace('\\n', '\\\\n')\n",
    "    print(len(toks), len(s), s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "txts = [\n",
    "    '<|doc_begin|> 20 <|doc_id_begin|> 733860 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>Hello, my name is Mikhail<|doc_end|>',\n",
    "    'Malaga is a city in Spain',\n",
    "    'LLM stands for Large <|mask|> Model',\n",
    "    'You\\'d better learn new modeling approaches first, Mikhail from Malaga, Spain!',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "<|doc_begin|>  20  <|doc_id_begin|>  733860  <|doc_id_end|>   <|doc_offset_begin|>  91  <|doc_offset_end|> Hello, my name is Mikhail <|doc_end|>\n",
      "Malaga is a city in Spain\n",
      "LLM stands for Large  <|mask|>  Model\n",
      "You'd better learn new modeling approaches first, Mikhail from Malaga, Spain!\n"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "for txt in txts:\n",
    "    toks = text_to_tokens(txt)\n",
    "    print(toks.shape)\n",
    "    chunks.append(toks)\n",
    "\n",
    "chunks = torch.concat(chunks)\n",
    "for toks in chunks:\n",
    "    s = tokens_to_text(toks)\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 100, 50271]) torch.float32\n",
      "torch.Size([4, 100])\n"
     ]
    }
   ],
   "source": [
    "chunks_pred = model_encdec_0(chunks)\n",
    "# chunks_pred = torch.sigmoid(chunks_pred)\n",
    "chunks_pred = torch.softmax(chunks_pred, dim=-1)\n",
    "print(chunks_pred.shape, chunks_pred.dtype)\n",
    "toks_pred = torch.argmax(chunks_pred, dim=-1)\n",
    "print(toks_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alusedis <|doc_id_begin|>  airlines ISO airlinesusedulated <|doc_offset_begin|> 0ountulated\"is <|doc_id_end|>  linkssk generic defunct also0 also is was <|doc_id_end|> <|doc_id_end|> ile generic A0 Comm design <|doc_id_begin|>  also also defunct airlines <|doc_id_end|> <|doc_id_end|> <|doc_id_end|> <|query_end|>  the <|doc_offset_begin|> <|doc_id_end|> <|query_end|> <|query_end|> <|doc_id_end|> <|doc_id_end|>  It distribution to <|doc_begin|>  The, <|doc_id_end|> <|doc_offset_begin|> <|doc_offset_end|>  generic scrapped <|doc_offset_begin|>  airlines generic 2is no, 2 launch a <|doc_id_end|> \\n sub design\\n Black was <|doc_offset_begin|> <|doc_id_end|> <|doc_id_end|>  refer <|doc_offset_begin|> <|doc_id_end|>  airlines\", a and,, <|doc_offset_begin|> <|doc_id_end|>  also <|doc_id_end|> <|doc_id_end|>,\n",
      "or the, the Transportation the theulated links  <|doc_id_begin|>   \\' marketers <|doc_offset_begin|> 0 <|doc_id_begin|>  plays, alsoard\"is is CommItized Rep designis alsois, firstulatedumentsumentsCommun <|doc_offset_begin|> <|doc_id_end|> <|doc_id_end|> orist toor Comm <|doc_id_end|> <|doc_id_end|> or alsoisuments the not <|doc_id_end|> <|doc_offset_begin|>  wasor generic its generic generic alsoor,, 2is a <|doc_id_end|> \\n Commal\\n two was <|query_end|> <|query_end|> <|doc_id_end|> <|doc_id_end|> oror only) <|doc_id_end|> \\n airlines, also <|doc_id_end|> <|doc_id_end|>  also <|doc_id_end|> <|doc_id_end|> encies\n",
      " venuesis, area ISO first first also also,  \\' \\' also0 first controls I also's 2is is toItor Rep mine <|query_end|> \\n\\n 2,, firstenciesuments defunct <|doc_offset_begin|> <|doc_id_end|> <|query_end|> or CommizedItor <|doc_id_end|> <|doc_id_end|>  strat also habitat strat the <|doc_begin|> <|doc_id_end|> <|doc_offset_begin|>  parkordm In generic generic also <|doc_id_end|>,, 2 Chile a <|doc_id_end|> \\n Import\\n water was It <|query_end|> <|doc_id_end|> <|doc_id_end|> oror\\n I wassk airlines  <|doc_id_end|> <|doc_id_end|> <|doc_id_end|>  also <|doc_id_end|> <|doc_id_end|> ized\n",
      "al the, area Transportation the,ulated <|doc_offset_begin|> ulateddm upgraded <|doc_id_begin|>  Alaska <|doc_offset_begin|> is\"\" was also\"\" is \"oris Comm stratis Commisisisis,,,ized generic Sites <|doc_id_end|> <|doc_id_end|> <|doc_id_end|> or also named mineized <|doc_id_end|> enedconst <|doc_offset_begin|>  distribution Comm <|query_end|>  Comm Comm <|doc_offset_begin|> <|doc_offset_begin|> is no airlines generic <|doc_id_begin|>  airlines 2isupon, 2 design the <|doc_id_end|>  Comm sub a\\n 2 was It <|doc_id_end|> <|doc_id_end|> <|doc_id_end|> ororor\"is generic airlines, and <|doc_id_end|> <|doc_id_end|>  also <|doc_id_end|> <|doc_id_end|>  negate\n"
     ]
    }
   ],
   "source": [
    "for toks in toks_pred:\n",
    "    s = tokens_to_text(toks)\n",
    "    s = s.replace('\\n', '\\\\n')\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], grad_fn=<IndexBackward0>)\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "probs = chunks_pred[0][8]\n",
    "inds = torch.arange(len(probs))\n",
    "prob_thres = 0.95\n",
    "prob_thres = 0.1\n",
    "probs_mask = probs >= prob_thres\n",
    "print(probs[probs_mask])\n",
    "toks = inds[probs_mask]\n",
    "strs = []\n",
    "for tok in toks:\n",
    "    toks_ = torch.Tensor([tok])\n",
    "    s = tokens_to_text(toks_)\n",
    "    strs.append(s)\n",
    "print(strs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MllmEncdecLevel(\n",
       "  (vocab_encoder): VocabEncoder(\n",
       "    (src_word_emb): Embedding(50271, 256, padding_idx=50267)\n",
       "    (position_enc): PositionalEncoding()\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (vocab_decoder): VocabDecoder(\n",
       "    (word_prj): Linear(in_features=256, out_features=50271, bias=False)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layer_stack): ModuleList(\n",
       "      (0-1): 2 x EncoderLayer(\n",
       "        (slf_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (w_ks): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (w_vs): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (fc): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): EmbDecoder(\n",
       "    (att_layers): ModuleList(\n",
       "      (0-1): 2 x EncoderLayer(\n",
       "        (slf_attn): MultiHeadAttention(\n",
       "          (w_qs): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (w_ks): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (w_vs): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (fc): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (attention): ScaledDotProductAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (pos_ffn): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_encdec_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_encdec_0.encoder.n_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\d{8}_\\d{6} re.compile('^[\\\\w-]+?\\\\-(\\\\d{8}_\\\\d{6})-.+$')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "DT_PAT_RE = r'\\d{8}_\\d{6}'\n",
    "pat = re.compile(r'^[\\w-]+?\\-(%s)-.+$' % DT_PAT_RE)\n",
    "print(DT_PAT_RE, pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encdec-20241018_092135-wiki_20 20241018_092135\n",
      "encdec-lvl0-20241026_120743-wi 20241026_120743\n",
      "encdec-33337128_001122-2024101 33337128_001122\n"
     ]
    }
   ],
   "source": [
    "paths = [\n",
    "    'encdec-20241018_092135-wiki_20200501_en-ch_100_fixed',\n",
    "    'encdec-lvl0-20241026_120743-wiki_20200501_en-ch_100_fixed-enc-lrs2-embmatFalse-d256-h8-dec-lrs2-seqlen100-d256-h8',\n",
    "    'encdec-33337128_001122-20241018_092135-wiki_20200501_en-ch_100_fixed',\n",
    "]\n",
    "for p in paths:\n",
    "    m = pat.match(p)\n",
    "    dt = None\n",
    "    if m:\n",
    "        dt = m.group(1)\n",
    "    print(p[:30], dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
