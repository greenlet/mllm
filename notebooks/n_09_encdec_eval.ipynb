{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import Optional\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pydantic_yaml import parse_yaml_file_as\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import GPT2Tokenizer, AddedToken, PreTrainedTokenizer\n",
    "\n",
    "from mllm.data.wiki.dswiki import WikiDsLoader\n",
    "from mllm.exp.args import TOKENIZER_CFG_FNAME, ENCDEC_MODEL_CFG_FNAME, RANKER_MODEL_CFG_FNAME\n",
    "from mllm.model.mllm_encdec import MllmEncdecLevel\n",
    "from mllm.model.mllm_ranker import MllmRankerLevel\n",
    "from mllm.config.model import TokenizerCfg, MllmEncdecCfg, MllmRankerCfg\n",
    "from mllm.tokenization.chunk_tokenizer import calc_max_inp_size, gen_all_tokens, ChunkTokenizer, tokenizer_from_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(os.path.expandvars('$HOME')) / 'data'\n",
    "DS_DIR_PATH = DATA_PATH / 'wiki_20200501_en' / 'ch_100_fixed'\n",
    "\n",
    "TRAIN_ENCDEC_0_PATH = DATA_PATH / 'train_mllm_encdec_0'\n",
    "TRAIN_ENCDEC_1_PATH = DATA_PATH / 'train_mllm_encdec_1'\n",
    "encdec_0_subdir = 'encdec-lvl0-20241026_120743-wiki_20200501_en-ch_100_fixed-enc-lrs2-embmatFalse-d256-h8-dec-lrs2-seqlen100-d256-h8'\n",
    "encdec_1_subdir = 'encdec-lvl1-20241022_224217-msmarco-fever-enc-lrs2-embmatTrue-d256-h8-dec-lrs2-seqlen100-d256-h8'\n",
    "\n",
    "encdec_0_train_path = TRAIN_ENCDEC_0_PATH / encdec_0_subdir\n",
    "encdec_1_train_path = TRAIN_ENCDEC_1_PATH / encdec_1_subdir\n",
    "encdec_0_snapshot_fpath = encdec_0_train_path / 'best.pth'\n",
    "encdec_1_snapshot_fpath = encdec_1_train_path / 'best.pth'\n",
    "encdec_0_tkz_cfg_fpath = encdec_0_train_path / TOKENIZER_CFG_FNAME\n",
    "encdec_0_model_cfg_fpath = encdec_0_train_path / ENCDEC_MODEL_CFG_FNAME\n",
    "encdec_1_model_cfg_fpath = encdec_1_train_path / ENCDEC_MODEL_CFG_FNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encdec_tkz_cfg = parse_yaml_file_as(TokenizerCfg, encdec_0_tkz_cfg_fpath)\n",
    "tokenizer = tokenizer_from_config(encdec_tkz_cfg)\n",
    "tok_dict = encdec_tkz_cfg.custom_tokens\n",
    "pad_tok, qbeg_tok, qend_tok = tok_dict['pad'].ind, tok_dict['query_begin'].ind, tok_dict['query_end'].ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "docs_batch_size = 5\n",
    "max_chunks_per_doc = 3\n",
    "model_level = 0\n",
    "device_name = 'cpu'\n",
    "# device_name = 'cuda'\n",
    "\n",
    "device = torch.device(device_name)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cache from /home/misha/data/wiki_20200501_en/ch_100_fixed/.mllm/ds.csv\n",
      "Loaded dataset size: 50989207\n"
     ]
    }
   ],
   "source": [
    "ds_loader = WikiDsLoader(\n",
    "    ds_path=DS_DIR_PATH, docs_batch_size=docs_batch_size, max_chunks_per_doc=max_chunks_per_doc,\n",
    "    pad_tok=pad_tok, qbeg_tok=qbeg_tok, qend_tok=qend_tok, device=device,\n",
    ")\n",
    "ds_loader.shuffle(train=True)\n",
    "ds_loader.shuffle(train=False)\n",
    "inp_len = ds_loader.emb_chunk_size if ds_loader.fixed_size else calc_max_inp_size(ds_loader.emb_chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_text(tokens: torch.Tensor) -> str:\n",
    "    tokens = tokens.flatten()\n",
    "    tokens = tokens[tokens != pad_tok]\n",
    "    tokens = list(tokens)\n",
    "    s = tokenizer.decode(tokens)\n",
    "    return s\n",
    "\n",
    "def distance(x: np.ndarray, y: np.ndarray, cosine: bool = False):\n",
    "    if not cosine:\n",
    "        return np.linalg.norm(x - y)\n",
    "    x_norm, y_norm = np.linalg.norm(x), np.linalg.norm(y)\n",
    "    return np.sum(x * y) / (x_norm * y_norm)\n",
    "\n",
    "def text_to_tokens(s: str, qbeg_tok: Optional[int] = None, qend_tok: Optional[int] = None) -> torch.Tensor:\n",
    "    tokens = tokenizer(s)['input_ids']\n",
    "    if qbeg_tok is not None:\n",
    "        assert qend_tok is not None\n",
    "        tokens = [qbeg_tok, *tokens, qend_tok]\n",
    "    n_tokens = len(tokens)\n",
    "    n_padded = n_tokens // inp_len + (n_tokens % inp_len > 0)\n",
    "    res = np.full((n_padded * inp_len, ), pad_tok, dtype=np.int32)\n",
    "    res[:n_tokens] = tokens\n",
    "    res = torch.from_numpy(res).to(device)\n",
    "    res = res.reshape(n_padded, inp_len)\n",
    "    return res\n",
    "\n",
    "def print_dist(target_embs: torch.Tensor, docs_embs: torch.Tensor, target_mask: torch.Tensor, cosine: bool = True):\n",
    "    for i, docs_emb in enumerate(docs_embs.detach().numpy()):\n",
    "        for target_emb in target_embs.detach().numpy():\n",
    "            dist = distance(target_emb, docs_emb, cosine)\n",
    "            print(f'{dist:0.6f} ', end='')\n",
    "        sfx = 'T' if target_mask[i] else 'F'\n",
    "        print(sfx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_encoder.src_word_emb.weight (50271, 256) -0.010897174 -3.6519843e-06 0.010897173\n",
      "vocab_encoder.layer_norm.weight (256,) -0.0998892 -0.0028097667 0.09690992\n",
      "vocab_encoder.layer_norm.bias (256,) -0.099947885 -0.0012904839 0.099928394\n",
      "vocab_decoder.word_prj.weight (50271, 256) -0.010897174 -1.8544521e-06 0.010897173\n",
      "encoder.a_em () 0.0035125257 0.0035125257 0.0035125257\n",
      "encoder.layer_stack.0.slf_attn.w_qs.weight (256, 256) -0.10824708 -0.00033453054 0.108253054\n",
      "encoder.layer_stack.0.slf_attn.w_ks.weight (256, 256) -0.10824891 -0.00026277496 0.108251795\n",
      "encoder.layer_stack.0.slf_attn.w_vs.weight (256, 256) -0.1082525 -0.00027601025 0.108245134\n",
      "encoder.layer_stack.0.slf_attn.fc.weight (256, 256) -0.108252764 0.00030779542 0.108250566\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.weight (256,) -0.099997304 6.118789e-05 0.09898521\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.bias (256,) -0.09913106 -0.0061583123 0.09971646\n",
      "encoder.layer_stack.0.pos_ffn.w_1.weight (1024, 256) -0.068464845 4.2547028e-05 0.06846521\n",
      "encoder.layer_stack.0.pos_ffn.w_1.bias (1024,) -0.09988367 0.0027359123 0.09996488\n",
      "encoder.layer_stack.0.pos_ffn.w_2.weight (256, 1024) -0.06846519 8.37013e-05 0.068464726\n",
      "encoder.layer_stack.0.pos_ffn.w_2.bias (256,) -0.09997634 0.0027652096 0.09909542\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.weight (256,) -0.09996517 -0.0005931008 0.096226454\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.bias (256,) -0.09955757 -0.0052364874 0.09746864\n",
      "encoder.layer_stack.1.slf_attn.w_qs.weight (256, 256) -0.108252324 1.2767245e-05 0.1082513\n",
      "encoder.layer_stack.1.slf_attn.w_ks.weight (256, 256) -0.1082512 0.00015498296 0.10825065\n",
      "encoder.layer_stack.1.slf_attn.w_vs.weight (256, 256) -0.10824983 -6.0694867e-05 0.10824586\n",
      "encoder.layer_stack.1.slf_attn.fc.weight (256, 256) -0.108249575 -0.00028711022 0.10824859\n",
      "encoder.layer_stack.1.slf_attn.layer_norm.weight (256,) -0.09997646 0.0005621421 0.09879374\n",
      "encoder.layer_stack.1.slf_attn.layer_norm.bias (256,) -0.09993668 0.0037897949 0.09980661\n",
      "encoder.layer_stack.1.pos_ffn.w_1.weight (1024, 256) -0.06846531 -1.16952215e-05 0.06846505\n",
      "encoder.layer_stack.1.pos_ffn.w_1.bias (1024,) -0.09985969 0.00030364614 0.09993321\n",
      "encoder.layer_stack.1.pos_ffn.w_2.weight (256, 1024) -0.068465315 0.00010035949 0.06846524\n",
      "encoder.layer_stack.1.pos_ffn.w_2.bias (256,) -0.09922011 0.0040661786 0.09995674\n",
      "encoder.layer_stack.1.pos_ffn.layer_norm.weight (256,) -0.099740386 -9.946554e-05 0.09963089\n",
      "encoder.layer_stack.1.pos_ffn.layer_norm.bias (256,) -0.09993149 0.0005347464 0.09981503\n",
      "encoder.layer_norm.weight (256,) -0.099242084 0.00057329086 0.09978274\n",
      "encoder.layer_norm.bias (256,) -0.09916629 -0.0013909907 0.09933386\n",
      "decoder.A_emb2sec (100, 256, 256) -0.008113919 2.8133481e-06 0.008113915\n",
      "decoder.att_layers.0.slf_attn.w_qs.weight (256, 256) -0.10824756 3.767803e-05 0.108247176\n",
      "decoder.att_layers.0.slf_attn.w_ks.weight (256, 256) -0.10825141 -0.00013585557 0.108252816\n",
      "decoder.att_layers.0.slf_attn.w_vs.weight (256, 256) -0.10825079 0.00021464055 0.108246796\n",
      "decoder.att_layers.0.slf_attn.fc.weight (256, 256) -0.10825039 0.00040212914 0.10824993\n",
      "decoder.att_layers.0.slf_attn.layer_norm.weight (256,) -0.09900693 -0.000117576215 0.09948992\n",
      "decoder.att_layers.0.slf_attn.layer_norm.bias (256,) -0.09976836 0.0055503584 0.09989139\n",
      "decoder.att_layers.0.pos_ffn.w_1.weight (1024, 256) -0.068464585 -6.598543e-05 0.068465225\n",
      "decoder.att_layers.0.pos_ffn.w_1.bias (1024,) -0.09998564 0.00071366294 0.09942465\n",
      "decoder.att_layers.0.pos_ffn.w_2.weight (256, 1024) -0.06846444 -7.272426e-05 0.06846517\n",
      "decoder.att_layers.0.pos_ffn.w_2.bias (256,) -0.099863544 0.0005043051 0.099233784\n",
      "decoder.att_layers.0.pos_ffn.layer_norm.weight (256,) -0.0989882 0.0020010225 0.09795045\n",
      "decoder.att_layers.0.pos_ffn.layer_norm.bias (256,) -0.09897464 -0.007859402 0.099469684\n",
      "decoder.att_layers.1.slf_attn.w_qs.weight (256, 256) -0.10824627 2.0736501e-05 0.10824776\n",
      "decoder.att_layers.1.slf_attn.w_ks.weight (256, 256) -0.1082524 0.00028374747 0.108249046\n",
      "decoder.att_layers.1.slf_attn.w_vs.weight (256, 256) -0.10824788 -0.00015198218 0.10824332\n",
      "decoder.att_layers.1.slf_attn.fc.weight (256, 256) -0.10825067 -4.6520836e-05 0.10825254\n",
      "decoder.att_layers.1.slf_attn.layer_norm.weight (256,) -0.09923285 -0.00040407223 0.099614166\n",
      "decoder.att_layers.1.slf_attn.layer_norm.bias (256,) -0.09865596 -0.0035364658 0.09945928\n",
      "decoder.att_layers.1.pos_ffn.w_1.weight (1024, 256) -0.068465 3.055805e-05 0.068464875\n",
      "decoder.att_layers.1.pos_ffn.w_1.bias (1024,) -0.09991415 3.9176608e-05 0.0995955\n",
      "decoder.att_layers.1.pos_ffn.w_2.weight (256, 1024) -0.06846494 7.454331e-05 0.06846391\n",
      "decoder.att_layers.1.pos_ffn.w_2.bias (256,) -0.09982238 0.00074320333 0.099233225\n",
      "decoder.att_layers.1.pos_ffn.layer_norm.weight (256,) -0.09932573 0.0031501567 0.09830543\n",
      "decoder.att_layers.1.pos_ffn.layer_norm.bias (256,) -0.09885917 0.00024157821 0.09927758\n"
     ]
    }
   ],
   "source": [
    "model_encdec_0_cfg = parse_yaml_file_as(MllmEncdecCfg, encdec_0_model_cfg_fpath)\n",
    "model_encdec_0 = MllmEncdecLevel(model_encdec_0_cfg, 0).to(device)\n",
    "checkpoint_encdec_0 = torch.load(encdec_0_snapshot_fpath)\n",
    "model_encdec_0.load_state_dict(checkpoint_encdec_0['model'], strict=False)\n",
    "model_encdec_0.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.layer_stack.0.slf_attn.w_qs.weight (256, 256) -0.10824737 -0.00018348327 0.10825293\n",
      "encoder.layer_stack.0.slf_attn.w_ks.weight (256, 256) -0.10825174 0.0004385211 0.10823614\n",
      "encoder.layer_stack.0.slf_attn.w_vs.weight (256, 256) -0.10824423 -0.00033476908 0.10825088\n",
      "encoder.layer_stack.0.slf_attn.fc.weight (256, 256) -0.10824534 0.00011559089 0.10825205\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.weight (256,) -0.09864409 0.0010340018 0.0991658\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.bias (256,) -0.09685143 0.0035557617 0.09987175\n",
      "encoder.layer_stack.0.pos_ffn.w_1.weight (1024, 256) -0.06846469 7.936111e-05 0.06846529\n",
      "encoder.layer_stack.0.pos_ffn.w_1.bias (1024,) -0.09958398 6.612661e-05 0.099899314\n",
      "encoder.layer_stack.0.pos_ffn.w_2.weight (256, 1024) -0.06846531 -3.3801393e-06 0.06846486\n",
      "encoder.layer_stack.0.pos_ffn.w_2.bias (256,) -0.09832839 -0.0058244728 0.09848913\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.weight (256,) -0.09979723 -0.004286126 0.09886774\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.bias (256,) -0.099568956 -0.0027976402 0.09960629\n",
      "encoder.layer_stack.1.slf_attn.w_qs.weight (256, 256) -0.108252764 -0.00018745774 0.1082508\n",
      "encoder.layer_stack.1.slf_attn.w_ks.weight (256, 256) -0.10825069 0.00062295946 0.108252\n",
      "encoder.layer_stack.1.slf_attn.w_vs.weight (256, 256) -0.108252645 -0.0005228595 0.10825194\n",
      "encoder.layer_stack.1.slf_attn.fc.weight (256, 256) -0.10825213 -0.00013582484 0.1082472\n",
      "encoder.layer_stack.1.slf_attn.layer_norm.weight (256,) -0.09633633 0.005731827 0.09942638\n",
      "encoder.layer_stack.1.slf_attn.layer_norm.bias (256,) -0.09933757 0.0021204732 0.09908935\n",
      "encoder.layer_stack.1.pos_ffn.w_1.weight (1024, 256) -0.06846495 2.0747893e-05 0.06846489\n",
      "encoder.layer_stack.1.pos_ffn.w_1.bias (1024,) -0.09994576 3.130721e-05 0.09984646\n",
      "encoder.layer_stack.1.pos_ffn.w_2.weight (256, 1024) -0.06846506 -0.00012974339 0.06846508\n",
      "encoder.layer_stack.1.pos_ffn.w_2.bias (256,) -0.09997256 0.00014582812 0.099384144\n",
      "encoder.layer_stack.1.pos_ffn.layer_norm.weight (256,) -0.09982546 0.00076386984 0.09991377\n",
      "encoder.layer_stack.1.pos_ffn.layer_norm.bias (256,) -0.09881423 0.0037175328 0.09991453\n",
      "encoder.w_em.weight (1, 100) -0.24216913 0.003599381 0.23283038\n",
      "encoder.layer_norm.weight (256,) -0.09909742 -0.0042441157 0.09818021\n",
      "encoder.layer_norm.bias (256,) -0.09913763 0.0055007627 0.09956559\n",
      "decoder.A_emb2sec (100, 256, 256) -0.008113916 3.4952138e-06 0.008113912\n",
      "decoder.att_layers.0.slf_attn.w_qs.weight (256, 256) -0.10825271 0.0002458235 0.10824039\n",
      "decoder.att_layers.0.slf_attn.w_ks.weight (256, 256) -0.10825314 0.0005272158 0.108246826\n",
      "decoder.att_layers.0.slf_attn.w_vs.weight (256, 256) -0.10824721 0.0003504747 0.10825106\n",
      "decoder.att_layers.0.slf_attn.fc.weight (256, 256) -0.10825137 -0.00020002098 0.10824912\n",
      "decoder.att_layers.0.slf_attn.layer_norm.weight (256,) -0.099922955 0.0019359104 0.09942081\n",
      "decoder.att_layers.0.slf_attn.layer_norm.bias (256,) -0.09973679 4.940247e-05 0.098955594\n",
      "decoder.att_layers.0.pos_ffn.w_1.weight (1024, 256) -0.0684653 -0.00011538292 0.06846496\n",
      "decoder.att_layers.0.pos_ffn.w_1.bias (1024,) -0.099397436 -0.0016863802 0.09996895\n",
      "decoder.att_layers.0.pos_ffn.w_2.weight (256, 1024) -0.068464465 2.5340254e-05 0.06846523\n",
      "decoder.att_layers.0.pos_ffn.w_2.bias (256,) -0.09962777 -0.0024428125 0.09993052\n",
      "decoder.att_layers.0.pos_ffn.layer_norm.weight (256,) -0.09945001 -0.00017426442 0.09959481\n",
      "decoder.att_layers.0.pos_ffn.layer_norm.bias (256,) -0.098419584 0.008045686 0.09925937\n",
      "decoder.att_layers.1.slf_attn.w_qs.weight (256, 256) -0.10825028 -8.71231e-05 0.1082473\n",
      "decoder.att_layers.1.slf_attn.w_ks.weight (256, 256) -0.10824894 3.1370317e-05 0.10825036\n",
      "decoder.att_layers.1.slf_attn.w_vs.weight (256, 256) -0.10824877 -0.00029997164 0.10824973\n",
      "decoder.att_layers.1.slf_attn.fc.weight (256, 256) -0.10824997 1.34698785e-05 0.10824894\n",
      "decoder.att_layers.1.slf_attn.layer_norm.weight (256,) -0.09930626 -0.0005550362 0.09804671\n",
      "decoder.att_layers.1.slf_attn.layer_norm.bias (256,) -0.09892099 0.000680406 0.099908665\n",
      "decoder.att_layers.1.pos_ffn.w_1.weight (1024, 256) -0.06846479 2.3884559e-05 0.06846531\n",
      "decoder.att_layers.1.pos_ffn.w_1.bias (1024,) -0.09994686 -0.00013943727 0.09970812\n",
      "decoder.att_layers.1.pos_ffn.w_2.weight (256, 1024) -0.06846513 -2.6713917e-05 0.06846526\n",
      "decoder.att_layers.1.pos_ffn.w_2.bias (256,) -0.098688 0.0024793409 0.09916532\n",
      "decoder.att_layers.1.pos_ffn.layer_norm.weight (256,) -0.09968145 -0.004045702 0.09965991\n",
      "decoder.att_layers.1.pos_ffn.layer_norm.bias (256,) -0.099516414 -0.0006797515 0.099442266\n"
     ]
    }
   ],
   "source": [
    "model_encdec_1_cfg = parse_yaml_file_as(MllmEncdecCfg, encdec_1_model_cfg_fpath)\n",
    "model_encdec_1 = MllmEncdecLevel(model_encdec_1_cfg, 1).to(device)\n",
    "checkpoint_encdec_1 = torch.load(encdec_1_snapshot_fpath)\n",
    "model_encdec_1.load_state_dict(checkpoint_encdec_1['model'], strict=False)\n",
    "model_encdec_1.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([13, 100]),\n",
       " torch.Size([1, 100]),\n",
       " tensor([ True,  True, False, False, False, False, False, False, False, False,\n",
       "         False, False, False]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 10\n",
    "batch = ds_loader.get_batch(i, train=True)\n",
    "docs_chunks, target_chunks, target_mask = batch.gen_tensors()\n",
    "docs_chunks.shape, target_chunks.shape, target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|query_begin|> KirenskyKirensky (masculine), Kirenskaya (feminine), or Kirenskoye (neuter) may refer to:\\nKirensky District, a district of Irkutsk Oblast, Russia\\nKirenskoye Urban Settlement, a municipal formation which the town of Kirensk and nine rural localities in Kirensky District of Irkutsk Oblast, Russia are incorporated as <|query_end|>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_target = tokens_to_text(target_chunks)\n",
    "s_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|doc_begin|> <|doc_id_begin|> 3435884 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Kirensky <|doc_title_end|> <|doc_body_begin|> Kirensky (masculine), Kirenskaya (feminine), or Kirenskoye (neuter) may refer to:\\nKirensky District, a district of Irkutsk Oblast, Russia\\nKirenskoye Urban Settlement, a municipal formation which the town of Kirensk and nine rural localities in Kirensky District of Irkutsk Oblast, Russia are\n",
      "<|doc_begin|> <|doc_id_begin|> 3435884 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  incorporated as <|doc_body_end|> <|doc_end|>\n",
      "<|doc_begin|> <|doc_id_begin|> 3568924 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Aleksandr Averin (cyclist) <|doc_title_end|> <|doc_body_begin|> Aleksandr Dmitriyevich Averin (; born 11 April 1954) is a retired Soviet cyclist. He competed at the 1976 Summer Olympics in the road race and finished in 17th place. He won the multistage Peace Race individually in 1978 and with the Soviet team in 1977–1979. \\n\\nHe retired from competitions in 1983 and moved to Odessa,\n",
      "<|doc_begin|> <|doc_id_begin|> 3568924 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  Ukraine, where he worked as a cycling coach. From the early 1990s to 2004 he taught physical education in a military institute. His son Maksim is a competitive cyclist who lives in Italy.\\n\\nReferences\\n\\nExternal links\\n \\n\\nCategory:1954 births\\nCategory:Living people\\nCategory:Olympic cyclists of the Soviet Union\\nCategory:Cyclists at the 1976 Summer Olympics\\nCategory:Soviet male cyclists\\nCategory\n",
      "<|doc_begin|> <|doc_id_begin|> 3568924 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|> :Sportspeople from Baku <|doc_body_end|> <|doc_end|>\n",
      "<|doc_begin|> <|doc_id_begin|> 393918 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Karibib Air Force Base <|doc_title_end|> <|doc_body_begin|> Karibib Air Force Base  is an air base near the central Namibian town of Karibib. Since 2016 the headquarters of the Namibian Air Force are located here. Air Force Command had previously been at the Grootfontein Air Force Base.\\n\\nSee also\\n\\nList of airports in Namibia\\nTransport in Namibia\\n\\nReferences\\n\\nExternal links\\n Our\n",
      "<|doc_begin|> <|doc_id_begin|> 393918 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|> Airport - Namibia\\n\\nCategory:Airports in Namibia\\nCategory:Military of Namibia <|doc_body_end|> <|doc_end|>\n",
      "<|doc_begin|> <|doc_id_begin|> 3161249 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  after his death. She was the eldest of three daughters born to Grace Lockwood and Archibald Bulloch Roosevelt, Theodore Roosevelt's third son.  Archie Roosevelt served in the Army in World War II and received the Silver Star. He later was chairman of Roosevelt & Cross, a Wall Street investment firm. Theodora's mother was Grace Lockwood, daughter of Thomas Lockwood and Emmeline Stackpole of Boston. In her later life,\n",
      "<|doc_begin|> <|doc_id_begin|> 3161249 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  Theodora played down her Roosevelt connections as she wanted her writings and her talents to be judged on their own merits.\\n\\nTheodora was brought up on the Upper East Side of New York, near the East River, and in the country at Cold Spring Harbor near Oyster Bay. She attended the Chapin School and finished her education at Countess Montgelas's in Munich, Germany. She graduated from Radcliffe College.\\n\\nCare\n",
      "<|doc_begin|> <|doc_id_begin|> 3161249 <|doc_id_end|> <|doc_offset_begin|> 273 <|doc_offset_end|> er\\nAfter finishing her education in Germany, she was briefly a debutante in New York, in 1937, and then began her professional life as a dancer in South America and Canada.  In 1945, she gave up dancing when she married Tom Keogh, a costumer, and moved to Paris. In France, Keogh designed for the theater and the ballet and worked as an illustrator for Vogue magazine from 1947 to 1951.  He designed\n",
      "<|doc_begin|> <|doc_id_begin|> 4123809 <|doc_id_end|> <|doc_offset_begin|> 1089 <|doc_offset_end|>  2nd. Joey Adrian, 3rd. Tavon Mcvey. //  MEN (FREESTYLE) 1st. Erik Mukhametshin, 2nd. Joey Adrian, 3rd. Sean Higgins.\\n\\nInstructor Certification\\nWFPF launched a Coaching Certification Program in 2012. WFPF has held parkour instructor certifications in USA, Canada, Thailand, Scotland, Wales, England, Portugal.  As\n",
      "<|doc_begin|> <|doc_id_begin|> 4123809 <|doc_id_end|> <|doc_offset_begin|> 1179 <|doc_offset_end|>  of the Spring of 2019 over 1000 parkour instructors have been attended and been certified by WFPF.  In 2016 WFPF certification was named the official Parkour certification for British Columbia Gymnastics in Canada. WFPF also offers online certifications for Parkour instructor assistants as well as Parkour Competition Judge certifications which are required to judge any WFPF competition.  Many WFPF certifications are done in partnership and with\n",
      "<|doc_begin|> <|doc_id_begin|> 4123809 <|doc_id_end|> <|doc_offset_begin|> 1269 <|doc_offset_end|>  the endorsement of IPTC- International Professional Training Certification which was established in 1978.\\n\\nReferences\\nhttp://www.nydailynews.com/sports/more_sports/2009/07/25/2009-07-25_parkour_is_taking_off.html\\nhttp://www.wfpf.com/\\nhttp://www.athletesforhope.org/parkour-harlem-childrens\n"
     ]
    }
   ],
   "source": [
    "for toks in docs_chunks:\n",
    "    s = tokens_to_text(toks)\n",
    "    print(s[:600].replace('\\n', '\\\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([13, 100, 50271]), torch.float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_chunks_pred = model_encdec_0(docs_chunks)\n",
    "# docs_chunks_pred = torch.sigmoid(docs_chunks_pred)\n",
    "docs_chunks_pred = torch.softmax(docs_chunks_pred, dim=-1)\n",
    "docs_chunks_pred.shape, docs_chunks_pred.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 100])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_toks_pred = torch.argmax(docs_chunks_pred, dim=-1)\n",
    "dc_toks_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 407 <|doc_begin|> <|doc_id_begin|> 736460 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Konky <|doc_title_end|> <|doc_body_begin|> Koyky (oratan, Kekaya (feminine), as Koyoyoye (ruguter) may refer to:\\nKhangkyky, a locality of Selkkk Oblast, Russia\\nKkkoye Rural Settlement, the local station in the border of Kokky, a rural railwayities in Karkky, in Khkodk Oblast, Russia covers\n",
      "100 135 <|doc_begin|> <|doc_id_begin|> 706432 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  served to <|doc_body_end|> <|doc_end|>\n",
      "100 471 <|doc_begin|> <|doc_id_begin|> 733834 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Aleksandr Kfst (cyclist) <|doc_title_end|> <|doc_body_begin|> Aleksandrrovrjrevev ( (born; born 25 January 1974) is a a swim cyclist. He competed at the 1992 Summer Olympics in the silver team and finished in 18th place. He won the bronzeistist Team Prix, in 1988 and with the Olympic title in 1976–08. \\n\\nHe started in Italy in 1984 and moved to El Aviv,\n",
      "100 480 <|doc_begin|> <|doc_id_begin|> 706423 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  Ukraine, where he worked as a military camp. From the early 1990s in 2009 he became a arts for a military teacher. His son Kjri is a military sports, lives in Italy.\\n\\nReferences\\n\\nExternal links\\n \\n\\nCategory:1957 births\\nCategory:Living people\\nCategory:Olympic cyclists of the Soviet Union\\nCategory:Cyclists at the 1996 Summer Olympics\\nCategory:Soviet male cyclists\\nCategory\n",
      "100 149 <|doc_begin|> <|doc_id_begin|> 734824 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|> :Sportspeople from Kaku <|doc_body_end|> <|doc_end|>\n",
      "100 480 <|doc_begin|> <|doc_id_begin|> 737523 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Saibib Air Air Base <|doc_title_end|> <|doc_body_begin|> Shibib Air Air Base  is a air airport in the Nam Aerodur of of Nunibib. In the the headquarters of of Aeribong Air Force is located in. Air Force forces who also been on the Airengweon Air Air Force Base.\\n\\nSee also\\n\\nList of airports in Namutes\\nTransport in Namibia\\n\\nReferences\\n\\nExternal links\\n List\n",
      "100 211 <|doc_begin|> <|doc_id_begin|> 733860 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|> Airlands in Namibia\\n\\nCategory:Airports in Namibia\\nCategory:International of Namibia <|doc_body_end|> <|doc_end|>\n",
      "100 467 <|doc_begin|> <|doc_id_begin|> 76444 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  after his death. She was the first of his sons was to William Elizabethman, Shibr Shinbury and Mary,'s second year. After Chief Field served by the Army during World War II and became the First War. He was later in the William & Hill, the'sman's firm. Shlin's daughter was Elizabeth Willey, daughter of William Willey and Shredus's Hospital of Boston. In his later later,\n",
      "100 472 <|doc_begin|> <|doc_id_begin|> 76423 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  Herendie moved to her husband and and and wanted her work and her efforts to be seen on her own life.\\n\\nScendel was moved up at the North East Park of New York, near the East Hills, and in the world at East War Street in Haren Hill. She attended the Balin School she began her fellow of at.ieghal School in Washington, 1960. She graduated from Marborough University.\\n\\nCare\n",
      "100 493 <|doc_begin|> <|doc_id_begin|> 76834 <|doc_id_end|> <|doc_offset_begin|> 273 <|doc_offset_end|> er\\nAfter completing a career in Germany, she was married a fashion Theatre in New York, in 1940, and then with her musical career as a theatre in South Africa and Canada.  In 1970, she married to her she she joined Richard Schel and her postred, then moved to Paris. In 1980, Marette returned to the opera and the Opera and worked as an illustised for Learts Theatre in in in 1983.  was performed\n",
      "100 311 <|doc_begin|> <|doc_id_begin|> 777 <|doc_id_end|> <|doc_offset_begin|> 1089 <|doc_offset_end|>  2nd. 2,, 2.\\n W L''. A A\\n-FF-WAC, 2.\\n W V Nsten, 2.0\\n 2, 2 2.\\n..\\n\\nDomialing\\nBCI won the Outstanding Achievement award in 2012. WITF has won Supericingationalment in Canada,, Canada,,,,,, Ontario, Ontario.  As\n",
      "100 460 <|doc_begin|> <|doc_id_begin|> 7987 <|doc_id_end|> <|doc_offset_begin|> 1120 <|doc_offset_end|>  at the World's year that 100-out program have been certified and previously hosted by WABW.  In 2016 WNCF Association was hosted the annual Curric Centre for annual annual Gymnastics in Canada.\\nNCF has include a nationaltime of Erowers as well well as Curart and's national selection which also provided to a the U&F.   The WUCF-ings are held in funding and with\n",
      "100 321 <|doc_begin|> <|doc_id_begin|> 7987 <|doc_id_end|> <|doc_offset_begin|> 29 <|doc_offset_end|> <|doc_offset_end|>  the Director of O-FA International Sports Training Association and also held in 2014.\\n\\nReferences\\nhttp://www.../.com///////////////////_id_/_?_?htmlhtml\\nhttp://www.wf..comcom\\nhttp://www.cs///////---//-s\n"
     ]
    }
   ],
   "source": [
    "for toks in dc_toks_pred:\n",
    "    s = tokens_to_text(toks)\n",
    "    s = s.replace('\\n', '\\\\n')\n",
    "    print(len(toks), len(s), s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "txts = [\n",
    "    '<|doc_begin|> 20 <|doc_id_begin|> 733860 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>Hello, my name is Mikhail<|doc_end|>',\n",
    "    'Malaga is a city in Spain',\n",
    "    'LLM stands for Large <|mask|> Model',\n",
    "    'You\\'d better learn new modeling approaches first, Mikhail from Malaga, Spain!',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "torch.Size([1, 100])\n",
      "<|doc_begin|>  20  <|doc_id_begin|>  733860  <|doc_id_end|>   <|doc_offset_begin|>  91  <|doc_offset_end|> Hello, my name is Mikhail <|doc_end|>\n",
      "Malaga is a city in Spain\n",
      "LLM stands for Large  <|mask|>  Model\n",
      "You'd better learn new modeling approaches first, Mikhail from Malaga, Spain!\n"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "for txt in txts:\n",
    "    toks = text_to_tokens(txt)\n",
    "    print(toks.shape)\n",
    "    chunks.append(toks)\n",
    "\n",
    "chunks = torch.concat(chunks)\n",
    "for toks in chunks:\n",
    "    s = tokens_to_text(toks)\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 100, 50271]) torch.float32\n",
      "torch.Size([4, 100])\n"
     ]
    }
   ],
   "source": [
    "chunks_pred = model_encdec_0(chunks)\n",
    "# chunks_pred = torch.sigmoid(chunks_pred)\n",
    "chunks_pred = torch.softmax(chunks_pred, dim=-1)\n",
    "print(chunks_pred.shape, chunks_pred.dtype)\n",
    "toks_pred = torch.argmax(chunks_pred, dim=-1)\n",
    "print(toks_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|doc_begin|> <|doc_id_begin|> 7:: <|doc_offset_begin|> 9291\\n    \\nst, a we is:\\n\n",
      "aaaa in the\n",
      "--'s\n",
      " a a of a the the the, Bosnia by from Marisi, the <|query_end|> <|query_end|>\n"
     ]
    }
   ],
   "source": [
    "for toks in toks_pred:\n",
    "    s = tokens_to_text(toks)\n",
    "    s = s.replace('\\n', '\\\\n')\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], grad_fn=<IndexBackward0>)\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "probs = chunks_pred[0][0]\n",
    "inds = torch.arange(len(probs))\n",
    "prob_thres = 0.95\n",
    "prob_thres = 0.1\n",
    "probs_mask = probs >= prob_thres\n",
    "print(probs[probs_mask])\n",
    "toks = inds[probs_mask]\n",
    "strs = []\n",
    "for tok in toks:\n",
    "    toks_ = torch.Tensor([tok])\n",
    "    s = tokens_to_text(toks_)\n",
    "    strs.append(s)\n",
    "print(strs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9900800442452646"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / 2.71**0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
