{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import Optional\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pydantic_yaml import parse_yaml_file_as\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import GPT2Tokenizer, AddedToken, PreTrainedTokenizer\n",
    "\n",
    "from mllm.config.model import MllmRankerCfg, MllmEncdecCfg, TokenizerCfg\n",
    "from mllm.data.dsqrels_embs import DsQrelsEmbs, QrelsEmbsBatch\n",
    "from mllm.data.utils import load_qrels_datasets\n",
    "from mllm.model.mllm_encdec import MllmEncdecLevel\n",
    "from mllm.model.mllm_ranker import RankProbLoss, MllmRanker, MllmRankerLevel\n",
    "from mllm.tokenization.chunk_tokenizer import gen_all_tokens, ChunkTokenizer, tokenizer_from_config\n",
    "from mllm.train.utils import find_create_train_path, calc_print_batches\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranker level 1 inference\n",
    "## Config and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranker cfg fpath: /home/misha/prog/mllm/mllm/config/cfg/ranker_model_cfg_01.yaml. Exists: True\n",
      "Ranker cfg fpath: /home/misha/prog/mllm/mllm/config/cfg/ranker_model_cfg_02.yaml. Exists: True\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(os.path.expandvars('$HOME')) / 'data'\n",
    "DS_MSMARCO_DIR_PATH = DATA_PATH / 'msmarco'\n",
    "DS_FEVER_DIR_PATH = DATA_PATH / 'fever'\n",
    "TRAIN_RANKER_PATH = DATA_PATH / 'train_mllm_ranker_qrels'\n",
    "TRAIN_RANKER_EMBS_PATH = DATA_PATH / 'train_mllm_ranker_qrels_1'\n",
    "DS_WIKI_DIR_PATH = DATA_PATH / 'wiki_20200501_en/ch_100_fixed'\n",
    "DS_EMBS_DIR_PATH = DATA_PATH / 'ranker_embs_msmarco_fever'\n",
    "CFG_DIR_PATH = Path(os.path.abspath('.')).parent / 'mllm/config/cfg'\n",
    "\n",
    "tokenizer_cfg_fpath = CFG_DIR_PATH / 'tokenizer_cfg_01.yaml'\n",
    "\n",
    "ranker0_subdir = 'ranker-20240903_215749-msmarco-fever'\n",
    "ranker0_train_path = TRAIN_RANKER_PATH / ranker0_subdir\n",
    "ranker0_snapshot_fpath = ranker0_train_path / 'best.pth'\n",
    "\n",
    "ranker1_subdir = 'ranker-l1-20241012_102220-encdec-l1-20241005_175446-msmarco-fever'\n",
    "ranker1_train_path = TRAIN_RANKER_EMBS_PATH / ranker1_subdir\n",
    "ranker1_snapshot_fpath = ranker1_train_path / 'best.pth'\n",
    "\n",
    "ranker0_model_cfg_fpath = CFG_DIR_PATH / 'ranker_model_cfg_01.yaml'\n",
    "print(f'Ranker cfg fpath: {ranker0_model_cfg_fpath}. Exists: {ranker0_model_cfg_fpath.exists()}')\n",
    "ranker1_model_cfg_fpath = CFG_DIR_PATH / 'ranker_model_cfg_02.yaml'\n",
    "print(f'Ranker cfg fpath: {ranker1_model_cfg_fpath}. Exists: {ranker1_model_cfg_fpath.exists()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "emb_chunk_size = 100\n",
    "embs_chunk_size = 100\n",
    "docs_batch_size = 10\n",
    "chunk_size = 100\n",
    "max_docs_embs = 10\n",
    "docs_per_chunk = chunk_size // max_docs_embs\n",
    "\n",
    "device = 'cpu'\n",
    "# device = 'cuda'\n",
    "\n",
    "device = torch.device(device)\n",
    "print(device)\n",
    "ranker0_model_cfg: MllmRankerCfg = parse_yaml_file_as(MllmRankerCfg, ranker0_model_cfg_fpath)\n",
    "ranker1_model_cfg: MllmRankerCfg = parse_yaml_file_as(MllmRankerCfg, ranker1_model_cfg_fpath)\n",
    "enc_cfg_1 = ranker1_model_cfg.encoders[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkz_cfg = parse_yaml_file_as(TokenizerCfg, tokenizer_cfg_fpath)\n",
    "ch_tkz = tokenizer_from_config(tkz_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Join datasets:\n",
      "   Msmarco. Queries: 372206. Docs: 3213835. QueryDocRels: 372206\n",
      "   Fever. Queries: 123142. Docs: 5416568. QueryDocRels: 156101\n"
     ]
    }
   ],
   "source": [
    "ds_qrels = load_qrels_datasets([DS_MSMARCO_DIR_PATH, DS_FEVER_DIR_PATH], ch_tkz, emb_chunk_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_embs = DsQrelsEmbs(\n",
    "    ds_dir_path=DS_EMBS_DIR_PATH, chunk_size=embs_chunk_size, emb_size=enc_cfg_1.d_model, emb_dtype=np.float32,\n",
    "    doc_id_driven=True, max_docs_embs=max_docs_embs, device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_encoder.src_word_emb.weight (50270, 256) -0.010897279 -1.8528651e-06 0.010897281\n",
      "vocab_encoder.layer_norm.weight (256,) -0.09951122 -0.0027663277 0.099862255\n",
      "vocab_encoder.layer_norm.bias (256,) -0.09966134 -0.00015156943 0.09998516\n",
      "encoders.0.layer_stack.0.slf_attn.w_qs.weight (256, 256) -0.10825235 1.8688355e-05 0.10825219\n",
      "encoders.0.layer_stack.0.slf_attn.w_ks.weight (256, 256) -0.10824529 0.00065023534 0.10824755\n",
      "encoders.0.layer_stack.0.slf_attn.w_vs.weight (256, 256) -0.10825016 0.00022870877 0.10825088\n",
      "encoders.0.layer_stack.0.slf_attn.fc.weight (256, 256) -0.10825094 0.00011086946 0.108252995\n",
      "encoders.0.layer_stack.0.slf_attn.layer_norm.weight (256,) -0.09992683 -0.0034989621 0.09979484\n",
      "encoders.0.layer_stack.0.slf_attn.layer_norm.bias (256,) -0.09871333 0.008641519 0.09965495\n",
      "encoders.0.layer_stack.0.pos_ffn.w_1.weight (1024, 256) -0.06846418 -9.048855e-05 0.068464264\n",
      "encoders.0.layer_stack.0.pos_ffn.w_1.bias (1024,) -0.09977015 0.002022188 0.09967265\n",
      "encoders.0.layer_stack.0.pos_ffn.w_2.weight (256, 1024) -0.06846512 -3.4117813e-05 0.06846495\n",
      "encoders.0.layer_stack.0.pos_ffn.w_2.bias (256,) -0.09972596 0.004091162 0.09959801\n",
      "encoders.0.layer_stack.0.pos_ffn.layer_norm.weight (256,) -0.099399365 0.0031454547 0.09975176\n",
      "encoders.0.layer_stack.0.pos_ffn.layer_norm.bias (256,) -0.09945654 -0.0017435187 0.09959447\n",
      "encoders.0.w_em.weight (1, 100) -0.23553118 -0.003670205 0.24349228\n",
      "encoders.0.layer_norm.weight (256,) -0.099828325 -0.0029596942 0.098221116\n",
      "encoders.0.layer_norm.bias (256,) -0.099280454 -0.0039320383 0.09956721\n",
      "decoders.0.w.weight (256, 256) -0.108251974 -0.00026603747 0.1082524\n",
      "decoders.0.layer_norm.weight (256,) -0.09885184 -0.006548438 0.09970911\n",
      "decoders.0.layer_norm.bias (256,) -0.09937006 -0.0047457577 0.0985684\n",
      "Loading model weights from /home/misha/data/train_mllm_ranker_qrels/ranker-20240903_215749-msmarco-fever/best.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ranker_0 = MllmRanker(ranker0_model_cfg).to(device)\n",
    "print(f'Loading model weights from {ranker0_snapshot_fpath}')\n",
    "checkpoint = torch.load(ranker0_snapshot_fpath, map_location=device)\n",
    "model_ranker_0.load_state_dict(checkpoint['model'])\n",
    "model_ranker_0.eval()\n",
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.a_em () -0.058038678 -0.058038678 -0.058038678\n",
      "encoder.layer_stack.0.slf_attn.w_qs.weight (256, 256) -0.10825312 0.00036181704 0.10825289\n",
      "encoder.layer_stack.0.slf_attn.w_ks.weight (256, 256) -0.10825222 0.0002943676 0.108250774\n",
      "encoder.layer_stack.0.slf_attn.w_vs.weight (256, 256) -0.10824366 -0.00034324033 0.1082444\n",
      "encoder.layer_stack.0.slf_attn.fc.weight (256, 256) -0.10824484 -0.00031665506 0.108250916\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.weight (256,) -0.09668002 0.004126996 0.09950475\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.bias (256,) -0.09707697 0.0043607038 0.099037364\n",
      "encoder.layer_stack.0.pos_ffn.w_1.weight (1024, 256) -0.06846472 5.0698e-05 0.06846529\n",
      "encoder.layer_stack.0.pos_ffn.w_1.bias (1024,) -0.09960637 2.2383058e-05 0.099872805\n",
      "encoder.layer_stack.0.pos_ffn.w_2.weight (256, 1024) -0.06846422 -1.6969448e-06 0.06846516\n",
      "encoder.layer_stack.0.pos_ffn.w_2.bias (256,) -0.09980021 0.004158388 0.09866786\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.weight (256,) -0.09987996 0.0025427341 0.09957677\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.bias (256,) -0.099511825 0.0047374815 0.099875264\n",
      "encoder.layer_norm.weight (256,) -0.0991138 0.002004438 0.0997595\n",
      "encoder.layer_norm.bias (256,) -0.09863474 0.002070488 0.098952465\n",
      "decoder.w.weight (256, 256) -0.10825139 0.00026889783 0.10825161\n",
      "decoder.layer_norm.weight (256,) -0.09972383 0.0036178166 0.09984976\n",
      "decoder.layer_norm.bias (256,) -0.099124216 -0.0013008693 0.09958463\n",
      "Loading model weights from /home/misha/data/train_mllm_ranker_qrels_1/ranker-l1-20241012_102220-encdec-l1-20241005_175446-msmarco-fever/best.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ranker_1 = MllmRankerLevel(ranker1_model_cfg, level=1).to(device)\n",
    "print(f'Loading model weights from {ranker1_snapshot_fpath}')\n",
    "checkpoint = torch.load(ranker1_snapshot_fpath, map_location=device)\n",
    "model_ranker_1.load_state_dict(checkpoint['model'])\n",
    "model_ranker_1.eval()\n",
    "''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using dataset queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embs_view = ds_embs.get_embs_view(batch_size=docs_batch_size * docs_per_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_batch = 0\n",
    "embs_batch_it = embs_view.get_batch_iterator(with_queries=True)\n",
    "for _ in range(i_batch):\n",
    "    embs_batch = next(embs_batch_it)\n",
    "embs_batch = next(embs_batch_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0. Docs embs: (10, 100, 256). Queries embs: (149, 256) 149\n"
     ]
    }
   ],
   "source": [
    "assert embs_batch.qs_embs is not None and embs_batch.qs_ind_len is not None\n",
    "print(f'Batch {i_batch}. Docs embs: {embs_batch.docs_embs.shape}. Queries embs: {embs_batch.qs_embs.shape} {len(embs_batch.qs_ind_len)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(769, 149, 149)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embs_batch.df_docs_ids), len(embs_batch.df_qrels), len(embs_batch.df_qs_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_rank. min, mean, max: 0.0764, 0.1000, 0.1241\n"
     ]
    }
   ],
   "source": [
    "docs_embs_t = embs_batch.get_docs_embs_tensor()\n",
    "qs_embs_t, qs_masks_t = embs_batch.get_qs_tensors()\n",
    "out_rank = model_ranker_1.run_qs_embs(docs_embs_t, qs_embs_t, embs_batch.qs_ind_len)\n",
    "print(f'out_rank. min, mean, max: {out_rank.min():0.4f}, {out_rank.mean():0.4f}, {out_rank.max():0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([149, 10])\n"
     ]
    }
   ],
   "source": [
    "print(out_rank.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 9174: +what is fascia or facia\n"
     ]
    }
   ],
   "source": [
    "query_ind = 0\n",
    "dsqid = embs_batch.qs_ind_len[query_ind][0]\n",
    "print(f'Query {query_ind} {dsqid}: {ds_qrels.df_qs.loc[dsqid].query}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1050, 0.1008, 0.1031, 0.0900, 0.1000, 0.1015, 0.1009, 0.0985, 0.1002,\n",
       "        0.1001], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_rank[query_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False,  True, False, False, False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_masks_t[query_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1234207,  508390,  198804, 1895725,  239631, 1388082, 2056134,\n",
       "         51362,  760521,   38219])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsdids = embs_batch.ids.reshape((docs_batch_size, docs_per_chunk))\n",
    "dsdids[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01. Doc 1234207: Cladosporium. \"From Wikipedia, the free encyclopedianavigation search Cladosporium Scientific classification Kingdom: Fungi Division: Ascomycota Class: Dothideomycetes Order: Capnodiales Family: Davidiellaceae Genu\n",
      "02. Doc 508390: fascia. \"fascia Also found in: Thesaurus, Medical, Legal, Encyclopedia, Wikipedia. Related to fascia: Colles fasciafas·cia (făsh′ə, fä′shə)n. pl. fas·ci·ae (făsh′ē-ē′, fä′shē-ē′)1. Anatomya. A sheet or band o\n",
      "03. Doc 198804: Learning About Bison Classroom Activities. \"Learning About Bison Classroom Activities Contents What Does A Bison Eat? Bison Food Summary Materials Background Procedure Assessment Extensions Vocabulary Cafe de Bison Math!Bison Calculations Summ\n",
      "04. Doc 1895725: Information processing. \"From Wikipedia, the free encyclopedianavigation search For other uses, see Information processor. [ hide]This article has multiple issues. Please help improve it or discuss these issues on the talk p\n",
      "05. Doc 239631: What Are Thunderstorms? - Definition, Types & Formation. Instructor: Sarah Friedl Sarah has two Master's, one in Zoology and one in GIS, a Bachelor's in Biology, and has taught college level Physical Science and Biology. Thunderstorms are common all over th\n",
      "06. Doc 1388082: Definitions &Translations. \"Princeton's Word Net (0.00 / 0 votes)Rate this definition:solvation (noun)a chemical process in which solvent molecules and molecules or ions of the solute combine to form a compound Wiktionary (0.00\n",
      "07. Doc 2056134: Hairy Bikersâ Cornish pasty Recipe. Home Recipes Hairy Bikers’ Cornish pasty Recipe ( 1561 ratings)Goodto Know | April 8, 2018 6:00 amserves:6Skill:medium Cost:cheap Total Time:01:10Prep:00:20Cooking:00:50Cornish pasty is a treat that e\n",
      "08. Doc 51362: Siding or Roofing Nailer for Hardiplank. cornbread New Member Join Date: Jun 2005Location: Southeast Tennessee Posts: 5#1Siding or Roofing Nailer for Hardiplank08-12-2005, 09:30 AMI'm about to start my first Hardiplank job, so I'm trying to \n",
      "09. Doc 760521: The Lord of the Rings  (film series). \"From Wikipedia, the free encyclopedia (Redirected from The Lord of the Rings film trilogy)navigation search This article is about the film series released in 2001 to 2003. For other films based on Th\n",
      "10. Doc 38219: How old was Theodore Roosevelt when he become president?. USCitizen 477,196 Contributions How old was Theodore Roosevelt when he become president? He was 43. Why did Theodore roosevelt want to become president?because he loved helping others. . J. P. Helm 12\n"
     ]
    }
   ],
   "source": [
    "for i, dsdid in enumerate(dsdids[6]):\n",
    "    title, text = ds_qrels.get_doc(dsdid)\n",
    "    print(f'{i + 1:02d}. Doc {dsdid}: {title[:100]}. {text[:200]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qid                           265\n",
      "query    +what is fascia or facia\n",
      "dsid                            1\n",
      "dsqid                        9174\n",
      "Name: 9174, dtype: object\n",
      "qid         265\n",
      "did       97881\n",
      "dsid          1\n",
      "dsqid      9174\n",
      "dsdid    508390\n",
      "Name: 9174, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(ds_qrels.df_qs.loc[dsqid])\n",
    "qrel = ds_qrels.df_qrels.loc[dsqid]\n",
    "print(qrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fascia. \"fascia Also found in: Thesaurus, Medical, Legal, Encyclopedia, Wikipedia. Related to fascia: Colles fasciafas·cia (făsh′ə, fä′shə)n. pl. fas·ci·ae (făsh′ē-ē′, fä′shē-ē′)1. Anatomya. A sheet or band of fibrous connective tissue enveloping, separating, or bindingtogether muscles, organs, and other soft structures of the body.b. The tissue of which such a sheet or band is composed.2. Biology A broad\n"
     ]
    }
   ],
   "source": [
    "title, text = ds_qrels.get_doc(qrel.dsdid)\n",
    "print(f'{title[:100]}. {text[:400]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrel.dsdid in embs_batch.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(ds_qrels.df_qrels.index) == set(ds_qrels.df_qs.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 895028, 3085932, 1616445, 2396834,  465048,  679478, 1282538,\n",
       "       2558828, 1918243, 1184395, 1931964,  991350, 1141254, 2247720,\n",
       "       2726870, 1461296, 2434362,  127982, 1479578, 1000903,  509488,\n",
       "       1161217, 3026873,  109872, 1446407, 1152228,  598469, 2971199,\n",
       "       2951585, 1365772, 2635634, 2588840, 2495189,   38604, 1537726,\n",
       "        699367, 2268633,  517965,  796713,  416362,  299777, 1742059,\n",
       "        544317, 2520629, 1436264, 2858298,  412377,  456861,  688057,\n",
       "        826758,  294285, 3081347,  650865, 2410836, 1107353, 3195243,\n",
       "       1505331, 1627906, 2145371,  739799, 1234207,  508390,  198804,\n",
       "       1895725,  239631, 1388082, 2056134,   51362,  760521,   38219,\n",
       "       1369469, 1901654,  632008, 2724055, 2305197, 1019421, 2345255,\n",
       "       2805343, 3182944,  655573,  308315,  580376, 1664242, 3115493,\n",
       "       2165184, 2810761,   58275,  525091,  919745, 1647851,  406509,\n",
       "       1163151, 2521349,  207467, 1206529,  803368,  597726,  874445,\n",
       "        314351, 1573595])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs_batch.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "for i, did in enumerate(embs_batch.ids):\n",
    "    if did == 508390:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>offset</th>\n",
       "      <th>dsid</th>\n",
       "      <th>dsdid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dsdid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1555982</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301595</td>\n",
       "      <td>1852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1359209</td>\n",
       "      <td>7973</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2147834</td>\n",
       "      <td>23656</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1568809</td>\n",
       "      <td>31104</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           did  offset  dsid  dsdid\n",
       "dsdid                              \n",
       "0      1555982       0     1      0\n",
       "1       301595    1852     1      1\n",
       "2      1359209    7973     1      2\n",
       "3      2147834   23656     1      3\n",
       "4      1568809   31104     1      4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_off = ds_qrels.df_off\n",
    "df_off.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>offset</th>\n",
       "      <th>dsid</th>\n",
       "      <th>dsdid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dsdid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301595</td>\n",
       "      <td>1852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1555982</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2147834</td>\n",
       "      <td>23656</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1359209</td>\n",
       "      <td>7973</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1568809</td>\n",
       "      <td>31104</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           did  offset  dsid  dsdid\n",
       "dsdid                              \n",
       "1       301595    1852     1      1\n",
       "0      1555982       0     1      0\n",
       "3      2147834   23656     1      3\n",
       "2      1359209    7973     1      2\n",
       "4      1568809   31104     1      4"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_off.loc[[1,0,3,2,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index([1, 0, 3, 2, 4], dtype='int64', name='dsdid'),\n",
       " dsdid\n",
       " 1     301595\n",
       " 0    1555982\n",
       " 3    2147834\n",
       " 2    1359209\n",
       " 4    1568809\n",
       " Name: did, dtype: int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_off.loc[[1,0,3,2,4]]\n",
    "df.index, df.did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_tok = tkz_cfg.custom_tokens['pad']\n",
    "inp_len = ranker1_model_cfg.vocab_encoder.inp_len\n",
    "\n",
    "def tokten_to_text(tokens: torch.Tensor) -> str:\n",
    "    tokens = tokens.flatten()\n",
    "    tokens = tokens[tokens != pad_tok]\n",
    "    tokens = list(tokens)\n",
    "    s = ch_tkz.decode(tokens)\n",
    "    return s\n",
    "\n",
    "def distance(x: np.ndarray, y: np.ndarray, cosine: bool = False):\n",
    "    if not cosine:\n",
    "        return np.linalg.norm(x - y)\n",
    "    x_norm, y_norm = np.linalg.norm(x), np.linalg.norm(y)\n",
    "    return np.sum(x * y) / (x_norm * y_norm)\n",
    "\n",
    "def text_to_tokens(s: str, qbeg_tok: Optional[int] = None, qend_tok: Optional[int] = None) -> torch.Tensor:\n",
    "    tokens = ch_tkz(s)['input_ids']\n",
    "    if qbeg_tok is not None:\n",
    "        assert qend_tok is not None\n",
    "        tokens = [qbeg_tok, *tokens, qend_tok]\n",
    "    n_tokens = len(tokens)\n",
    "    n_padded = n_tokens // inp_len + (n_tokens % inp_len > 0)\n",
    "    res = np.full((n_padded * inp_len, ), pad_tok, dtype=np.int32)\n",
    "    res[:n_tokens] = tokens\n",
    "    res = torch.from_numpy(res).to(device)\n",
    "    res = res.reshape(n_padded, inp_len)\n",
    "    return res\n",
    "\n",
    "def print_dist(target_embs: torch.Tensor, docs_embs: torch.Tensor, target_mask: torch.Tensor, cosine: bool = True):\n",
    "    for i, docs_emb in enumerate(docs_embs.detach().numpy()):\n",
    "        for target_emb in target_embs.detach().numpy():\n",
    "            dist = distance(target_emb, docs_emb, cosine)\n",
    "            print(f'{dist:0.6f} ', end='')\n",
    "        sfx = 'T' if target_mask[i] else 'F'\n",
    "        print(sfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
