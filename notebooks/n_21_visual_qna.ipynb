{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import pipeline, Pix2StructProcessor, Pix2StructForConditionalGeneration, \\\n",
    "    ViltProcessor, ViltForQuestionAnswering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image-Text VQA models\n",
    "## BLIP-VQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'BlipForQuestionAnswering' is not supported for visual-question-answering. Supported models are ['Blip2ForConditionalGeneration', 'ViltForQuestionAnswering'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'answer': 'yes'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vqa_pipeline = pipeline(\n",
    "    \"visual-question-answering\", model=\"Salesforce/blip-vqa-capfilt-large\"\n",
    ")\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/vis-nlp/ChartQA/main/ChartQA%20Dataset/val/png/5090.png\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "question = \"What's in the image?\"\n",
    "question = 'Is Portugal is mentioned in the chart?'\n",
    "\n",
    "vqa_pipeline(image, question, top_k=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4b5c3ea42c4c9a955d4789cfcc01e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/249 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bcf666a294a444997952c1eb7a7c255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e88f9e09f714c80a8a0fe99aa059bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/851k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f77bbf443e437fae3a54b13c584821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.27M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4bb645bbc94cdbbbd659328fd0aa77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41bf9c0a19dd4d1b9c4a521f4017933f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.88k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24fd3ea3663c4a4194fb582f674139e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.13G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff51f702ca5741ab863ab4aa262a0be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Arial.TTF:   0%|          | 0.00/276k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity | Individuals responsibility | Government's responsibility <0x0A> MEDIAN | 39.0 | 55.0 <0x0A> Germany | nan | 35.0 <0x0A> UK | 45.0 | 49.0 <0x0A> Sweden | 37.0 | 53.0 <0x0A> Denmark | 42.0 | 54.0 <0x0A> France | 38.0 | 55.0 <0x0A> Netherla nns | 40.0 | 58.0 <0x0A> Spain | 29.0 | 63.0 <0x0A> Italy | 22.0 | 74.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "processor = Pix2StructProcessor.from_pretrained(\"google/deplot\")\n",
    "model = Pix2StructForConditionalGeneration.from_pretrained(\"google/deplot\")\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/vis-nlp/ChartQA/main/ChartQA%20Dataset/val/png/5090.png\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "inputs = processor(\n",
    "    images=image,\n",
    "    text=\"Generate underlying data table of the figure below:\",\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "predictions = model.generate(**inputs, max_new_tokens=512)\n",
    "print(processor.decode(predictions[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer: remote\n"
     ]
    }
   ],
   "source": [
    "# prepare image + question\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "text = \"How many cats are there?\"\n",
    "text = \"What animals are on the picture?\"\n",
    "text = 'What animals and what devices do you see?'\n",
    "\n",
    "processor = ViltProcessor.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")\n",
    "model = ViltForQuestionAnswering.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")\n",
    "\n",
    "# prepare inputs\n",
    "encoding = processor(image, text, return_tensors=\"pt\")\n",
    "\n",
    "# forward pass\n",
    "outputs = model(**encoding)\n",
    "logits = outputs.logits\n",
    "idx = logits.argmax(-1).item()\n",
    "print(\"Predicted answer:\", model.config.id2label[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer: remote\n",
      "Predicted answer: cats\n",
      "Predicted answer: remote\n"
     ]
    }
   ],
   "source": [
    "text = 'What animals and what devices do you see?'\n",
    "encoding = processor(image, text, return_tensors=\"pt\")\n",
    "outputs = model(**encoding)\n",
    "logits = outputs.logits\n",
    "idx = logits.argmax(-1).item()\n",
    "word = model.config.id2label[idx]\n",
    "print(\"Predicted answer:\", word)\n",
    "\n",
    "text += f' {word}'\n",
    "encoding = processor(image, text, return_tensors=\"pt\")\n",
    "outputs = model(**encoding)\n",
    "logits = outputs.logits\n",
    "idx = logits.argmax(-1).item()\n",
    "word = model.config.id2label[idx]\n",
    "print(\"Predicted answer:\", word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LayoutLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    \"document-question-answering\", model=\"naver-clova-ix/donut-base-finetuned-docvqa\"\n",
    ")\n",
    "\n",
    "question = \"What is the purchase amount?\"\n",
    "img_url = 'https://visaguide.world/wp-content/uploads/2019/08/screenshot-ceac.state_.gov-security-question-1.png'\n",
    "image = Image.open(requests.get(img_url, stream=True).raw)\n",
    "# image.show()\n",
    "\n",
    "pipe(image=image, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
