{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import Optional\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pydantic_yaml import parse_yaml_file_as\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import GPT2Tokenizer, AddedToken, PreTrainedTokenizer\n",
    "\n",
    "from mllm.data.wiki.dswiki import WikiDsLoader\n",
    "from mllm.exp.args import TOKENIZER_CFG_FNAME, ENCDEC_MODEL_CFG_FNAME, RANKER_MODEL_CFG_FNAME\n",
    "from mllm.model.mllm_encdec import MllmEncdecLevel\n",
    "from mllm.model.mllm_ranker import MllmRankerLevel\n",
    "from mllm.config.model import TokenizerCfg, MllmEncdecCfg, MllmRankerCfg\n",
    "from mllm.tokenization.chunk_tokenizer import calc_max_inp_size, gen_all_tokens, ChunkTokenizer, tokenizer_from_config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(os.path.expandvars('$HOME')) / 'data'\n",
    "DS_DIR_PATH = DATA_PATH / 'wiki_20200501_en' / 'ch_100_fixed'\n",
    "\n",
    "# TRAIN_ENCDEC_PATH = DATA_PATH / 'train_mllm_encdec'\n",
    "# TRAIN_RANKER_PATH = DATA_PATH / 'train_mllm_ranker_qrels'\n",
    "# encdec_subdir = 'encdec-20240718_221554-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240903_215749-msmarco-fever'\n",
    "\n",
    "TRAIN_ENCDEC_PATH = DATA_PATH / 'train_mllm_encdec_0'\n",
    "TRAIN_RANKER_PATH = DATA_PATH / 'train_mllm_ranker_qrels_0'\n",
    "encdec_subdir = 'encdec-lvl0-20241029_140645-wiki_20200501_en-ch_100_fixed-enc-lrs3-embmatFalse-d256-h8-dec-lrs3-seqlen100-d256-h8-vocdecTrue'\n",
    "ranker_subdir = 'ranker-lvl0-20241030_230226-msmarco-fever-enc-lrs3-embmatFalse-d256-h8-dec-lrs0-d256-h8'\n",
    "ranker_subdir = 'ranker-lvl0-20241031_215643-msmarco-fever-enc-lrs3-embmatFalse-d256-h8-dec-lrs3-d256-h8'\n",
    "\n",
    "encdec_train_path = TRAIN_ENCDEC_PATH / encdec_subdir\n",
    "ranker_train_path = TRAIN_RANKER_PATH / ranker_subdir\n",
    "encdec_snapshot_fpath = encdec_train_path / 'best.pth'\n",
    "ranker_snapshot_fpath = ranker_train_path / 'best.pth'\n",
    "encdec_tkz_cfg_fpath = encdec_train_path / TOKENIZER_CFG_FNAME\n",
    "ranker_tkz_cfg_fpath = ranker_train_path / TOKENIZER_CFG_FNAME\n",
    "encdec_model_cfg_fpath = encdec_train_path / ENCDEC_MODEL_CFG_FNAME\n",
    "ranker_model_cfg_fpath = ranker_train_path / RANKER_MODEL_CFG_FNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "docs_batch_size = 5\n",
    "max_chunks_per_doc = 3\n",
    "model_level = 0\n",
    "device_name = 'cpu'\n",
    "# device_name = 'cuda'\n",
    "\n",
    "device = torch.device(device_name)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encdec_tkz_cfg = parse_yaml_file_as(TokenizerCfg, encdec_tkz_cfg_fpath)\n",
    "ranker_tkz_cfg = parse_yaml_file_as(TokenizerCfg, ranker_tkz_cfg_fpath)\n",
    "assert encdec_tkz_cfg == ranker_tkz_cfg\n",
    "tokenizer = tokenizer_from_config(encdec_tkz_cfg)\n",
    "tok_dict = encdec_tkz_cfg.custom_tokens\n",
    "pad_tok, qbeg_tok, qend_tok = tok_dict['pad'].ind, tok_dict['query_begin'].ind, tok_dict['query_end'].ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cache from /home/misha/data/wiki_20200501_en/ch_100_fixed/.mllm/ds.csv\n",
      "Loaded dataset size: 50989207\n"
     ]
    }
   ],
   "source": [
    "ds_loader = WikiDsLoader(\n",
    "    ds_path=DS_DIR_PATH, docs_batch_size=docs_batch_size, max_chunks_per_doc=max_chunks_per_doc,\n",
    "    pad_tok=pad_tok, qbeg_tok=qbeg_tok, qend_tok=qend_tok, device=device,\n",
    ")\n",
    "ds_loader.shuffle(train=True)\n",
    "ds_loader.shuffle(train=False)\n",
    "inp_len = ds_loader.emb_chunk_size if ds_loader.fixed_size else calc_max_inp_size(ds_loader.emb_chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_text(tokens: torch.Tensor) -> str:\n",
    "    tokens = tokens.flatten()\n",
    "    tokens = tokens[tokens != pad_tok]\n",
    "    tokens = list(tokens)\n",
    "    s = tokenizer.decode(tokens)\n",
    "    return s\n",
    "\n",
    "def distance(x: np.ndarray, y: np.ndarray, cosine: bool = False):\n",
    "    if not cosine:\n",
    "        return np.linalg.norm(x - y)\n",
    "    x_norm, y_norm = np.linalg.norm(x), np.linalg.norm(y)\n",
    "    return np.sum(x * y) / (x_norm * y_norm)\n",
    "\n",
    "def text_to_tokens(s: str, qbeg_tok: Optional[int] = None, qend_tok: Optional[int] = None) -> torch.Tensor:\n",
    "    tokens = tokenizer(s)['input_ids']\n",
    "    if qbeg_tok is not None:\n",
    "        assert qend_tok is not None\n",
    "        tokens = [qbeg_tok, *tokens, qend_tok]\n",
    "    n_tokens = len(tokens)\n",
    "    n_padded = n_tokens // inp_len + (n_tokens % inp_len > 0)\n",
    "    res = np.full((n_padded * inp_len, ), pad_tok, dtype=np.int32)\n",
    "    res[:n_tokens] = tokens\n",
    "    res = torch.from_numpy(res).to(device)\n",
    "    res = res.reshape(n_padded, inp_len)\n",
    "    return res\n",
    "\n",
    "def print_dist(target_embs: torch.Tensor, docs_embs: torch.Tensor, target_mask: torch.Tensor, cosine: bool = True):\n",
    "    for i, docs_emb in enumerate(docs_embs.detach().numpy()):\n",
    "        for target_emb in target_embs.detach().numpy():\n",
    "            dist = distance(target_emb, docs_emb, cosine)\n",
    "            print(f'{dist:0.6f} ', end='')\n",
    "        sfx = 'T' if target_mask[i] else 'F'\n",
    "        print(sfx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_encoder.src_word_emb.weight (50271, 256) -0.010897174 2.1067253e-06 0.010897173\n",
      "vocab_encoder.layer_norm.weight (256,) -0.09786662 -0.0013290788 0.099208556\n",
      "vocab_encoder.layer_norm.bias (256,) -0.0994437 -0.011387913 0.09963775\n",
      "vocab_decoder.word_prj.weight (50271, 256) -0.010897174 -1.922783e-07 0.010897171\n",
      "encoder.a_em () 0.0899288 0.0899288 0.0899288\n",
      "encoder.layer_stack.0.slf_attn.w_qs.weight (256, 256) -0.108246244 5.1258652e-05 0.10824751\n",
      "encoder.layer_stack.0.slf_attn.w_ks.weight (256, 256) -0.10824494 0.00030634573 0.10825305\n",
      "encoder.layer_stack.0.slf_attn.w_vs.weight (256, 256) -0.10824328 6.980845e-05 0.1082527\n",
      "encoder.layer_stack.0.slf_attn.fc.weight (256, 256) -0.10825218 1.6250924e-05 0.10824487\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.weight (256,) -0.099198155 0.0035320162 0.09855495\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.bias (256,) -0.09984912 0.0031056185 0.09970801\n",
      "encoder.layer_stack.0.pos_ffn.w_1.weight (1024, 256) -0.06846509 9.866831e-05 0.068465255\n",
      "encoder.layer_stack.0.pos_ffn.w_1.bias (1024,) -0.099941395 -0.0011425434 0.099850655\n",
      "encoder.layer_stack.0.pos_ffn.w_2.weight (256, 1024) -0.06846512 -7.3475894e-05 0.068463236\n",
      "encoder.layer_stack.0.pos_ffn.w_2.bias (256,) -0.09953133 0.006407426 0.09936851\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.weight (256,) -0.099616684 0.0028193314 0.09906679\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.bias (256,) -0.099847615 -0.0024282166 0.0995024\n",
      "encoder.layer_stack.1.slf_attn.w_qs.weight (256, 256) -0.108249485 0.00022086255 0.10825228\n",
      "encoder.layer_stack.1.slf_attn.w_ks.weight (256, 256) -0.108249575 -0.0002987456 0.10825159\n",
      "encoder.layer_stack.1.slf_attn.w_vs.weight (256, 256) -0.10825261 0.00021605383 0.108246654\n",
      "encoder.layer_stack.1.slf_attn.fc.weight (256, 256) -0.108250745 -0.00012574608 0.10824935\n",
      "encoder.layer_stack.1.slf_attn.layer_norm.weight (256,) -0.09944733 -0.0044695595 0.09958197\n",
      "encoder.layer_stack.1.slf_attn.layer_norm.bias (256,) -0.096007064 -0.0018311357 0.09920712\n",
      "encoder.layer_stack.1.pos_ffn.w_1.weight (1024, 256) -0.06846529 -7.618068e-05 0.0684646\n",
      "encoder.layer_stack.1.pos_ffn.w_1.bias (1024,) -0.099759236 -0.00046607357 0.09973396\n",
      "encoder.layer_stack.1.pos_ffn.w_2.weight (256, 1024) -0.06846502 0.00013780467 0.06846508\n",
      "encoder.layer_stack.1.pos_ffn.w_2.bias (256,) -0.09940125 0.004731203 0.09954854\n",
      "encoder.layer_stack.1.pos_ffn.layer_norm.weight (256,) -0.09692245 0.0010321897 0.09987873\n",
      "encoder.layer_stack.1.pos_ffn.layer_norm.bias (256,) -0.09950757 0.0019695521 0.09840188\n",
      "encoder.layer_stack.2.slf_attn.w_qs.weight (256, 256) -0.10824365 0.00035228126 0.10825009\n",
      "encoder.layer_stack.2.slf_attn.w_ks.weight (256, 256) -0.108247004 -0.00045741064 0.108251326\n",
      "encoder.layer_stack.2.slf_attn.w_vs.weight (256, 256) -0.10824969 0.00018089659 0.10825305\n",
      "encoder.layer_stack.2.slf_attn.fc.weight (256, 256) -0.10825266 0.00031095304 0.10825088\n",
      "encoder.layer_stack.2.slf_attn.layer_norm.weight (256,) -0.09962622 0.006431762 0.09998311\n",
      "encoder.layer_stack.2.slf_attn.layer_norm.bias (256,) -0.099543765 0.0016450488 0.098404944\n",
      "encoder.layer_stack.2.pos_ffn.w_1.weight (1024, 256) -0.06846529 -6.964204e-05 0.06846469\n",
      "encoder.layer_stack.2.pos_ffn.w_1.bias (1024,) -0.09990936 -0.0022221608 0.09985173\n",
      "encoder.layer_stack.2.pos_ffn.w_2.weight (256, 1024) -0.06846495 0.00013909841 0.0684652\n",
      "encoder.layer_stack.2.pos_ffn.w_2.bias (256,) -0.09862759 0.0012923465 0.0993315\n",
      "encoder.layer_stack.2.pos_ffn.layer_norm.weight (256,) -0.09996887 -0.005417512 0.09998812\n",
      "encoder.layer_stack.2.pos_ffn.layer_norm.bias (256,) -0.099954486 0.006840644 0.09967275\n",
      "encoder.layer_norm.weight (256,) -0.09940576 -0.009770457 0.098039046\n",
      "encoder.layer_norm.bias (256,) -0.0999036 0.00020479143 0.0998868\n",
      "decoder.A_emb2sec (100, 256, 256) -0.008113917 1.4684788e-06 0.008113918\n",
      "decoder.att_layers.0.slf_attn.w_qs.weight (256, 256) -0.10825009 -0.00043072138 0.108252995\n",
      "decoder.att_layers.0.slf_attn.w_ks.weight (256, 256) -0.108252525 4.4335844e-05 0.108251356\n",
      "decoder.att_layers.0.slf_attn.w_vs.weight (256, 256) -0.10825118 0.00019698036 0.10824863\n",
      "decoder.att_layers.0.slf_attn.fc.weight (256, 256) -0.108248115 6.844695e-05 0.10824697\n",
      "decoder.att_layers.0.slf_attn.layer_norm.weight (256,) -0.09983569 0.0028285296 0.09992956\n",
      "decoder.att_layers.0.slf_attn.layer_norm.bias (256,) -0.09969435 0.0030003253 0.09989232\n",
      "decoder.att_layers.0.pos_ffn.w_1.weight (1024, 256) -0.06846531 -7.2834064e-06 0.06846394\n",
      "decoder.att_layers.0.pos_ffn.w_1.bias (1024,) -0.09935663 0.00017877709 0.09956975\n",
      "decoder.att_layers.0.pos_ffn.w_2.weight (256, 1024) -0.06846498 -2.6234298e-05 0.06846488\n",
      "decoder.att_layers.0.pos_ffn.w_2.bias (256,) -0.099463664 0.0010376264 0.09995102\n",
      "decoder.att_layers.0.pos_ffn.layer_norm.weight (256,) -0.09996747 -0.0053690774 0.09834763\n",
      "decoder.att_layers.0.pos_ffn.layer_norm.bias (256,) -0.09928168 -0.004497298 0.09869577\n",
      "decoder.att_layers.1.slf_attn.w_qs.weight (256, 256) -0.10824975 3.308303e-05 0.10825245\n",
      "decoder.att_layers.1.slf_attn.w_ks.weight (256, 256) -0.10825266 0.00036265468 0.10825261\n",
      "decoder.att_layers.1.slf_attn.w_vs.weight (256, 256) -0.10825062 -0.0004139319 0.10825093\n",
      "decoder.att_layers.1.slf_attn.fc.weight (256, 256) -0.10825095 0.00017914514 0.108251624\n",
      "decoder.att_layers.1.slf_attn.layer_norm.weight (256,) -0.09971316 -0.0053624464 0.09959661\n",
      "decoder.att_layers.1.slf_attn.layer_norm.bias (256,) -0.09690942 0.0040450627 0.09934857\n",
      "decoder.att_layers.1.pos_ffn.w_1.weight (1024, 256) -0.06846515 -3.2186384e-05 0.06846523\n",
      "decoder.att_layers.1.pos_ffn.w_1.bias (1024,) -0.09992585 0.0003275312 0.099327885\n",
      "decoder.att_layers.1.pos_ffn.w_2.weight (256, 1024) -0.06846522 -0.00012557462 0.06846493\n",
      "decoder.att_layers.1.pos_ffn.w_2.bias (256,) -0.0996507 0.0004511656 0.09923887\n",
      "decoder.att_layers.1.pos_ffn.layer_norm.weight (256,) -0.096361 -0.00088779884 0.099890195\n",
      "decoder.att_layers.1.pos_ffn.layer_norm.bias (256,) -0.09962469 -0.0020912453 0.09944644\n",
      "decoder.att_layers.2.slf_attn.w_qs.weight (256, 256) -0.108252 -0.000114533286 0.10824534\n",
      "decoder.att_layers.2.slf_attn.w_ks.weight (256, 256) -0.10825262 0.00013504371 0.10824822\n",
      "decoder.att_layers.2.slf_attn.w_vs.weight (256, 256) -0.10825305 0.0001148449 0.108242474\n",
      "decoder.att_layers.2.slf_attn.fc.weight (256, 256) -0.1082519 0.00018484064 0.108252786\n",
      "decoder.att_layers.2.slf_attn.layer_norm.weight (256,) -0.09949746 -0.0053321845 0.0994302\n",
      "decoder.att_layers.2.slf_attn.layer_norm.bias (256,) -0.09920917 -0.0010299499 0.09979924\n",
      "decoder.att_layers.2.pos_ffn.w_1.weight (1024, 256) -0.0684649 -9.523401e-06 0.06846502\n",
      "decoder.att_layers.2.pos_ffn.w_1.bias (1024,) -0.09995221 -0.0020052432 0.09984088\n",
      "decoder.att_layers.2.pos_ffn.w_2.weight (256, 1024) -0.06846364 -5.1195406e-05 0.068465225\n",
      "decoder.att_layers.2.pos_ffn.w_2.bias (256,) -0.09967772 -0.00020782533 0.097832695\n",
      "decoder.att_layers.2.pos_ffn.layer_norm.weight (256,) -0.09911459 -0.0012547718 0.09979712\n",
      "decoder.att_layers.2.pos_ffn.layer_norm.bias (256,) -0.097983696 -0.0034820489 0.09967035\n"
     ]
    }
   ],
   "source": [
    "model_encdec_cfg = parse_yaml_file_as(MllmEncdecCfg, encdec_model_cfg_fpath)\n",
    "model_encdec = MllmEncdecLevel(model_encdec_cfg, model_level).to(device)\n",
    "checkpoint_encdec = torch.load(encdec_snapshot_fpath)\n",
    "model_encdec.load_state_dict(checkpoint_encdec['model'], strict=False)\n",
    "model_encdec.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496,   612, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267]],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_tokens('Hello there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 100]),\n",
       " torch.Size([2, 100]),\n",
       " tensor([False, False, False, False, False,  True,  True, False, False, False,\n",
       "         False, False]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 10\n",
    "batch = ds_loader.get_batch(i, train=True)\n",
    "docs_chunks, target_chunks, target_mask = batch.gen_tensors()\n",
    "docs_chunks.shape, target_chunks.shape, target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|query_begin|> Virginie ClaesVirginie Claes (born 17 December 1982 in Herk-de-Stad, Limburg) is television and radio presenter and a former beauty pageant title-holder.\\n\\nBiography \\nClaes was Miss Limburg 2006 and later that year she was crowned Miss Belgium.\\n\\nShe later became a television and radio presenter, including for French-language channels RTL-TVI and Bel RTL.\\n\\nReferences\\n\\nExternal links \\nMiss Limburg - Virginie Claes\\n\\nCategory:Living people\\nCategory:People from Limburg (Belgium)\\nCategory:Belgian female models\\nCategory:1982 births\\nCategory:Miss World 2006 delegates\\nCategory:Belgian beauty pageant winners\\nCategory:Miss Belgium winners\\nCategory:Flemish models <|query_end|>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_target = tokens_to_text(target_chunks)\n",
    "s_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|doc_begin|> <|doc_id_begin|> 2177006 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> 2012 European Karate Championships <|doc_title_end|> <|doc_body_begin|> The 2012 Eur\n",
      "<|doc_begin|> <|doc_id_begin|> 2177006 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  competitions hosted by Spain\\nEuropean Karate Championships\\nEuropean championships in 2012\\nCategory:Spo\n",
      "<|doc_begin|> <|doc_id_begin|> 5514810 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Chetogaster <|doc_title_end|> <|doc_body_begin|> Chetogaster is a genus of bristle f\n",
      "<|doc_begin|> <|doc_id_begin|> 5514810 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|> berrae Paramonov, 1954 c g\\n Chetogaster oblonga (Macquart, 1847) c g\\n Chetogaster pellucida Paramonov, \n",
      "<|doc_begin|> <|doc_id_begin|> 5514810 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  b = Bugguide.net\\n\\nReferences\\n\\nFurther reading\\n\\nExternal links \\n\\n \\n \\n\\nCategory:Tachinidae <|doc_body_e\n",
      "<|doc_begin|> <|doc_id_begin|> 5226702 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Virginie Claes <|doc_title_end|> <|doc_body_begin|> Virginie Claes (born 17 December\n",
      "<|doc_begin|> <|doc_id_begin|> 5226702 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>.\\n\\nReferences\\n\\nExternal links \\nMiss Limburg - Virginie Claes\\n\\nCategory:Living people\\nCategory:People fro\n",
      "<|doc_begin|> <|doc_id_begin|> 5099379 <|doc_id_end|> <|doc_offset_begin|> 273 <|doc_offset_end|>, it was redefined to consist of the part of the City of Kitchener bounded on the west by the western l\n",
      "<|doc_begin|> <|doc_id_begin|> 5099379 <|doc_id_end|> <|doc_offset_begin|> 364 <|doc_offset_end|> way No. 8), King Street East and the Conestoga Parkway.\\n\\nThis riding lost territory to Kitchener—Cones\n",
      "<|doc_begin|> <|doc_id_begin|> 5099379 <|doc_id_end|> <|doc_offset_begin|> 455 <|doc_offset_end|>  compared to the total of the Canadian Alliance vote and Progressive Conservative vote in 2000 electio\n",
      "<|doc_begin|> <|doc_id_begin|> 303980 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> 1995 Fed Cup Europe/Africa Zone Group II – Pool D <|doc_title_end|> <|doc_body_begin|\n",
      "<|doc_begin|> <|doc_id_begin|> 303980 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>. Kenya\\n\\nYugoslavia vs. Malta\\n\\nYugoslavia vs. Cyprus\\n\\nMalta vs. Kenya\\n\\nIreland vs. Yugoslavia\\n\\nMalta vs. \n"
     ]
    }
   ],
   "source": [
    "for toks in docs_chunks:\n",
    "    s = tokens_to_text(toks)\n",
    "    print(s[:200].replace('\\n', '\\\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embs = model_encdec.run_enc_emb(target_chunks)\n",
    "docs_embs = model_encdec.run_enc_emb(docs_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.184208 0.079882 F\n",
      "0.094283 0.323757 F\n",
      "0.165659 0.239028 F\n",
      "0.217627 0.339339 F\n",
      "0.165336 0.404311 F\n",
      "0.102995 0.225116 T\n",
      "0.140231 0.469443 T\n",
      "0.079364 -0.090584 F\n",
      "0.263610 0.251187 F\n",
      "0.203657 0.113284 F\n",
      "0.118158 0.168529 F\n",
      "0.220931 0.330329 F\n"
     ]
    }
   ],
   "source": [
    "cosine = False\n",
    "cosine = True\n",
    "print_dist(target_embs, docs_embs, target_mask, cosine=cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_encoder.src_word_emb.weight (50271, 256) -0.010897168 -1.2185656e-06 0.01089717\n",
      "vocab_encoder.layer_norm.weight (256,) -0.099739194 0.00296096 0.0996237\n",
      "vocab_encoder.layer_norm.bias (256,) -0.099467896 0.001347108 0.09899004\n",
      "encoder.a_em () -0.038321506 -0.038321506 -0.038321506\n",
      "encoder.layer_stack.0.slf_attn.w_qs.weight (256, 256) -0.108252116 0.00020532531 0.10824986\n",
      "encoder.layer_stack.0.slf_attn.w_ks.weight (256, 256) -0.10824924 -1.2689488e-05 0.108252436\n",
      "encoder.layer_stack.0.slf_attn.w_vs.weight (256, 256) -0.10825268 -0.00025201027 0.10825282\n",
      "encoder.layer_stack.0.slf_attn.fc.weight (256, 256) -0.10825143 8.3124265e-05 0.10824674\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.weight (256,) -0.09940179 -0.0054651625 0.09948772\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.bias (256,) -0.09809735 0.0043678153 0.09915371\n",
      "encoder.layer_stack.0.pos_ffn.w_1.weight (1024, 256) -0.06846482 -1.8771465e-05 0.068464346\n",
      "encoder.layer_stack.0.pos_ffn.w_1.bias (1024,) -0.099980436 0.0006258688 0.099289395\n",
      "encoder.layer_stack.0.pos_ffn.w_2.weight (256, 1024) -0.06846516 -1.3137159e-05 0.06846372\n",
      "encoder.layer_stack.0.pos_ffn.w_2.bias (256,) -0.099599816 -0.003416 0.09983232\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.weight (256,) -0.099578775 0.0043579354 0.09951736\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.bias (256,) -0.09762231 0.0064592105 0.09926625\n",
      "encoder.layer_stack.1.slf_attn.w_qs.weight (256, 256) -0.10825263 5.6760095e-05 0.10823736\n",
      "encoder.layer_stack.1.slf_attn.w_ks.weight (256, 256) -0.10824577 0.00021073568 0.10825231\n",
      "encoder.layer_stack.1.slf_attn.w_vs.weight (256, 256) -0.10824961 -0.00019591756 0.10824886\n",
      "encoder.layer_stack.1.slf_attn.fc.weight (256, 256) -0.108251445 -0.00058992533 0.108251534\n",
      "encoder.layer_stack.1.slf_attn.layer_norm.weight (256,) -0.09965172 -0.0032156445 0.099994116\n",
      "encoder.layer_stack.1.slf_attn.layer_norm.bias (256,) -0.099558845 -0.0012142138 0.098694794\n",
      "encoder.layer_stack.1.pos_ffn.w_1.weight (1024, 256) -0.06846501 2.1364795e-05 0.06846509\n",
      "encoder.layer_stack.1.pos_ffn.w_1.bias (1024,) -0.09965458 -0.0023151764 0.09986307\n",
      "encoder.layer_stack.1.pos_ffn.w_2.weight (256, 1024) -0.06846424 -0.00010160757 0.068465166\n",
      "encoder.layer_stack.1.pos_ffn.w_2.bias (256,) -0.099902205 -0.0041689486 0.099799834\n",
      "encoder.layer_stack.1.pos_ffn.layer_norm.weight (256,) -0.09712763 0.0010257927 0.09989265\n",
      "encoder.layer_stack.1.pos_ffn.layer_norm.bias (256,) -0.09994023 -0.002786756 0.09990821\n",
      "encoder.layer_stack.2.slf_attn.w_qs.weight (256, 256) -0.108249575 2.559177e-05 0.108250335\n",
      "encoder.layer_stack.2.slf_attn.w_ks.weight (256, 256) -0.10824898 -8.554154e-05 0.108250745\n",
      "encoder.layer_stack.2.slf_attn.w_vs.weight (256, 256) -0.10824413 -0.00036329962 0.1082493\n",
      "encoder.layer_stack.2.slf_attn.fc.weight (256, 256) -0.108250424 -0.00011351118 0.108245894\n",
      "encoder.layer_stack.2.slf_attn.layer_norm.weight (256,) -0.09893548 -0.003039984 0.09936096\n",
      "encoder.layer_stack.2.slf_attn.layer_norm.bias (256,) -0.09972002 0.006084754 0.09970172\n",
      "encoder.layer_stack.2.pos_ffn.w_1.weight (1024, 256) -0.06846498 7.687163e-05 0.06846526\n",
      "encoder.layer_stack.2.pos_ffn.w_1.bias (1024,) -0.099981844 0.0012495038 0.09995999\n",
      "encoder.layer_stack.2.pos_ffn.w_2.weight (256, 1024) -0.06846499 -2.093772e-05 0.068464674\n",
      "encoder.layer_stack.2.pos_ffn.w_2.bias (256,) -0.09843427 0.0038899647 0.09770427\n",
      "encoder.layer_stack.2.pos_ffn.layer_norm.weight (256,) -0.09919419 0.00046561647 0.099724196\n",
      "encoder.layer_stack.2.pos_ffn.layer_norm.bias (256,) -0.09887888 -0.003947388 0.09680485\n",
      "encoder.layer_norm.weight (256,) -0.09930899 -0.00034167175 0.09983697\n",
      "encoder.layer_norm.bias (256,) -0.09994934 -0.0017504573 0.099758565\n",
      "decoder.layer_stack.0.slf_attn.w_qs.weight (256, 256) -0.108252525 1.61416e-05 0.10825201\n",
      "decoder.layer_stack.0.slf_attn.w_ks.weight (256, 256) -0.10825315 0.00069515663 0.10824697\n",
      "decoder.layer_stack.0.slf_attn.w_vs.weight (256, 256) -0.108250685 -5.324777e-05 0.10825115\n",
      "decoder.layer_stack.0.slf_attn.fc.weight (256, 256) -0.10825303 3.2171585e-05 0.1082463\n",
      "decoder.layer_stack.0.slf_attn.layer_norm.weight (256,) -0.09998055 -0.0064615468 0.09905969\n",
      "decoder.layer_stack.0.slf_attn.layer_norm.bias (256,) -0.09970392 -8.834759e-05 0.09988641\n",
      "decoder.layer_stack.0.pos_ffn.w_1.weight (1024, 256) -0.068463154 -1.2040462e-05 0.068465054\n",
      "decoder.layer_stack.0.pos_ffn.w_1.bias (1024,) -0.099946156 -0.0007350506 0.099789836\n",
      "decoder.layer_stack.0.pos_ffn.w_2.weight (256, 1024) -0.06846439 -6.296839e-05 0.06846526\n",
      "decoder.layer_stack.0.pos_ffn.w_2.bias (256,) -0.09983339 0.0043445714 0.09990221\n",
      "decoder.layer_stack.0.pos_ffn.layer_norm.weight (256,) -0.099724054 0.0031638395 0.09838239\n",
      "decoder.layer_stack.0.pos_ffn.layer_norm.bias (256,) -0.0994124 -0.006412834 0.09941633\n",
      "decoder.layer_stack.1.slf_attn.w_qs.weight (256, 256) -0.1082524 0.00014097863 0.108251356\n",
      "decoder.layer_stack.1.slf_attn.w_ks.weight (256, 256) -0.108252816 0.00049756595 0.1082531\n",
      "decoder.layer_stack.1.slf_attn.w_vs.weight (256, 256) -0.10824949 -0.00045426615 0.108250424\n",
      "decoder.layer_stack.1.slf_attn.fc.weight (256, 256) -0.108251534 -4.445221e-05 0.1082399\n",
      "decoder.layer_stack.1.slf_attn.layer_norm.weight (256,) -0.09998158 -0.0032159046 0.09941039\n",
      "decoder.layer_stack.1.slf_attn.layer_norm.bias (256,) -0.09909296 0.0013744473 0.09973488\n",
      "decoder.layer_stack.1.pos_ffn.w_1.weight (1024, 256) -0.06846515 -2.5608397e-06 0.06846516\n",
      "decoder.layer_stack.1.pos_ffn.w_1.bias (1024,) -0.09993769 0.0006466366 0.099873446\n",
      "decoder.layer_stack.1.pos_ffn.w_2.weight (256, 1024) -0.06846505 -8.5821164e-05 0.06846482\n",
      "decoder.layer_stack.1.pos_ffn.w_2.bias (256,) -0.09967452 -0.0060489625 0.098202005\n",
      "decoder.layer_stack.1.pos_ffn.layer_norm.weight (256,) -0.09887183 -0.0009969568 0.099257074\n",
      "decoder.layer_stack.1.pos_ffn.layer_norm.bias (256,) -0.09958253 -0.0020133131 0.09896771\n",
      "decoder.layer_stack.2.slf_attn.w_qs.weight (256, 256) -0.10824903 -0.0001372431 0.10825302\n",
      "decoder.layer_stack.2.slf_attn.w_ks.weight (256, 256) -0.10825315 0.00052240456 0.10824996\n",
      "decoder.layer_stack.2.slf_attn.w_vs.weight (256, 256) -0.108252525 -0.00028672753 0.108249314\n",
      "decoder.layer_stack.2.slf_attn.fc.weight (256, 256) -0.10825315 7.319054e-05 0.108252026\n",
      "decoder.layer_stack.2.slf_attn.layer_norm.weight (256,) -0.096413784 0.003225299 0.09924864\n",
      "decoder.layer_stack.2.slf_attn.layer_norm.bias (256,) -0.09955623 -0.0040655714 0.0989926\n",
      "decoder.layer_stack.2.pos_ffn.w_1.weight (1024, 256) -0.06846462 4.4520268e-05 0.06846337\n",
      "decoder.layer_stack.2.pos_ffn.w_1.bias (1024,) -0.099893235 0.00027358718 0.09972689\n",
      "decoder.layer_stack.2.pos_ffn.w_2.weight (256, 1024) -0.06846501 3.8259852e-05 0.06846409\n",
      "decoder.layer_stack.2.pos_ffn.w_2.bias (256,) -0.09930034 -0.0057898723 0.099795036\n",
      "decoder.layer_stack.2.pos_ffn.layer_norm.weight (256,) -0.0974008 0.001532181 0.09978413\n",
      "decoder.layer_stack.2.pos_ffn.layer_norm.bias (256,) -0.099547125 -0.0041808784 0.099869244\n",
      "decoder.w.weight (256, 256) -0.108252116 -2.4071102e-05 0.108252734\n",
      "decoder.layer_norm.weight (256,) -0.09963173 -0.005573563 0.09989418\n",
      "decoder.layer_norm.bias (256,) -0.099473454 -0.00079842017 0.09986271\n"
     ]
    }
   ],
   "source": [
    "inp_len = ds_loader.emb_chunk_size if ds_loader.fixed_size else calc_max_inp_size(ds_loader.emb_chunk_size)\n",
    "model_ranker_cfg = parse_yaml_file_as(MllmRankerCfg, ranker_model_cfg_fpath)\n",
    "model_ranker = MllmRankerLevel(model_ranker_cfg, model_level).to(device)\n",
    "checkpoint_ranker = torch.load(ranker_snapshot_fpath)\n",
    "model_ranker.load_state_dict(checkpoint_ranker['model'])\n",
    "model_ranker.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([13, 100]),\n",
       " torch.Size([3, 100]),\n",
       " tensor([False, False, False, False, False, False, False,  True,  True,  True,\n",
       "         False, False, False]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 11\n",
    "batch = ds_loader.get_batch(i, train=True)\n",
    "docs_chunks, target_chunks, target_mask = batch.gen_tensors()\n",
    "docs_chunks.shape, target_chunks.shape, target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|query_begin|>  methods and seeks to contain a strong sense of narrative. Her work seeks to highlight the absurdities and inequalities of wealth inequalities among a small percentage of society. \\n\\nIn the 1980s, her work was described as \"strongly distinctive\", and were originally monochromatic before including the flat application of bright primary colours. Her methods for oil painting sat in contrast to customary methods, instead using small strokes of the brush while keeping the rest of the canvas largely colorless.\\n\\nIn 1990, she received the Young Artists Award from the Bangladesh Shilpakala Academy.\\n\\nHer known works include a series titled \"Which Can Be Knotted\", which was shown at the Fukuoka Asian Art Museum in 2002, representing both the wish to form strong bonds between people, as well as the suffocation created by strong relationships. She has also experimented with mixed media installations, for example at the 2010 Asian Biennale when she created an installation focused on the sound of birds. In 2016, her performance art was selected as a group of 20 diverse artists to be included in the Performance Art Week 2016, arranged by the Visual Arts Programme of Bengal Foundation. In 2019, her work was included in the 23rd National Art Exhibition held at the National Art Gallery of Bangladesh Shilpakala Academy.\\n\\nSee also \\n\\n Women Artists of Bangladesh\\n\\n <|query_end|>'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_target = tokens_to_text(target_chunks)\n",
    "s_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|doc_begin|> <|doc_id_begin|> 1879814 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Mazzara Airfield <|doc_title_end|> <|doc_body_begin|> Mazara Airfield is an abandone\n",
      "<|doc_begin|> <|doc_id_begin|> 1879814 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|> elfth Air Force 316th Troop Carrier Group  between 1 September and 18 October 1943  The unit had three \n",
      "<|doc_begin|> <|doc_id_begin|> 1879814 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|> \\n\\nThe airfield was not used during Operation Husky (invasion of Sicily). It appears to have been a sta\n",
      "<|doc_begin|> <|doc_id_begin|> 4409149 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Palm IIIx <|doc_title_end|> <|doc_body_begin|> The Palm IIIx is a PDA from Palm Comp\n",
      "<|doc_begin|> <|doc_id_begin|> 4409149 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  along with claims to be more efficient, than the 16 MHz Motorola DragonBall CPU found in all previous \n",
      "<|doc_begin|> <|doc_id_begin|> 4409149 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  previous version of Palm OS, 3.0.\\n\\nThe Palm IIIx also featured an expansion slot inside of its casing\n",
      "<|doc_begin|> <|doc_id_begin|> 4590269 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Leslie Kerr <|doc_title_end|> <|doc_body_begin|> Leslie Kerr (born September 17, 195\n",
      "<|doc_begin|> <|doc_id_begin|> 809788 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  methods and seeks to contain a strong sense of narrative. Her work seeks to highlight the absurdities a\n",
      "<|doc_begin|> <|doc_id_begin|> 809788 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  canvas largely colorless.\\n\\nIn 1990, she received the Young Artists Award from the Bangladesh Shilpakal\n",
      "<|doc_begin|> <|doc_id_begin|> 809788 <|doc_id_end|> <|doc_offset_begin|> 273 <|doc_offset_end|>  Asian Biennale when she created an installation focused on the sound of birds. In 2016, her performanc\n",
      "<|doc_begin|> <|doc_id_begin|> 1456939 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  notably Negazione. In 1991, he joined the hip hop ensamble Isola Posse All Stars and adopted the stage\n",
      "<|doc_begin|> <|doc_id_begin|> 1456939 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|> i della dopa which was led by the single \"Aspettando il sole\". In the following albums he spanned vari\n",
      "<|doc_begin|> <|doc_id_begin|> 1456939 <|doc_id_end|> <|doc_offset_begin|> 273 <|doc_offset_end|>  2004 he entered the main competition at the 54th edition of the Sanremo Music Festival, placing ninth\n"
     ]
    }
   ],
   "source": [
    "for toks in docs_chunks:\n",
    "    s = tokens_to_text(toks)\n",
    "    print(s[:200].replace('\\n', '\\\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embs = model_ranker.run_enc_emb(target_chunks)\n",
    "docs_embs = model_ranker.run_enc_emb(docs_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.303889 0.394754 0.218053 F\n",
      "0.144708 0.106359 -0.003139 F\n",
      "0.303046 0.219121 0.042181 F\n",
      "0.292043 0.390917 0.428751 F\n",
      "0.366955 0.339398 0.279463 F\n",
      "0.332836 0.310158 0.278422 F\n",
      "0.062432 0.049842 0.042358 F\n",
      "0.730377 0.612713 0.457807 T\n",
      "0.640144 0.715191 0.573683 T\n",
      "0.623566 0.749315 0.604172 T\n",
      "0.310417 0.362377 0.229236 F\n",
      "0.367458 0.450242 0.314680 F\n",
      "0.282556 0.361620 0.234114 F\n"
     ]
    }
   ],
   "source": [
    "cosine = False\n",
    "cosine = True\n",
    "print_dist(target_embs, docs_embs, target_mask, cosine=cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n",
      "0.272010 F\n",
      "0.071873 F\n",
      "0.156574 F\n",
      "-0.150676 F\n",
      "-0.052874 F\n",
      "-0.086484 F\n",
      "0.507175 F\n",
      "0.345749 T\n",
      "0.273679 T\n",
      "0.383693 T\n",
      "0.181840 F\n",
      "0.213475 F\n",
      "0.130052 F\n"
     ]
    }
   ],
   "source": [
    "txt = '1995 Fed Cup Europe'\n",
    "# txt = ' Kitchener Centre'\n",
    "# txt = 'Virginie Claes'\n",
    "txt = 'Asian Biennale when she created an installation focused on the sound of birds'\n",
    "\n",
    "# txt = 'The graph sandwich problem for property Π is defined as follows:'\n",
    "cosine = True\n",
    "txt_tokens = text_to_tokens(txt, qbeg_tok=qbeg_tok, qend_tok=qend_tok)\n",
    "# txt_tokens = txt_tokens.repeat(3, 1)\n",
    "print(txt_tokens.shape)\n",
    "txt_embs = model_ranker.run_enc_emb(txt_tokens)\n",
    "print_dist(txt_embs, docs_embs, target_mask, cosine=cosine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.000225',\n",
       " '0.000030',\n",
       " '0.000252',\n",
       " '0.000000',\n",
       " '0.000263',\n",
       " '0.000169',\n",
       " '0.968853',\n",
       " '0.007174',\n",
       " '0.009793',\n",
       " '0.010131',\n",
       " '0.000708',\n",
       " '0.001147',\n",
       " '0.001255']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rank = model_ranker.run_qs_infer(docs_chunks, txt_tokens)\n",
    "rank_str = [f'{r:.06f}' for r in rank.flatten()]\n",
    "rank_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 100])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_chunks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8737, 0.8907, 0.7371, 0.5201, 0.4101, 0.8237, 0.7342, 0.8183, 0.8694,\n",
       "         0.6263, 0.6608, 0.6087, 0.2565, 0.3135, 0.3250]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = model_ranker(txt_tokens, docs_chunks)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6538e-21, 3.7294e-11, 2.4412e-19, 3.4020e-23, 7.5630e-20, 3.8663e-25,\n",
       "         1.3986e-18, 7.2614e-22, 1.0000e+00, 1.0000e+00, 1.0000e+00, 4.7166e-09,\n",
       "         1.9997e-11, 1.3684e-08]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = model_ranker(target_chunks, docs_chunks)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device1 = torch.device('cpu')\n",
    "device2 = torch.device('cuda')\n",
    "device3 = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(device1 == device2)\n",
    "print(device2 == device3)\n",
    "print(device1 == device3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cpu', str)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device1.type, type(device1.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0.5,  0.5],\n",
       "       [ 1.7,  1.7,  1.7],\n",
       "       [-1. ,  7. , 33. ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "toks = [\n",
    "    np.ones(3) * 0.5,\n",
    "    np.ones(3) * 1.7,\n",
    "    np.array([-1, 7, 33])\n",
    "]\n",
    "np.stack(toks, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0.5,  0.5],\n",
       "       [ 1.7,  1.7,  1.7],\n",
       "       [-1. ,  7. , 33. ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(np.array(toks), np.stack(toks, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
