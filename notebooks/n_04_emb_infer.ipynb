{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import Optional\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import GPT2Tokenizer, AddedToken, PreTrainedTokenizer\n",
    "\n",
    "from mllm.data.wiki.dswiki import WikiDsLoader\n",
    "from mllm.model.mllm_encdec import MllmEncdec\n",
    "from mllm.model.mllm_ranker import MllmRanker\n",
    "from mllm.exp.cfg import create_mllm_encdec_cfg, create_mllm_ranker_cfg\n",
    "from mllm.tokenization.chunk_tokenizer import calc_max_inp_size, gen_all_tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(os.path.expandvars('$HOME')) / 'data'\n",
    "TRAIN_ENCDEC_PATH = DATA_PATH / 'train_mllm_encdec'\n",
    "# TRAIN_RANKER_PATH = DATA_PATH / 'train_mllm_ranker'\n",
    "TRAIN_RANKER_PATH = DATA_PATH / 'train_mllm_ranker_qs'\n",
    "DS_DIR_PATH = DATA_PATH / 'wiki_20200501_en' / 'ch_100_fixed'\n",
    "\n",
    "encdec_subdir = 'encdec-20240718_221554-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240722_225232-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240724_230827-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240726_232850-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240722_225232-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240730_213328-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240806_221913-msmarco'\n",
    "# ranker_subdir = 'ranker-20240815_180317-msmarco'\n",
    "ranker_subdir = 'ranker-20240903_215749-msmarco-fever'\n",
    "encdec_train_path = TRAIN_ENCDEC_PATH / encdec_subdir\n",
    "# ranker_train_path = TRAIN_RANKER_PATH / ranker_subdir\n",
    "ranker_train_path = DATA_PATH / 'train_mllm_ranker_qrels' / ranker_subdir\n",
    "encdec_snapshot_path = encdec_train_path / 'best.pth'\n",
    "ranker_snapshot_path = ranker_train_path / 'best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "docs_batch_size = 5\n",
    "max_chunks_per_doc = 3\n",
    "device = 'cpu'\n",
    "# device = 'cuda'\n",
    "\n",
    "device = torch.device(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cache from /home/misha/data/wiki_20200501_en/ch_100_fixed/.mllm/ds.csv\n",
      "Loaded dataset size: 50989207\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', model_max_length=100000)\n",
    "tok_dict = gen_all_tokens(tokenizer)\n",
    "pad_tok, qbeg_tok, qend_tok = tok_dict['pad'].ind, tok_dict['query_begin'].ind, tok_dict['query_end'].ind\n",
    "ds_loader = WikiDsLoader(\n",
    "    ds_path=DS_DIR_PATH, docs_batch_size=docs_batch_size, max_chunks_per_doc=max_chunks_per_doc,\n",
    "    pad_tok=pad_tok, qbeg_tok=qbeg_tok, qend_tok=qend_tok, device=device,\n",
    ")\n",
    "ds_loader.shuffle(train=True)\n",
    "ds_loader.shuffle(train=False)\n",
    "inp_len = ds_loader.emb_chunk_size if ds_loader.fixed_size else calc_max_inp_size(ds_loader.emb_chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokten_to_text(tokens: torch.Tensor) -> str:\n",
    "    tokens = tokens.flatten()\n",
    "    tokens = tokens[tokens != pad_tok]\n",
    "    tokens = list(tokens)\n",
    "    s = tokenizer.decode(tokens)\n",
    "    return s\n",
    "\n",
    "def distance(x: np.ndarray, y: np.ndarray, cosine: bool = False):\n",
    "    if not cosine:\n",
    "        return np.linalg.norm(x - y)\n",
    "    x_norm, y_norm = np.linalg.norm(x), np.linalg.norm(y)\n",
    "    return np.sum(x * y) / (x_norm * y_norm)\n",
    "\n",
    "def text_to_tokens(s: str, qbeg_tok: Optional[int] = None, qend_tok: Optional[int] = None) -> torch.Tensor:\n",
    "    tokens = tokenizer(s)['input_ids']\n",
    "    if qbeg_tok is not None:\n",
    "        assert qend_tok is not None\n",
    "        tokens = [qbeg_tok, *tokens, qend_tok]\n",
    "    n_tokens = len(tokens)\n",
    "    n_padded = n_tokens // inp_len + (n_tokens % inp_len > 0)\n",
    "    res = np.full((n_padded * inp_len, ), pad_tok, dtype=np.int32)\n",
    "    res[:n_tokens] = tokens\n",
    "    res = torch.from_numpy(res).to(device)\n",
    "    res = res.reshape(n_padded, inp_len)\n",
    "    return res\n",
    "\n",
    "def print_dist(target_embs: torch.Tensor, docs_embs: torch.Tensor, target_mask: torch.Tensor, cosine: bool = True):\n",
    "    for i, docs_emb in enumerate(docs_embs.detach().numpy()):\n",
    "        for target_emb in target_embs.detach().numpy():\n",
    "            dist = distance(target_emb, docs_emb, cosine)\n",
    "            print(f'{dist:0.6f} ', end='')\n",
    "        sfx = 'T' if target_mask[i] else 'F'\n",
    "        print(sfx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_encoder.src_word_emb.weight (50270, 256) -0.010897282 6.494323e-07 0.010897274\n",
      "vocab_encoder.layer_norm.weight (256,) -0.09865731 -0.001520379 0.099232934\n",
      "vocab_encoder.layer_norm.bias (256,) -0.0992744 -0.00053189404 0.09931554\n",
      "encoder.layer_stack.0.slf_attn.w_qs.weight (256, 256) -0.1082497 9.433067e-05 0.10825228\n",
      "encoder.layer_stack.0.slf_attn.w_ks.weight (256, 256) -0.108243585 0.0002877548 0.10825116\n",
      "encoder.layer_stack.0.slf_attn.w_vs.weight (256, 256) -0.10825165 -8.560575e-05 0.10825129\n",
      "encoder.layer_stack.0.slf_attn.fc.weight (256, 256) -0.1082527 0.00017292064 0.10824915\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.weight (256,) -0.0987946 0.0008891132 0.09902761\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.bias (256,) -0.09978663 -0.009286782 0.098430514\n",
      "encoder.layer_stack.0.pos_ffn.w_1.weight (1024, 256) -0.06846424 -4.3240772e-05 0.068464406\n",
      "encoder.layer_stack.0.pos_ffn.w_1.bias (1024,) -0.099947274 0.0028740857 0.09994185\n",
      "encoder.layer_stack.0.pos_ffn.w_2.weight (256, 1024) -0.06846487 -0.00012320561 0.06846501\n",
      "encoder.layer_stack.0.pos_ffn.w_2.bias (256,) -0.09976915 0.0035709941 0.09870058\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.weight (256,) -0.099938385 0.001422405 0.09930412\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.bias (256,) -0.09928443 0.00046096288 0.09819315\n",
      "encoder.w_em.weight (1, 100) -0.23313925 -0.021498749 0.23446852\n",
      "encoder.layer_norm.weight (256,) -0.09952656 -0.0031835204 0.09859675\n",
      "encoder.layer_norm.bias (256,) -0.099105895 0.003684339 0.099502124\n",
      "decoder.A_emb2sec (100, 256, 256) -0.008113919 -1.1920752e-06 0.008113918\n",
      "decoder.att_layers.0.slf_attn.w_qs.weight (256, 256) -0.108253 0.00022207612 0.10825113\n",
      "decoder.att_layers.0.slf_attn.w_ks.weight (256, 256) -0.108249635 -0.0001492667 0.10825049\n",
      "decoder.att_layers.0.slf_attn.w_vs.weight (256, 256) -0.10824893 0.00019174 0.10825241\n",
      "decoder.att_layers.0.slf_attn.fc.weight (256, 256) -0.10824912 -0.00027848163 0.108251214\n",
      "decoder.att_layers.0.slf_attn.layer_norm.weight (256,) -0.09841957 0.0015460504 0.09965124\n",
      "decoder.att_layers.0.slf_attn.layer_norm.bias (256,) -0.09970003 -0.0072924737 0.09840423\n",
      "decoder.att_layers.0.pos_ffn.w_1.weight (1024, 256) -0.06846514 -1.9705622e-05 0.06846453\n",
      "decoder.att_layers.0.pos_ffn.w_1.bias (1024,) -0.0997533 -0.0016378163 0.09980913\n",
      "decoder.att_layers.0.pos_ffn.w_2.weight (256, 1024) -0.06846439 0.00010000249 0.068465136\n",
      "decoder.att_layers.0.pos_ffn.w_2.bias (256,) -0.09781279 -0.0028138924 0.09792944\n",
      "decoder.att_layers.0.pos_ffn.layer_norm.weight (256,) -0.099026166 0.0014005657 0.09990094\n",
      "decoder.att_layers.0.pos_ffn.layer_norm.bias (256,) -0.09974845 0.0041506984 0.0980232\n",
      "vocab_decoder.word_prj.weight (50270, 256) -0.010897279 2.7050285e-06 0.010897281\n"
     ]
    }
   ],
   "source": [
    "model_encdec_cfg = create_mllm_encdec_cfg(\n",
    "    n_vocab=len(tokenizer), d_word_wec=256, inp_len=inp_len,\n",
    "    enc_n_layers=1, dec_n_layers=1,\n",
    "    n_heads=8, d_model=256, d_inner=1024,\n",
    "    pad_idx=pad_tok, dropout_rate=0.1, enc_with_emb_mat=True,\n",
    ")\n",
    "model_encdec = MllmEncdec(model_encdec_cfg).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_encdec = torch.load(encdec_snapshot_path)\n",
    "model_encdec.load_state_dict(checkpoint_encdec['model'], strict=False)\n",
    "model_encdec.eval()\n",
    "del checkpoint_encdec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496,   612, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267]],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_tokens('Hello there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14, 100]),\n",
       " torch.Size([3, 100]),\n",
       " tensor([False, False, False,  True,  True,  True, False, False, False, False,\n",
       "         False, False, False, False]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 10\n",
    "batch = ds_loader.get_batch(i, train=True)\n",
    "docs_chunks, target_chunks, target_mask = batch.gen_tensors()\n",
    "docs_chunks.shape, target_chunks.shape, target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|query_begin|> California's 16th State Assembly districtCalifornia's 16th State Assembly district is one of 80 California State Assembly districts. It is currently represented by Democrat Rebecca Bauer-Kahan of Orinda.\\n\\nDistrict profile \\nThe district is located in the East Bay. It consists of the primarily affluent suburbs east of the Berkeley Hills, including Lamorinda and the Tri-Valley. During Catharine Baker's time in office, it was the most Democratic seat held by a Republican in the Assembly.\\n\\nAlameda County – 13.3% of Alameda County population\\n Dublin\\n Livermore\\n Pleasanton\\n\\nContra Costa County – 25.3% of Contra Costa County population\\n Alamo\\n Blackhawk\\n Danville\\n Diablo\\n Lafayette\\n Moraga\\n Orinda\\n Saranap\\n San Ramon\\n Walnut Creek – 82.5% of Walnut Creek population included\\n\\nElection results from statewide races\\n\\nElection results\\n\\n2020\\n\\n2018\\n\\n2016\\n\\n2014\\n\\n2012\\n\\nSee also \\n California State Assembly\\n California State Assembly districts\\n Districts in California\\n\\nReferences\\n\\nExternal links \\n District map from the California Citizens Redistricting Commission\\n\\n16\\nCategory:Government of Alameda County, California\\nCategory:Government of Contra Costa County, California\\nCategory: <|query_end|>\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_target = tokten_to_text(target_chunks)\n",
    "s_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|doc_begin|> <|doc_id_begin|> 3357836 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  The show also follows Willie's attempts to win back his former fiancé from his nemesis. Many of Bushw\n",
      "<|doc_begin|> <|doc_id_begin|> 3357836 <|doc_id_end|> <|doc_offset_begin|> 273 <|doc_offset_end|>  predominantly Latino, though a much larger audience will relate to the themes in the series. The show\n",
      "<|doc_begin|> <|doc_id_begin|> 3357836 <|doc_id_end|> <|doc_offset_begin|> 364 <|doc_offset_end|>  Award for \"Best Web Series: Comedy.\" East Willy B was also highlighted in IndieWire as one of the thi\n",
      "<|doc_begin|> <|doc_id_begin|> 427145 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> California's 16th State Assembly district <|doc_title_end|> <|doc_body_begin|> Califo\n",
      "<|doc_begin|> <|doc_id_begin|> 427145 <|doc_id_end|> <|doc_offset_begin|> 92 <|doc_offset_end|>  most Democratic seat held by a Republican in the Assembly.\\n\\nAlameda County – 13.3% of Alameda County po\n",
      "<|doc_begin|> <|doc_id_begin|> 427145 <|doc_id_end|> <|doc_offset_begin|> 184 <|doc_offset_end|> \\n\\nElection results from statewide races\\n\\nElection results\\n\\n2020\\n\\n2018\\n\\n2016\\n\\n2014\\n\\n2012\\n\\nSee also \\n Cal\n",
      "<|doc_begin|> <|doc_id_begin|> 5074536 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> 2012 Clipsal 500 <|doc_title_end|> <|doc_body_begin|> The 2012 Clipsal 500 was a mot\n",
      "<|doc_begin|> <|doc_id_begin|> 5074536 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|> \\nTriple Eight Race Engineering driver Craig Lowndes qualified on pole position for the first race — his\n",
      "<|doc_begin|> <|doc_id_begin|> 5074536 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  red flags during qualifying.\\n\\nRace \\nGarth Tander took an early lead in the race, but was re-passed by\n",
      "<|doc_begin|> <|doc_id_begin|> 638874 <|doc_id_end|> <|doc_offset_begin|> 364 <|doc_offset_end|> \\n\\nRelated activities included the \"Staffrider Series\", a book series comprising almost thirty stand-alo\n",
      "<|doc_begin|> <|doc_id_begin|> 638874 <|doc_id_end|> <|doc_offset_begin|> 455 <|doc_offset_end|>  I. Vladislavic (eds), Johannesburg: Ravan Press, 1988.\\n Oliphant, Andries. Staffrider Magazine and Pop\n",
      "<|doc_begin|> <|doc_id_begin|> 638874 <|doc_id_end|> <|doc_offset_begin|> 546 <|doc_offset_end|> othobi Mutloatse. Interview conducted 9 September 2006.\\n Gwala, Mafika. Writing as a Cultural Weapon in\n",
      "<|doc_begin|> <|doc_id_begin|> 5633388 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Prataprao Gujar <|doc_title_end|> <|doc_body_begin|> Prataprao Gujar born in Bhosare\n",
      "<|doc_begin|> <|doc_id_begin|> 5633388 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  Prataprao Gujar\\n\\nCategory:Indian military leaders\\nCategory:People of the Maratha Empire\\nCategory:Marat\n"
     ]
    }
   ],
   "source": [
    "for toks in docs_chunks:\n",
    "    s = tokten_to_text(toks)\n",
    "    print(s[:200].replace('\\n', '\\\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embs = model_encdec.run_enc_emb(target_chunks)\n",
    "docs_embs = model_encdec.run_enc_emb(docs_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.659873 0.625968 0.588829 F\n",
      "0.649063 0.515043 0.551877 F\n",
      "0.638165 0.640675 0.606706 F\n",
      "0.761945 0.688867 0.711992 T\n",
      "0.708158 0.748468 0.746569 T\n",
      "0.672655 0.724277 0.768461 T\n",
      "0.675588 0.682079 0.598821 F\n",
      "0.630862 0.613829 0.549941 F\n",
      "0.631237 0.662260 0.596649 F\n",
      "0.603324 0.614365 0.643579 F\n",
      "0.643235 0.683757 0.673601 F\n",
      "0.633847 0.679635 0.626069 F\n",
      "0.638340 0.628420 0.610957 F\n",
      "0.573513 0.547358 0.578394 F\n"
     ]
    }
   ],
   "source": [
    "cosine = False\n",
    "cosine = True\n",
    "print_dist(target_embs, docs_embs, target_mask, cosine=cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_encoder.src_word_emb.weight (50270, 256) -0.010897281 -2.6339873e-07 0.010897276\n",
      "vocab_encoder.layer_norm.weight (256,) -0.09994521 -0.0027807415 0.09999938\n",
      "vocab_encoder.layer_norm.bias (256,) -0.09996406 0.003614617 0.09834387\n",
      "encoders.0.layer_stack.0.slf_attn.w_qs.weight (256, 256) -0.1082469 -0.00036873628 0.10824658\n",
      "encoders.0.layer_stack.0.slf_attn.w_ks.weight (256, 256) -0.10825051 -0.0001931882 0.10825238\n",
      "encoders.0.layer_stack.0.slf_attn.w_vs.weight (256, 256) -0.10824983 -0.00018752666 0.108235635\n",
      "encoders.0.layer_stack.0.slf_attn.fc.weight (256, 256) -0.10825132 -0.0007193911 0.1082494\n",
      "encoders.0.layer_stack.0.slf_attn.layer_norm.weight (256,) -0.09955348 0.0025702321 0.09993328\n",
      "encoders.0.layer_stack.0.slf_attn.layer_norm.bias (256,) -0.09987169 -0.00085548125 0.09968227\n",
      "encoders.0.layer_stack.0.pos_ffn.w_1.weight (1024, 256) -0.06846416 -7.183825e-05 0.06846529\n",
      "encoders.0.layer_stack.0.pos_ffn.w_1.bias (1024,) -0.09973278 0.0007764242 0.09967058\n",
      "encoders.0.layer_stack.0.pos_ffn.w_2.weight (256, 1024) -0.06846531 -0.00011074922 0.06846514\n",
      "encoders.0.layer_stack.0.pos_ffn.w_2.bias (256,) -0.09960877 0.0029526316 0.099027745\n",
      "encoders.0.layer_stack.0.pos_ffn.layer_norm.weight (256,) -0.09942074 -0.009472223 0.09962416\n",
      "encoders.0.layer_stack.0.pos_ffn.layer_norm.bias (256,) -0.098402716 0.002221473 0.09994036\n",
      "encoders.0.w_em.weight (1, 100) -0.2425008 -0.0010678753 0.24023628\n",
      "encoders.0.layer_norm.weight (256,) -0.09951385 -0.0036468387 0.099202804\n",
      "encoders.0.layer_norm.bias (256,) -0.09728445 0.0011407031 0.099903464\n",
      "decoders.0.w.weight (256, 256) -0.108252965 0.00015600654 0.10825016\n",
      "decoders.0.layer_norm.weight (256,) -0.09939152 -0.0037324196 0.09985795\n",
      "decoders.0.layer_norm.bias (256,) -0.099228635 -0.00032980437 0.09931848\n"
     ]
    }
   ],
   "source": [
    "inp_len = ds_loader.emb_chunk_size if ds_loader.fixed_size else calc_max_inp_size(ds_loader.emb_chunk_size)\n",
    "model_ranker_cfg = create_mllm_ranker_cfg(\n",
    "    n_vocab=len(tokenizer), inp_len=inp_len, d_word_wec=256,\n",
    "    n_levels=1, enc_n_layers=1, dec_n_layers=1,\n",
    "    n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024,\n",
    "    pad_idx=pad_tok, dropout_rate=0.1, enc_with_emb_mat=True,\n",
    ")\n",
    "\n",
    "model_ranker = MllmRanker(model_ranker_cfg).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_ranker = torch.load(ranker_snapshot_path)\n",
    "model_ranker.load_state_dict(checkpoint_ranker['model'])\n",
    "model_ranker.eval()\n",
    "del checkpoint_ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14, 100]),\n",
       " torch.Size([3, 100]),\n",
       " tensor([ True,  True,  True, False, False, False, False, False, False, False,\n",
       "         False, False, False, False]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 10\n",
    "batch = ds_loader.get_batch(i, train=True)\n",
    "docs_chunks, target_chunks, target_mask = batch.gen_tensors()\n",
    "docs_chunks.shape, target_chunks.shape, target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|query_begin|> East Willy BEast Willy B is a comedic Web series that profiles Latinos in the gentrifying neighborhood of Bushwick in Brooklyn, New York City. Described as a Puerto Rican Cheers, its episodes generally run six to nine minutes online and tackle themes such as love, race, gentrification, entrepreneurship, and more. The series aims to promote Latino voices in media outlets.\\n\\nThe series\\nThe series, created by Julia Ahumada Grob and Yamin Segal, follows the life of Willie Jr. and his bartender friend, Ceci Rivera. The show documents the process where a Latino neighborhood starts to change, with young hipsters moving to Bushwick in search of the next hot Brooklyn neighborhood. As rents increase in Bushwick, Brooklyn (or \"East Williamsburg\") due to gentrification, Ceci and Willie organize their neighborhood to save Willie\\'s bar. The show also follows Willie\\'s attempts to win back his former fiancé from his nemesis. Many of Bushwick\\'s \"quirky characters\" are included in the show, including a \"bodega CEO, piragua (shaved ice) purveyors, local artists, family drunks, sassy women, local beggars, salsa music lovers, as well as the unwanted \\'hipsters.\\'\"\\n\\nThe cast and crew are <|query_end|>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_target = tokten_to_text(target_chunks)\n",
    "s_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|doc_begin|> <|doc_id_begin|> 3357836 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> East Willy B <|doc_title_end|> <|doc_body_begin|> East Willy B is a comedic Web seri\n",
      "<|doc_begin|> <|doc_id_begin|> 3357836 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  Julia Ahumada Grob and Yamin Segal, follows the life of Willie Jr. and his bartender friend, Ceci Rive\n",
      "<|doc_begin|> <|doc_id_begin|> 3357836 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  The show also follows Willie's attempts to win back his former fiancé from his nemesis. Many of Bushw\n",
      "<|doc_begin|> <|doc_id_begin|> 427145 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> California's 16th State Assembly district <|doc_title_end|> <|doc_body_begin|> Califo\n",
      "<|doc_begin|> <|doc_id_begin|> 427145 <|doc_id_end|> <|doc_offset_begin|> 92 <|doc_offset_end|>  most Democratic seat held by a Republican in the Assembly.\\n\\nAlameda County – 13.3% of Alameda County po\n",
      "<|doc_begin|> <|doc_id_begin|> 427145 <|doc_id_end|> <|doc_offset_begin|> 184 <|doc_offset_end|> \\n\\nElection results from statewide races\\n\\nElection results\\n\\n2020\\n\\n2018\\n\\n2016\\n\\n2014\\n\\n2012\\n\\nSee also \\n Cal\n",
      "<|doc_begin|> <|doc_id_begin|> 5074536 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> 2012 Clipsal 500 <|doc_title_end|> <|doc_body_begin|> The 2012 Clipsal 500 was a mot\n",
      "<|doc_begin|> <|doc_id_begin|> 5074536 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|> \\nTriple Eight Race Engineering driver Craig Lowndes qualified on pole position for the first race — his\n",
      "<|doc_begin|> <|doc_id_begin|> 5074536 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  red flags during qualifying.\\n\\nRace \\nGarth Tander took an early lead in the race, but was re-passed by\n",
      "<|doc_begin|> <|doc_id_begin|> 638874 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|> ced by The Durban Moment that saw Steve Biko begin the South African Students' Organisation, Staffrider\n",
      "<|doc_begin|> <|doc_id_begin|> 638874 <|doc_id_end|> <|doc_offset_begin|> 273 <|doc_offset_end|>  magazine. Debates around Staffrider′s \"self-editing\" editorial policy were ongoing and the magazine ev\n",
      "<|doc_begin|> <|doc_id_begin|> 638874 <|doc_id_end|> <|doc_offset_begin|> 364 <|doc_offset_end|> \\n\\nRelated activities included the \"Staffrider Series\", a book series comprising almost thirty stand-alo\n",
      "<|doc_begin|> <|doc_id_begin|> 5633388 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Prataprao Gujar <|doc_title_end|> <|doc_body_begin|> Prataprao Gujar born in Bhosare\n",
      "<|doc_begin|> <|doc_id_begin|> 5633388 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  Prataprao Gujar\\n\\nCategory:Indian military leaders\\nCategory:People of the Maratha Empire\\nCategory:Marat\n"
     ]
    }
   ],
   "source": [
    "for toks in docs_chunks:\n",
    "    s = tokten_to_text(toks)\n",
    "    print(s[:200].replace('\\n', '\\\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embs = model_ranker.run_enc_emb(target_chunks)\n",
    "docs_embs = model_ranker.run_enc_emb(docs_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.896406 0.764625 0.658545 T\n",
      "0.804114 0.923876 0.671374 T\n",
      "0.765415 0.808461 0.869088 T\n",
      "0.715746 0.657727 0.467861 F\n",
      "0.601611 0.647713 0.413840 F\n",
      "0.516053 0.485636 0.232942 F\n",
      "0.399742 0.406179 0.354653 F\n",
      "0.463552 0.525545 0.435180 F\n",
      "0.569390 0.681343 0.548763 F\n",
      "0.549657 0.498152 0.543873 F\n",
      "0.717221 0.709256 0.709675 F\n",
      "0.445960 0.375591 0.521954 F\n",
      "0.273253 0.298420 0.504144 F\n",
      "0.076357 0.108437 0.267569 F\n"
     ]
    }
   ],
   "source": [
    "cosine = False\n",
    "cosine = True\n",
    "print_dist(target_embs, docs_embs, target_mask, cosine=cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n",
      "0.009376 T\n",
      "0.085239 T\n",
      "0.211096 T\n",
      "0.133755 F\n",
      "0.143394 F\n",
      "0.122204 F\n",
      "0.227482 F\n",
      "0.067510 F\n",
      "0.046468 F\n",
      "0.230950 F\n",
      "0.220598 F\n",
      "0.303955 F\n",
      "0.670864 F\n",
      "0.703972 F\n"
     ]
    }
   ],
   "source": [
    "txt = 'Hong Kong 1987'\n",
    "txt = 'Climate Classification system, Mays Landing has a humid subtropical climate, abbreviated \"Cfa\"'\n",
    "# txt = 'Climate Classification system'\n",
    "txt = 'War and Peace'\n",
    "txt = 'Bandar Express, Ichhamati Express and Benapole Express'\n",
    "txt = 'Rick Anderson'\n",
    "txt = 'Makangarawe Temeke ward'\n",
    "# txt = 'graph sandwich'\n",
    "txt = 'james barry'\n",
    "txt = 'erigeron'\n",
    "txt = 'Dillon Gabriel america'\n",
    "txt = 'East Willy B'\n",
    "txt = 'Prataprao Gujar'\n",
    "# txt = 'The graph sandwich problem for property Π is defined as follows:'\n",
    "cosine = True\n",
    "txt_tokens = text_to_tokens(txt, qbeg_tok=qbeg_tok, qend_tok=qend_tok)\n",
    "# txt_tokens = txt_tokens.repeat(3, 1)\n",
    "print(txt_tokens.shape)\n",
    "txt_embs = model_ranker.run_enc_emb(txt_tokens)\n",
    "print_dist(txt_embs, docs_embs, target_mask, cosine=cosine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8170e-05, 8.9663e-05, 1.4852e-03, 9.0462e-04, 4.0314e-04, 2.9787e-04,\n",
       "         7.4527e-03, 1.6140e-04, 1.0724e-04, 2.7201e-03, 2.8551e-04, 1.0182e-02,\n",
       "         9.8398e-01, 9.8504e-01]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rank = model_ranker.run_qs_infer(docs_chunks, txt_tokens)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442500"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 59\n",
    "batch_size = 15\n",
    "train_steps = 500\n",
    "\n",
    "n_epochs * train_steps * batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8737, 0.8907, 0.7371, 0.5201, 0.4101, 0.8237, 0.7342, 0.8183, 0.8694,\n",
       "         0.6263, 0.6608, 0.6087, 0.2565, 0.3135, 0.3250]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = model_ranker(txt_tokens, docs_chunks)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6538e-21, 3.7294e-11, 2.4412e-19, 3.4020e-23, 7.5630e-20, 3.8663e-25,\n",
       "         1.3986e-18, 7.2614e-22, 1.0000e+00, 1.0000e+00, 1.0000e+00, 4.7166e-09,\n",
       "         1.9997e-11, 1.3684e-08]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = model_ranker(target_chunks, docs_chunks)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device1 = torch.device('cpu')\n",
    "device2 = torch.device('cuda')\n",
    "device3 = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(device1 == device2)\n",
    "print(device2 == device3)\n",
    "print(device1 == device3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cpu', str)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device1.type, type(device1.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0.5,  0.5],\n",
       "       [ 1.7,  1.7,  1.7],\n",
       "       [-1. ,  7. , 33. ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "toks = [\n",
    "    np.ones(3) * 0.5,\n",
    "    np.ones(3) * 1.7,\n",
    "    np.array([-1, 7, 33])\n",
    "]\n",
    "np.stack(toks, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0.5,  0.5],\n",
       "       [ 1.7,  1.7,  1.7],\n",
       "       [-1. ,  7. , 33. ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(np.array(toks), np.stack(toks, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
