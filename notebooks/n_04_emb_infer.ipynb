{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import Optional\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import GPT2Tokenizer, AddedToken, PreTrainedTokenizer\n",
    "\n",
    "from mllm.data.wiki.dswiki import WikiDsLoader\n",
    "from mllm.model.mllm_encdec import MllmEncdec\n",
    "from mllm.model.mllm_ranker import MllmRanker\n",
    "from mllm.config.model import create_mllm_encdec_cfg, create_mllm_ranker_cfg\n",
    "from mllm.tokenization.chunk_tokenizer import calc_max_inp_size, gen_all_tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(os.path.expandvars('$HOME')) / 'data'\n",
    "TRAIN_ENCDEC_PATH = DATA_PATH / 'train_mllm_encdec'\n",
    "# TRAIN_RANKER_PATH = DATA_PATH / 'train_mllm_ranker'\n",
    "TRAIN_RANKER_PATH = DATA_PATH / 'train_mllm_ranker_qs'\n",
    "DS_DIR_PATH = DATA_PATH / 'wiki_20200501_en' / 'ch_100_fixed'\n",
    "\n",
    "encdec_subdir = 'encdec-20240718_221554-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240722_225232-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240724_230827-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240726_232850-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240722_225232-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240730_213328-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240806_221913-msmarco'\n",
    "# ranker_subdir = 'ranker-20240815_180317-msmarco'\n",
    "ranker_subdir = 'ranker-20240903_215749-msmarco-fever'\n",
    "# ranker_subdir = 'ranker-20240905_213413-msmarco-fever'\n",
    "encdec_train_path = TRAIN_ENCDEC_PATH / encdec_subdir\n",
    "# ranker_train_path = TRAIN_RANKER_PATH / ranker_subdir\n",
    "ranker_train_path = DATA_PATH / 'train_mllm_ranker_qrels' / ranker_subdir\n",
    "encdec_snapshot_path = encdec_train_path / 'best.pth'\n",
    "ranker_snapshot_path = ranker_train_path / 'best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "docs_batch_size = 5\n",
    "max_chunks_per_doc = 3\n",
    "device = 'cpu'\n",
    "# device = 'cuda'\n",
    "\n",
    "device = torch.device(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cache from /home/misha/data/wiki_20200501_en/ch_100_fixed/.mllm/ds.csv\n",
      "Loaded dataset size: 50989207\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', model_max_length=100000)\n",
    "tok_dict = gen_all_tokens(tokenizer)\n",
    "pad_tok, qbeg_tok, qend_tok = tok_dict['pad'].ind, tok_dict['query_begin'].ind, tok_dict['query_end'].ind\n",
    "ds_loader = WikiDsLoader(\n",
    "    ds_path=DS_DIR_PATH, docs_batch_size=docs_batch_size, max_chunks_per_doc=max_chunks_per_doc,\n",
    "    pad_tok=pad_tok, qbeg_tok=qbeg_tok, qend_tok=qend_tok, device=device,\n",
    ")\n",
    "ds_loader.shuffle(train=True)\n",
    "ds_loader.shuffle(train=False)\n",
    "inp_len = ds_loader.emb_chunk_size if ds_loader.fixed_size else calc_max_inp_size(ds_loader.emb_chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokten_to_text(tokens: torch.Tensor) -> str:\n",
    "    tokens = tokens.flatten()\n",
    "    tokens = tokens[tokens != pad_tok]\n",
    "    tokens = list(tokens)\n",
    "    s = tokenizer.decode(tokens)\n",
    "    return s\n",
    "\n",
    "def distance(x: np.ndarray, y: np.ndarray, cosine: bool = False):\n",
    "    if not cosine:\n",
    "        return np.linalg.norm(x - y)\n",
    "    x_norm, y_norm = np.linalg.norm(x), np.linalg.norm(y)\n",
    "    return np.sum(x * y) / (x_norm * y_norm)\n",
    "\n",
    "def text_to_tokens(s: str, qbeg_tok: Optional[int] = None, qend_tok: Optional[int] = None) -> torch.Tensor:\n",
    "    tokens = tokenizer(s)['input_ids']\n",
    "    if qbeg_tok is not None:\n",
    "        assert qend_tok is not None\n",
    "        tokens = [qbeg_tok, *tokens, qend_tok]\n",
    "    n_tokens = len(tokens)\n",
    "    n_padded = n_tokens // inp_len + (n_tokens % inp_len > 0)\n",
    "    res = np.full((n_padded * inp_len, ), pad_tok, dtype=np.int32)\n",
    "    res[:n_tokens] = tokens\n",
    "    res = torch.from_numpy(res).to(device)\n",
    "    res = res.reshape(n_padded, inp_len)\n",
    "    return res\n",
    "\n",
    "def print_dist(target_embs: torch.Tensor, docs_embs: torch.Tensor, target_mask: torch.Tensor, cosine: bool = True):\n",
    "    for i, docs_emb in enumerate(docs_embs.detach().numpy()):\n",
    "        for target_emb in target_embs.detach().numpy():\n",
    "            dist = distance(target_emb, docs_emb, cosine)\n",
    "            print(f'{dist:0.6f} ', end='')\n",
    "        sfx = 'T' if target_mask[i] else 'F'\n",
    "        print(sfx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_encoder.src_word_emb.weight (50270, 256) -0.010897278 -1.335788e-06 0.010897281\n",
      "vocab_encoder.layer_norm.weight (256,) -0.09893657 0.0066219117 0.09997964\n",
      "vocab_encoder.layer_norm.bias (256,) -0.099779785 0.0021610437 0.099599935\n",
      "encoder.layer_stack.0.slf_attn.w_qs.weight (256, 256) -0.10825171 -7.75688e-05 0.10825041\n",
      "encoder.layer_stack.0.slf_attn.w_ks.weight (256, 256) -0.10825286 6.4800486e-05 0.10825026\n",
      "encoder.layer_stack.0.slf_attn.w_vs.weight (256, 256) -0.10825027 0.00010499777 0.10825214\n",
      "encoder.layer_stack.0.slf_attn.fc.weight (256, 256) -0.10825227 -6.173113e-05 0.108251885\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.weight (256,) -0.098802604 -0.0031716428 0.09854559\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.bias (256,) -0.09966463 0.005480206 0.099370494\n",
      "encoder.layer_stack.0.pos_ffn.w_1.weight (1024, 256) -0.06846521 2.8875238e-05 0.06846477\n",
      "encoder.layer_stack.0.pos_ffn.w_1.bias (1024,) -0.09987471 -0.000680316 0.09982319\n",
      "encoder.layer_stack.0.pos_ffn.w_2.weight (256, 1024) -0.06846418 5.4428307e-05 0.06846529\n",
      "encoder.layer_stack.0.pos_ffn.w_2.bias (256,) -0.09924189 -0.0026071104 0.09941343\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.weight (256,) -0.099536076 -0.0029492364 0.09992571\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.bias (256,) -0.09896375 -0.00020993093 0.099204235\n",
      "encoder.w_em.weight (1, 100) -0.23841062 0.010643251 0.24269055\n",
      "encoder.layer_norm.weight (256,) -0.099820614 -0.0011928759 0.099980496\n",
      "encoder.layer_norm.bias (256,) -0.099939875 0.007379391 0.09998008\n",
      "decoder.A_emb2sec (100, 256, 256) -0.008113919 -3.861617e-07 0.008113918\n",
      "decoder.att_layers.0.slf_attn.w_qs.weight (256, 256) -0.1082497 2.6443224e-05 0.10825316\n",
      "decoder.att_layers.0.slf_attn.w_ks.weight (256, 256) -0.10825291 0.0001582905 0.108251266\n",
      "decoder.att_layers.0.slf_attn.w_vs.weight (256, 256) -0.10825108 -0.00029298262 0.10825262\n",
      "decoder.att_layers.0.slf_attn.fc.weight (256, 256) -0.108250014 0.00021564952 0.1082509\n",
      "decoder.att_layers.0.slf_attn.layer_norm.weight (256,) -0.09799917 0.007648286 0.09952034\n",
      "decoder.att_layers.0.slf_attn.layer_norm.bias (256,) -0.0995448 -4.823087e-07 0.0997681\n",
      "decoder.att_layers.0.pos_ffn.w_1.weight (1024, 256) -0.068464994 1.5649359e-06 0.06846493\n",
      "decoder.att_layers.0.pos_ffn.w_1.bias (1024,) -0.099832736 6.3878833e-06 0.09979477\n",
      "decoder.att_layers.0.pos_ffn.w_2.weight (256, 1024) -0.06846268 -3.2310483e-05 0.06846487\n",
      "decoder.att_layers.0.pos_ffn.w_2.bias (256,) -0.09978296 -0.008715762 0.09874582\n",
      "decoder.att_layers.0.pos_ffn.layer_norm.weight (256,) -0.09842759 0.00048604666 0.09993773\n",
      "decoder.att_layers.0.pos_ffn.layer_norm.bias (256,) -0.09779986 0.0049055996 0.09775948\n",
      "vocab_decoder.word_prj.weight (50270, 256) -0.010897279 -3.4982088e-07 0.010897281\n"
     ]
    }
   ],
   "source": [
    "model_encdec_cfg = create_mllm_encdec_cfg(\n",
    "    n_vocab=len(tokenizer), d_word_wec=256, inp_len=inp_len,\n",
    "    enc_n_layers=1, dec_n_layers=1,\n",
    "    n_heads=8, d_model=256, d_inner=1024,\n",
    "    pad_idx=pad_tok, dropout_rate=0.1, enc_with_emb_mat=True,\n",
    ")\n",
    "model_encdec = MllmEncdec(model_encdec_cfg).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_encdec = torch.load(encdec_snapshot_path)\n",
    "model_encdec.load_state_dict(checkpoint_encdec['model'], strict=False)\n",
    "model_encdec.eval()\n",
    "del checkpoint_encdec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496,   612, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267]],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_tokens('Hello there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([13, 100]),\n",
       " torch.Size([3, 100]),\n",
       " tensor([False, False, False, False, False, False, False, False,  True,  True,\n",
       "          True, False, False]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 10\n",
    "batch = ds_loader.get_batch(i, train=True)\n",
    "docs_chunks, target_chunks, target_mask = batch.gen_tensors()\n",
    "docs_chunks.shape, target_chunks.shape, target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|query_begin|> Suden uniSuden uni (\"Wolf\\'s Dream\") is the first full-length album by Finnish pagan metal band Moonsorrow. It was originally released in 2001, and then re-released in 2003 with one bonus track (a Finnish lyrics version of the traditional Swedish song \"Kom nu gubbar\"), different cover art, and a 40-minute DVD.\\n\\nTrack listing\\n\\nPersonnel\\n Ville Sorvali - vocals, bass, handclaps, choir\\n Marko Tarvonen - drums, timpani, 12-string, vocals (backing), handclaps, choir\\n Henri Sorvali - choir, guitars, keyboards, vocals (clean), accordion, mouth harp, handclaps\\n\\nGuest musicians\\n Robert Lejon - handclaps on \"Tulkaapa äijät!\"\\n Stefan Lejon - handclaps on \"Tulkaapa äijät!\"\\n Blastmor - handclaps\\n Avather - handclaps\\n Janne Perttilä - choir, handclaps\\n\\nProduction\\n Mika Jussila - remastering\\n Ahti \"Pirtu\" Kortelainen - recording, mixing, mastering\\n Niklas Sundin - reissue cover art\\n\\nCategory: <|query_end|>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_target = tokten_to_text(target_chunks)\n",
    "s_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|doc_begin|> <|doc_id_begin|> 4043219 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> The Hamilton Spectator <|doc_title_end|> <|doc_body_begin|> The Hamilton Spectator, \n",
      "<|doc_begin|> <|doc_id_begin|> 4043219 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  the Spectator the first of the chain. The Southam chain was sold in 1998 to Conrad Black, who in turn \n",
      "<|doc_begin|> <|doc_id_begin|> 4043219 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  the surrounding communities of Grimsby and Beamsville. It also serves Brant County and Haldimand Coun\n",
      "<|doc_begin|> <|doc_id_begin|> 5623618 <|doc_id_end|> <|doc_offset_begin|> 4330 <|doc_offset_end|>.\\n Sport Available starting from the 2017 model year, the inline-4 is replaced by the 2.7 Ecoboost 325\n",
      "<|doc_begin|> <|doc_id_begin|> 5623618 <|doc_id_end|> <|doc_offset_begin|> 4420 <|doc_offset_end|>  Fancy Sport Chrome Mesh Grille, Nappa Leather Seating Surfaces, and Heated and Cooled Front Seats.\\n \n",
      "<|doc_begin|> <|doc_id_begin|> 5623618 <|doc_id_end|> <|doc_offset_begin|> 4510 <|doc_offset_end|> charger producing 245hp and 275lbft with 1 mpg overall increase in fuel economy\\n\\nHybrid\\nThe new 2013 \n",
      "<|doc_begin|> <|doc_id_begin|> 3716608 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Buddy Baumann (American football) <|doc_title_end|> <|doc_body_begin|> Carl Buddy Ba\n",
      "<|doc_begin|> <|doc_id_begin|> 3716608 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  deaths <|doc_body_end|> <|doc_end|>\n",
      "<|doc_begin|> <|doc_id_begin|> 1346880 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Suden uni <|doc_title_end|> <|doc_body_begin|> Suden uni (\"Wolf's Dream\") is the fir\n",
      "<|doc_begin|> <|doc_id_begin|> 1346880 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|> i - vocals, bass, handclaps, choir\\n Marko Tarvonen - drums, timpani, 12-string, vocals (backing), handc\n",
      "<|doc_begin|> <|doc_id_begin|> 1346880 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|> jon - handclaps on \"Tulkaapa äijät!\"\\n Blastmor - handclaps\\n Avather - handclaps\\n Janne Perttilä - choi\n",
      "<|doc_begin|> <|doc_id_begin|> 4719159 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Zel Keh-ye Olya <|doc_title_end|> <|doc_body_begin|> Zel Keh-ye Olya (, also Romaniz\n",
      "<|doc_begin|> <|doc_id_begin|> 4719159 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  2006 census, its population was 750, in 134 families.\\n\\nReferences \\n\\nCategory:Populated places in Maku \n"
     ]
    }
   ],
   "source": [
    "for toks in docs_chunks:\n",
    "    s = tokten_to_text(toks)\n",
    "    print(s[:200].replace('\\n', '\\\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embs = model_encdec.run_enc_emb(target_chunks)\n",
    "docs_embs = model_encdec.run_enc_emb(docs_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.586205 0.576020 0.477831 F\n",
      "0.576322 0.482000 0.543113 F\n",
      "0.520205 0.474481 0.514628 F\n",
      "0.614104 0.664908 0.666830 F\n",
      "0.597907 0.575063 0.665326 F\n",
      "0.590845 0.581053 0.620674 F\n",
      "0.558637 0.512605 0.530244 F\n",
      "0.597204 0.632336 0.617147 F\n",
      "0.700274 0.638536 0.582114 T\n",
      "0.698899 0.835854 0.719015 T\n",
      "0.671124 0.757178 0.785849 T\n",
      "0.604881 0.599266 0.567953 F\n",
      "0.538754 0.573610 0.576608 F\n"
     ]
    }
   ],
   "source": [
    "cosine = False\n",
    "cosine = True\n",
    "print_dist(target_embs, docs_embs, target_mask, cosine=cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_encoder.src_word_emb.weight (50270, 256) -0.010897282 -9.1012805e-07 0.010897279\n",
      "vocab_encoder.layer_norm.weight (256,) -0.09958132 0.00054555107 0.099090874\n",
      "vocab_encoder.layer_norm.bias (256,) -0.099580586 -0.0005646632 0.09982468\n",
      "encoders.0.layer_stack.0.slf_attn.w_qs.weight (256, 256) -0.108248346 -4.838856e-05 0.10825213\n",
      "encoders.0.layer_stack.0.slf_attn.w_ks.weight (256, 256) -0.10825298 -0.00034150513 0.10825191\n",
      "encoders.0.layer_stack.0.slf_attn.w_vs.weight (256, 256) -0.10824595 -0.00038487592 0.10825164\n",
      "encoders.0.layer_stack.0.slf_attn.fc.weight (256, 256) -0.108249485 3.074905e-05 0.108251706\n",
      "encoders.0.layer_stack.0.slf_attn.layer_norm.weight (256,) -0.09877449 -0.0065938733 0.099637486\n",
      "encoders.0.layer_stack.0.slf_attn.layer_norm.bias (256,) -0.09863682 0.009567137 0.09970514\n",
      "encoders.0.layer_stack.0.pos_ffn.w_1.weight (1024, 256) -0.06846418 1.3598855e-05 0.068465136\n",
      "encoders.0.layer_stack.0.pos_ffn.w_1.bias (1024,) -0.09990684 -0.0018554593 0.099997476\n",
      "encoders.0.layer_stack.0.pos_ffn.w_2.weight (256, 1024) -0.06846372 -3.0715008e-05 0.068464555\n",
      "encoders.0.layer_stack.0.pos_ffn.w_2.bias (256,) -0.099359356 -0.0010241223 0.098882\n",
      "encoders.0.layer_stack.0.pos_ffn.layer_norm.weight (256,) -0.09894701 -0.005167881 0.099222064\n",
      "encoders.0.layer_stack.0.pos_ffn.layer_norm.bias (256,) -0.09900482 -0.0021914642 0.09997324\n",
      "encoders.0.w_em.weight (1, 100) -0.24298064 -0.029549427 0.23799461\n",
      "encoders.0.layer_norm.weight (256,) -0.09924728 -0.00084467675 0.09862106\n",
      "encoders.0.layer_norm.bias (256,) -0.09958658 -0.0026564198 0.09964998\n",
      "decoders.0.w.weight (256, 256) -0.1082508 5.9647056e-05 0.108252734\n",
      "decoders.0.layer_norm.weight (256,) -0.09583936 0.006473962 0.09993712\n",
      "decoders.0.layer_norm.bias (256,) -0.09881284 -0.00642048 0.09906087\n"
     ]
    }
   ],
   "source": [
    "inp_len = ds_loader.emb_chunk_size if ds_loader.fixed_size else calc_max_inp_size(ds_loader.emb_chunk_size)\n",
    "model_ranker_cfg = create_mllm_ranker_cfg(\n",
    "    n_vocab=len(tokenizer), inp_len=inp_len, d_word_wec=256,\n",
    "    n_levels=1, enc_n_layers=1, dec_n_layers=1,\n",
    "    n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024,\n",
    "    pad_idx=pad_tok, dropout_rate=0.1, enc_with_emb_mat=True,\n",
    ")\n",
    "\n",
    "model_ranker = MllmRanker(model_ranker_cfg).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_ranker = torch.load(ranker_snapshot_path)\n",
    "model_ranker.load_state_dict(checkpoint_ranker['model'])\n",
    "model_ranker.eval()\n",
    "del checkpoint_ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([13, 100]),\n",
       " torch.Size([1, 100]),\n",
       " tensor([False, False, False, False, False, False,  True,  True, False, False,\n",
       "         False, False, False]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 10\n",
    "batch = ds_loader.get_batch(i, train=True)\n",
    "docs_chunks, target_chunks, target_mask = batch.gen_tensors()\n",
    "docs_chunks.shape, target_chunks.shape, target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|query_begin|> Buddy Baumann (American football)Carl Buddy Baumann (August 4, 1900 – April 27, 1951) was an American football player in the National Football League. He played with the Racine Legion during the 1922 NFL season.\\n\\nReferences\\n\\nCategory:Sportspeople from Racine, Wisconsin\\nCategory:Players of American football from Wisconsin\\nCategory:Racine Legion players\\nCategory:1900 births\\nCategory:1951 deaths <|query_end|>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_target = tokten_to_text(target_chunks)\n",
    "s_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|doc_begin|> <|doc_id_begin|> 4043219 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> The Hamilton Spectator <|doc_title_end|> <|doc_body_begin|> The Hamilton Spectator, \n",
      "<|doc_begin|> <|doc_id_begin|> 4043219 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  the Spectator the first of the chain. The Southam chain was sold in 1998 to Conrad Black, who in turn \n",
      "<|doc_begin|> <|doc_id_begin|> 4043219 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  the surrounding communities of Grimsby and Beamsville. It also serves Brant County and Haldimand Coun\n",
      "<|doc_begin|> <|doc_id_begin|> 5623618 <|doc_id_end|> <|doc_offset_begin|> 5590 <|doc_offset_end|>  is powered by the 2.0L EcoBoost turbocharged I4 gasoline engine. All Fusion Hybrid and Fusion Energi\n",
      "<|doc_begin|> <|doc_id_begin|> 5623618 <|doc_id_end|> <|doc_offset_begin|> 5680 <|doc_offset_end|>  wheel drive (FWD), while select gasoline-only Fusion models are offered with all wheel drive. \\n\\nAll \n",
      "<|doc_begin|> <|doc_id_begin|> 5623618 <|doc_id_end|> <|doc_offset_begin|> 5770 <|doc_offset_end|>  the Ford CoPilot360+ Package. All models feature Ford's CoPilot360 driver assistance system, with mo\n",
      "<|doc_begin|> <|doc_id_begin|> 3716608 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Buddy Baumann (American football) <|doc_title_end|> <|doc_body_begin|> Carl Buddy Ba\n",
      "<|doc_begin|> <|doc_id_begin|> 3716608 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  deaths <|doc_body_end|> <|doc_end|>\n",
      "<|doc_begin|> <|doc_id_begin|> 1346880 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Suden uni <|doc_title_end|> <|doc_body_begin|> Suden uni (\"Wolf's Dream\") is the fir\n",
      "<|doc_begin|> <|doc_id_begin|> 1346880 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|> i - vocals, bass, handclaps, choir\\n Marko Tarvonen - drums, timpani, 12-string, vocals (backing), handc\n",
      "<|doc_begin|> <|doc_id_begin|> 1346880 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|> jon - handclaps on \"Tulkaapa äijät!\"\\n Blastmor - handclaps\\n Avather - handclaps\\n Janne Perttilä - choi\n",
      "<|doc_begin|> <|doc_id_begin|> 4719159 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Zel Keh-ye Olya <|doc_title_end|> <|doc_body_begin|> Zel Keh-ye Olya (, also Romaniz\n",
      "<|doc_begin|> <|doc_id_begin|> 4719159 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  2006 census, its population was 750, in 134 families.\\n\\nReferences \\n\\nCategory:Populated places in Maku \n"
     ]
    }
   ],
   "source": [
    "for toks in docs_chunks:\n",
    "    s = tokten_to_text(toks)\n",
    "    print(s[:200].replace('\\n', '\\\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embs = model_ranker.run_enc_emb(target_chunks)\n",
    "docs_embs = model_ranker.run_enc_emb(docs_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.443827 F\n",
      "0.403274 F\n",
      "0.597387 F\n",
      "0.276130 F\n",
      "0.164219 F\n",
      "0.261762 F\n",
      "0.911145 T\n",
      "0.207537 T\n",
      "0.228399 F\n",
      "0.270754 F\n",
      "0.173670 F\n",
      "0.248695 F\n",
      "0.355535 F\n"
     ]
    }
   ],
   "source": [
    "cosine = False\n",
    "cosine = True\n",
    "print_dist(target_embs, docs_embs, target_mask, cosine=cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n",
      "0.374339 F\n",
      "0.465199 F\n",
      "0.231861 F\n",
      "0.682488 F\n",
      "0.482204 F\n",
      "0.496427 F\n",
      "0.243842 T\n",
      "0.264784 T\n",
      "0.379053 F\n",
      "0.345734 F\n",
      "0.411226 F\n",
      "0.174130 F\n",
      "0.137890 F\n"
     ]
    }
   ],
   "source": [
    "txt = 'Hong Kong 1987'\n",
    "txt = 'Climate Classification system, Mays Landing has a humid subtropical climate, abbreviated \"Cfa\"'\n",
    "# txt = 'Climate Classification system'\n",
    "txt = 'War and Peace'\n",
    "txt = 'Bandar Express, Ichhamati Express and Benapole Express'\n",
    "txt = 'Rick Anderson'\n",
    "txt = 'Makangarawe Temeke ward'\n",
    "# txt = 'graph sandwich'\n",
    "txt = 'james barry'\n",
    "txt = 'erigeron'\n",
    "txt = 'Dillon Gabriel america'\n",
    "txt = 'East Willy B'\n",
    "txt = 'Fusion Hybrid EcoBoost Gasoline'\n",
    "# txt = 'The graph sandwich problem for property Π is defined as follows:'\n",
    "cosine = True\n",
    "txt_tokens = text_to_tokens(txt, qbeg_tok=qbeg_tok, qend_tok=qend_tok)\n",
    "# txt_tokens = txt_tokens.repeat(3, 1)\n",
    "print(txt_tokens.shape)\n",
    "txt_embs = model_ranker.run_enc_emb(txt_tokens)\n",
    "print_dist(txt_embs, docs_embs, target_mask, cosine=cosine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.010951',\n",
       " '0.058801',\n",
       " '0.001228',\n",
       " '0.615539',\n",
       " '0.022415',\n",
       " '0.051561',\n",
       " '0.004969',\n",
       " '0.230985',\n",
       " '0.000338',\n",
       " '0.000157',\n",
       " '0.001883',\n",
       " '0.000541',\n",
       " '0.000633']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rank = model_ranker.run_qs_infer(docs_chunks, txt_tokens)\n",
    "rank_str = [f'{r:.06f}' for r in rank.flatten()]\n",
    "rank_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442500"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(1).un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8737, 0.8907, 0.7371, 0.5201, 0.4101, 0.8237, 0.7342, 0.8183, 0.8694,\n",
       "         0.6263, 0.6608, 0.6087, 0.2565, 0.3135, 0.3250]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = model_ranker(txt_tokens, docs_chunks)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6538e-21, 3.7294e-11, 2.4412e-19, 3.4020e-23, 7.5630e-20, 3.8663e-25,\n",
       "         1.3986e-18, 7.2614e-22, 1.0000e+00, 1.0000e+00, 1.0000e+00, 4.7166e-09,\n",
       "         1.9997e-11, 1.3684e-08]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = model_ranker(target_chunks, docs_chunks)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device1 = torch.device('cpu')\n",
    "device2 = torch.device('cuda')\n",
    "device3 = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(device1 == device2)\n",
    "print(device2 == device3)\n",
    "print(device1 == device3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cpu', str)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device1.type, type(device1.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0.5,  0.5],\n",
       "       [ 1.7,  1.7,  1.7],\n",
       "       [-1. ,  7. , 33. ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "toks = [\n",
    "    np.ones(3) * 0.5,\n",
    "    np.ones(3) * 1.7,\n",
    "    np.array([-1, 7, 33])\n",
    "]\n",
    "np.stack(toks, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0.5,  0.5],\n",
       "       [ 1.7,  1.7,  1.7],\n",
       "       [-1. ,  7. , 33. ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(np.array(toks), np.stack(toks, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
