{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import Optional\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pydantic_yaml import parse_yaml_file_as\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import GPT2Tokenizer, AddedToken, PreTrainedTokenizer\n",
    "\n",
    "from mllm.data.wiki.dswiki import WikiDsLoader\n",
    "from mllm.exp.args import TOKENIZER_CFG_FNAME, ENCDEC_MODEL_CFG_FNAME, RANKER_MODEL_CFG_FNAME\n",
    "from mllm.model.mllm_encdec import MllmEncdecLevel\n",
    "from mllm.model.mllm_ranker import MllmRankerLevel\n",
    "from mllm.config.model import TokenizerCfg, MllmEncdecCfg, MllmRankerCfg\n",
    "from mllm.tokenization.chunk_tokenizer import calc_max_inp_size, gen_all_tokens, ChunkTokenizer, tokenizer_from_config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(os.path.expandvars('$HOME')) / 'data'\n",
    "DS_DIR_PATH = DATA_PATH / 'wiki_20200501_en' / 'ch_100_fixed'\n",
    "\n",
    "# TRAIN_ENCDEC_PATH = DATA_PATH / 'train_mllm_encdec'\n",
    "# TRAIN_RANKER_PATH = DATA_PATH / 'train_mllm_ranker_qrels'\n",
    "# encdec_subdir = 'encdec-20240718_221554-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240903_215749-msmarco-fever'\n",
    "\n",
    "TRAIN_ENCDEC_PATH = DATA_PATH / 'train_mllm_encdec_0'\n",
    "TRAIN_RANKER_PATH = DATA_PATH / 'train_mllm_ranker_qrels_0'\n",
    "encdec_subdir = 'encdec-lvl0-20241029_140645-wiki_20200501_en-ch_100_fixed-enc-lrs3-embmatFalse-d256-h8-dec-lrs3-seqlen100-d256-h8-vocdecTrue'\n",
    "ranker_subdir = 'ranker-lvl0-20241030_230226-msmarco-fever-enc-lrs3-embmatFalse-d256-h8-dec-lrs0-d256-h8'\n",
    "ranker_subdir = 'ranker-lvl0-20241031_215643-msmarco-fever-enc-lrs3-embmatFalse-d256-h8-dec-lrs3-d256-h8'\n",
    "ranker_subdir = 'ranker-lvl0-20241103_130114-msmarco-fever-enc-lrs3-embmatFalse-d256-h8-dec-lrs3-d256-h8'\n",
    "\n",
    "encdec_train_path = TRAIN_ENCDEC_PATH / encdec_subdir\n",
    "ranker_train_path = TRAIN_RANKER_PATH / ranker_subdir\n",
    "encdec_snapshot_fpath = encdec_train_path / 'best.pth'\n",
    "ranker_snapshot_fpath = ranker_train_path / 'best.pth'\n",
    "encdec_tkz_cfg_fpath = encdec_train_path / TOKENIZER_CFG_FNAME\n",
    "ranker_tkz_cfg_fpath = ranker_train_path / TOKENIZER_CFG_FNAME\n",
    "encdec_model_cfg_fpath = encdec_train_path / ENCDEC_MODEL_CFG_FNAME\n",
    "ranker_model_cfg_fpath = ranker_train_path / RANKER_MODEL_CFG_FNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "docs_batch_size = 5\n",
    "max_chunks_per_doc = 3\n",
    "model_level = 0\n",
    "device_name = 'cpu'\n",
    "# device_name = 'cuda'\n",
    "\n",
    "device = torch.device(device_name)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encdec_tkz_cfg = parse_yaml_file_as(TokenizerCfg, encdec_tkz_cfg_fpath)\n",
    "ranker_tkz_cfg = parse_yaml_file_as(TokenizerCfg, ranker_tkz_cfg_fpath)\n",
    "assert encdec_tkz_cfg == ranker_tkz_cfg\n",
    "tokenizer = tokenizer_from_config(encdec_tkz_cfg)\n",
    "tok_dict = encdec_tkz_cfg.custom_tokens\n",
    "pad_tok, qbeg_tok, qend_tok = tok_dict['pad'].ind, tok_dict['query_begin'].ind, tok_dict['query_end'].ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cache from /home/misha/data/wiki_20200501_en/ch_100_fixed/.mllm/ds.csv\n",
      "Loaded dataset size: 50989207\n"
     ]
    }
   ],
   "source": [
    "ds_loader = WikiDsLoader(\n",
    "    ds_path=DS_DIR_PATH, docs_batch_size=docs_batch_size, max_chunks_per_doc=max_chunks_per_doc,\n",
    "    pad_tok=pad_tok, qbeg_tok=qbeg_tok, qend_tok=qend_tok, device=device,\n",
    ")\n",
    "ds_loader.shuffle(train=True)\n",
    "ds_loader.shuffle(train=False)\n",
    "inp_len = ds_loader.emb_chunk_size if ds_loader.fixed_size else calc_max_inp_size(ds_loader.emb_chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_text(tokens: torch.Tensor) -> str:\n",
    "    tokens = tokens.flatten()\n",
    "    tokens = tokens[tokens != pad_tok]\n",
    "    tokens = list(tokens)\n",
    "    s = tokenizer.decode(tokens)\n",
    "    return s\n",
    "\n",
    "def distance(x: np.ndarray, y: np.ndarray, cosine: bool = False):\n",
    "    if not cosine:\n",
    "        return np.linalg.norm(x - y)\n",
    "    x_norm, y_norm = np.linalg.norm(x), np.linalg.norm(y)\n",
    "    return np.sum(x * y) / (x_norm * y_norm)\n",
    "\n",
    "def text_to_tokens(s: str, qbeg_tok: Optional[int] = None, qend_tok: Optional[int] = None) -> torch.Tensor:\n",
    "    tokens = tokenizer(s)['input_ids']\n",
    "    if qbeg_tok is not None:\n",
    "        assert qend_tok is not None\n",
    "        tokens = [qbeg_tok, *tokens, qend_tok]\n",
    "    n_tokens = len(tokens)\n",
    "    n_padded = n_tokens // inp_len + (n_tokens % inp_len > 0)\n",
    "    res = np.full((n_padded * inp_len, ), pad_tok, dtype=np.int32)\n",
    "    res[:n_tokens] = tokens\n",
    "    res = torch.from_numpy(res).to(device)\n",
    "    res = res.reshape(n_padded, inp_len)\n",
    "    return res\n",
    "\n",
    "def print_dist(target_embs: torch.Tensor, docs_embs: torch.Tensor, target_mask: torch.Tensor, cosine: bool = True):\n",
    "    for i, docs_emb in enumerate(docs_embs.detach().numpy()):\n",
    "        for target_emb in target_embs.detach().numpy():\n",
    "            dist = distance(target_emb, docs_emb, cosine)\n",
    "            print(f'{dist:0.6f} ', end='')\n",
    "        sfx = 'T' if target_mask[i] else 'F'\n",
    "        print(sfx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_encoder.src_word_emb.weight (50271, 256) -0.010897174 1.3329893e-06 0.010897173\n",
      "vocab_encoder.layer_norm.weight (256,) -0.098980986 0.0022841117 0.09967321\n",
      "vocab_encoder.layer_norm.bias (256,) -0.099942826 -0.0019740022 0.09916983\n",
      "vocab_decoder.word_prj.weight (50271, 256) -0.010897174 -4.0607728e-07 0.010897173\n",
      "encoder.a_em () 0.020802975 0.020802975 0.020802975\n",
      "encoder.layer_stack.0.slf_attn.w_qs.weight (256, 256) -0.10825261 0.00022600047 0.10825103\n",
      "encoder.layer_stack.0.slf_attn.w_ks.weight (256, 256) -0.10824928 0.00038556458 0.10824711\n",
      "encoder.layer_stack.0.slf_attn.w_vs.weight (256, 256) -0.108251125 0.0004757878 0.10825291\n",
      "encoder.layer_stack.0.slf_attn.fc.weight (256, 256) -0.1082521 0.00055551186 0.108248554\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.weight (256,) -0.09971508 0.002642855 0.099901095\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.bias (256,) -0.09900289 0.0011596174 0.099956356\n",
      "encoder.layer_stack.0.pos_ffn.w_1.weight (1024, 256) -0.06846522 -7.1032286e-05 0.06846505\n",
      "encoder.layer_stack.0.pos_ffn.w_1.bias (1024,) -0.09957335 0.0024186014 0.09993227\n",
      "encoder.layer_stack.0.pos_ffn.w_2.weight (256, 1024) -0.0684653 3.622981e-05 0.06846498\n",
      "encoder.layer_stack.0.pos_ffn.w_2.bias (256,) -0.099909954 -0.009316646 0.09956347\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.weight (256,) -0.0994051 -0.0028513444 0.09944532\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.bias (256,) -0.09869789 0.0008950412 0.09902858\n",
      "encoder.layer_stack.1.slf_attn.w_qs.weight (256, 256) -0.108252436 4.682703e-05 0.10825262\n",
      "encoder.layer_stack.1.slf_attn.w_ks.weight (256, 256) -0.10825196 9.718306e-05 0.10825099\n",
      "encoder.layer_stack.1.slf_attn.w_vs.weight (256, 256) -0.10825054 4.7251364e-05 0.10825104\n",
      "encoder.layer_stack.1.slf_attn.fc.weight (256, 256) -0.10825266 -0.00012322649 0.108251706\n",
      "encoder.layer_stack.1.slf_attn.layer_norm.weight (256,) -0.09938486 -0.0041191755 0.0993109\n",
      "encoder.layer_stack.1.slf_attn.layer_norm.bias (256,) -0.097757496 0.0035142712 0.09976069\n",
      "encoder.layer_stack.1.pos_ffn.w_1.weight (1024, 256) -0.06846526 -1.04301125e-05 0.068464115\n",
      "encoder.layer_stack.1.pos_ffn.w_1.bias (1024,) -0.09967705 -0.0022791494 0.09936507\n",
      "encoder.layer_stack.1.pos_ffn.w_2.weight (256, 1024) -0.06846335 -0.00011862733 0.068465255\n",
      "encoder.layer_stack.1.pos_ffn.w_2.bias (256,) -0.0970843 0.004398075 0.099410355\n",
      "encoder.layer_stack.1.pos_ffn.layer_norm.weight (256,) -0.09987394 0.005703618 0.09982306\n",
      "encoder.layer_stack.1.pos_ffn.layer_norm.bias (256,) -0.09980687 -0.00057836133 0.098233394\n",
      "encoder.layer_stack.2.slf_attn.w_qs.weight (256, 256) -0.108252645 -0.00023808911 0.1082531\n",
      "encoder.layer_stack.2.slf_attn.w_ks.weight (256, 256) -0.108249485 0.00028024544 0.10824418\n",
      "encoder.layer_stack.2.slf_attn.w_vs.weight (256, 256) -0.10824975 3.165877e-05 0.10825247\n",
      "encoder.layer_stack.2.slf_attn.fc.weight (256, 256) -0.10825201 0.00037180466 0.10825143\n",
      "encoder.layer_stack.2.slf_attn.layer_norm.weight (256,) -0.099547915 0.0005792212 0.09990895\n",
      "encoder.layer_stack.2.slf_attn.layer_norm.bias (256,) -0.09994896 -0.0011783291 0.099787906\n",
      "encoder.layer_stack.2.pos_ffn.w_1.weight (1024, 256) -0.06846255 -9.181084e-05 0.068463966\n",
      "encoder.layer_stack.2.pos_ffn.w_1.bias (1024,) -0.099951886 3.6846264e-05 0.09989989\n",
      "encoder.layer_stack.2.pos_ffn.w_2.weight (256, 1024) -0.06846484 1.9208273e-05 0.06846478\n",
      "encoder.layer_stack.2.pos_ffn.w_2.bias (256,) -0.09975306 0.0019264494 0.09988727\n",
      "encoder.layer_stack.2.pos_ffn.layer_norm.weight (256,) -0.0999025 0.0026281194 0.09990095\n",
      "encoder.layer_stack.2.pos_ffn.layer_norm.bias (256,) -0.09945929 0.0014598421 0.099707164\n",
      "encoder.layer_norm.weight (256,) -0.09852153 0.0051281652 0.0974829\n",
      "encoder.layer_norm.bias (256,) -0.09996321 0.0023917197 0.09957393\n",
      "decoder.A_emb2sec (100, 256, 256) -0.008113913 7.1878685e-07 0.008113912\n",
      "decoder.att_layers.0.slf_attn.w_qs.weight (256, 256) -0.10825141 1.0570664e-05 0.108252205\n",
      "decoder.att_layers.0.slf_attn.w_ks.weight (256, 256) -0.10825169 0.00018526806 0.10824415\n",
      "decoder.att_layers.0.slf_attn.w_vs.weight (256, 256) -0.10824286 -0.0001902228 0.10825157\n",
      "decoder.att_layers.0.slf_attn.fc.weight (256, 256) -0.108248204 4.8770744e-08 0.10824645\n",
      "decoder.att_layers.0.slf_attn.layer_norm.weight (256,) -0.099659435 -0.0060968604 0.09969789\n",
      "decoder.att_layers.0.slf_attn.layer_norm.bias (256,) -0.099553525 -0.007048627 0.09863832\n",
      "decoder.att_layers.0.pos_ffn.w_1.weight (1024, 256) -0.06846437 1.1455464e-05 0.0684653\n",
      "decoder.att_layers.0.pos_ffn.w_1.bias (1024,) -0.09996312 -0.001968225 0.09987203\n",
      "decoder.att_layers.0.pos_ffn.w_2.weight (256, 1024) -0.06846507 9.933675e-06 0.06846456\n",
      "decoder.att_layers.0.pos_ffn.w_2.bias (256,) -0.09827282 -0.0015565176 0.09964855\n",
      "decoder.att_layers.0.pos_ffn.layer_norm.weight (256,) -0.09967517 0.0015801755 0.09992095\n",
      "decoder.att_layers.0.pos_ffn.layer_norm.bias (256,) -0.098437026 -0.0029096927 0.099077635\n",
      "decoder.att_layers.1.slf_attn.w_qs.weight (256, 256) -0.10823877 -5.7639e-05 0.108247854\n",
      "decoder.att_layers.1.slf_attn.w_ks.weight (256, 256) -0.10825005 0.00013923699 0.10825027\n",
      "decoder.att_layers.1.slf_attn.w_vs.weight (256, 256) -0.108241856 -0.00053067796 0.10825039\n",
      "decoder.att_layers.1.slf_attn.fc.weight (256, 256) -0.10824843 0.0002305953 0.10825293\n",
      "decoder.att_layers.1.slf_attn.layer_norm.weight (256,) -0.09948619 0.0036370507 0.09974227\n",
      "decoder.att_layers.1.slf_attn.layer_norm.bias (256,) -0.099321604 -0.0023195972 0.09913667\n",
      "decoder.att_layers.1.pos_ffn.w_1.weight (1024, 256) -0.06846428 2.5049205e-05 0.06846457\n",
      "decoder.att_layers.1.pos_ffn.w_1.bias (1024,) -0.09965696 0.00044023752 0.099076405\n",
      "decoder.att_layers.1.pos_ffn.w_2.weight (256, 1024) -0.06846497 -6.569538e-05 0.06846366\n",
      "decoder.att_layers.1.pos_ffn.w_2.bias (256,) -0.099656425 0.0023223427 0.09839851\n",
      "decoder.att_layers.1.pos_ffn.layer_norm.weight (256,) -0.09986656 -0.00065249077 0.09993265\n",
      "decoder.att_layers.1.pos_ffn.layer_norm.bias (256,) -0.09990175 0.0011808 0.09807978\n",
      "decoder.att_layers.2.slf_attn.w_qs.weight (256, 256) -0.10824806 0.00033814303 0.10825238\n",
      "decoder.att_layers.2.slf_attn.w_ks.weight (256, 256) -0.10825314 -0.00028003828 0.10825138\n",
      "decoder.att_layers.2.slf_attn.w_vs.weight (256, 256) -0.108252436 6.0512477e-05 0.10825116\n",
      "decoder.att_layers.2.slf_attn.fc.weight (256, 256) -0.10825254 0.00014434672 0.10825247\n",
      "decoder.att_layers.2.slf_attn.layer_norm.weight (256,) -0.09981592 -0.004061534 0.09907385\n",
      "decoder.att_layers.2.slf_attn.layer_norm.bias (256,) -0.09941959 -0.0018049253 0.09936048\n",
      "decoder.att_layers.2.pos_ffn.w_1.weight (1024, 256) -0.06846471 -1.5055208e-05 0.068464756\n",
      "decoder.att_layers.2.pos_ffn.w_1.bias (1024,) -0.09975982 0.0028528227 0.09998542\n",
      "decoder.att_layers.2.pos_ffn.w_2.weight (256, 1024) -0.068465166 5.2228716e-05 0.068464644\n",
      "decoder.att_layers.2.pos_ffn.w_2.bias (256,) -0.09951072 0.0021449202 0.09999108\n",
      "decoder.att_layers.2.pos_ffn.layer_norm.weight (256,) -0.098003924 0.0045614205 0.09988636\n",
      "decoder.att_layers.2.pos_ffn.layer_norm.bias (256,) -0.09972209 0.0020569619 0.09873738\n"
     ]
    }
   ],
   "source": [
    "model_encdec_cfg = parse_yaml_file_as(MllmEncdecCfg, encdec_model_cfg_fpath)\n",
    "model_encdec = MllmEncdecLevel(model_encdec_cfg, model_level).to(device)\n",
    "checkpoint_encdec = torch.load(encdec_snapshot_fpath)\n",
    "model_encdec.load_state_dict(checkpoint_encdec['model'], strict=False)\n",
    "model_encdec.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496,   612, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267]],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_tokens('Hello there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14, 100]),\n",
       " torch.Size([2, 100]),\n",
       " tensor([False, False, False,  True,  True, False, False, False, False, False,\n",
       "         False, False, False, False]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 10\n",
    "batch = ds_loader.get_batch(i, train=True)\n",
    "docs_chunks, target_chunks, target_mask = batch.gen_tensors()\n",
    "docs_chunks.shape, target_chunks.shape, target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|query_begin|> 1945 Paris–RoubaixThe 1945 Paris–Roubaix was the 43rd\\xa0edition of the Paris–Roubaix, a classic one-day cycle race in France. The single day event was held on 9 April 1945 and stretched  from Paris to the finish at Roubaix Velodrome. The winner was Paul Maye from France.\\n\\nResults\\n\\nReferences\\n\\nCategory:Paris–Roubaix\\nCategory:1945 in road cycling\\nCategory:1945 in French sport <|query_end|>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_target = tokens_to_text(target_chunks)\n",
    "s_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|doc_begin|> <|doc_id_begin|> 4838950 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Maine State Route 149 <|doc_title_end|> <|doc_body_begin|> State Route 149 (SR 149) \n",
      "<|doc_begin|> <|doc_id_begin|> 4838950 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  begins at an intersection in the Fairbanks neighborhood of Farmington at SR 4. The road, named South S\n",
      "<|doc_begin|> <|doc_id_begin|> 4838950 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|> on Hill Road). SR 149 and SR 234 form a concurrency and travel into downtown Strong along Norton Hill \n",
      "<|doc_begin|> <|doc_id_begin|> 2020592 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> 1945 Paris–Roubaix <|doc_title_end|> <|doc_body_begin|> The 1945 Paris–Roubaix was t\n",
      "<|doc_begin|> <|doc_id_begin|> 2020592 <|doc_id_end|> <|doc_offset_begin|> 92 <|doc_offset_end|> baix\\nCategory:1945 in road cycling\\nCategory:1945 in French sport <|doc_body_end|> <|doc_end|>\n",
      "<|doc_begin|> <|doc_id_begin|> 4396956 <|doc_id_end|> <|doc_offset_begin|> 637 <|doc_offset_end|> tsung, Andrew Putnam, Chez Reavie\\nAaron Wise did not play.\\n\\n5. Top 30 from the Race to Dubai as of 15 \n",
      "<|doc_begin|> <|doc_id_begin|> 4396956 <|doc_id_end|> <|doc_offset_begin|> 727 <|doc_offset_end|>  Andy Sullivan, Julian Suri, Matt Wallace\\n\\nChris Wood was a late withdrawal with a neck injury and was\n",
      "<|doc_begin|> <|doc_id_begin|> 4396956 <|doc_id_end|> <|doc_offset_begin|> 818 <|doc_offset_end|>  October\\nYuta Ikeda, Yuki Inamori\\nShugo Imahira did not play.\\n\\n8. The leading two available players fr\n",
      "<|doc_begin|> <|doc_id_begin|> 5268754 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  Qulla and related specifically to the native Qulla Quechuas who primarily resided in areas such as Coc\n",
      "<|doc_begin|> <|doc_id_begin|> 5268754 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  Qullasuyu\" (or Qullana Suyu Marka) which would incorporate a territory similar to the former Tawantin\n",
      "<|doc_begin|> <|doc_id_begin|> 5268754 <|doc_id_end|> <|doc_offset_begin|> 273 <|doc_offset_end|> yu encompassed the Bolivian Altiplano and much of the southern Andes, running down into Argentina and \n",
      "<|doc_begin|> <|doc_id_begin|> 250076 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Peter Cartwright (actor) <|doc_title_end|> <|doc_body_begin|> Peter Cartwright (30 Au\n",
      "<|doc_begin|> <|doc_id_begin|> 250076 <|doc_id_end|> <|doc_offset_begin|> 92 <|doc_offset_end|>  Britain in 1959 and studied at RADA.\\n\\nHe was best known in South Africa for a series of television comm\n",
      "<|doc_begin|> <|doc_id_begin|> 250076 <|doc_id_end|> <|doc_offset_begin|> 184 <|doc_offset_end|> ole of the Bailey, Danger UXB,Yes Prime Minister, Casualty, Shackleton, Longitude, The Vicar of Dibley,\n"
     ]
    }
   ],
   "source": [
    "for toks in docs_chunks:\n",
    "    s = tokens_to_text(toks)\n",
    "    print(s[:200].replace('\\n', '\\\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embs = model_encdec.run_enc_emb(target_chunks)\n",
    "docs_embs = model_encdec.run_enc_emb(docs_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050723 0.140819 F\n",
      "0.177963 0.191794 F\n",
      "0.007825 0.115876 F\n",
      "0.217006 0.237375 T\n",
      "0.230547 0.664481 T\n",
      "0.028282 0.243856 F\n",
      "0.138972 0.150037 F\n",
      "0.256995 0.220254 F\n",
      "0.127542 0.185235 F\n",
      "0.113792 0.236069 F\n",
      "0.121711 0.241804 F\n",
      "0.225511 0.197613 F\n",
      "0.193322 0.239168 F\n",
      "0.136008 0.277026 F\n"
     ]
    }
   ],
   "source": [
    "cosine = False\n",
    "cosine = True\n",
    "print_dist(target_embs, docs_embs, target_mask, cosine=cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_encoder.src_word_emb.weight (50271, 256) -0.010897174 2.8711395e-07 0.010897168\n",
      "vocab_encoder.layer_norm.weight (256,) -0.09975773 -0.0026611888 0.099174134\n",
      "vocab_encoder.layer_norm.bias (256,) -0.099611916 -0.003419092 0.0988902\n",
      "encoder.a_em () -0.06363992 -0.06363992 -0.06363992\n",
      "encoder.layer_stack.0.slf_attn.w_qs.weight (256, 256) -0.108250596 -6.590552e-05 0.10825305\n",
      "encoder.layer_stack.0.slf_attn.w_ks.weight (256, 256) -0.1082521 6.1234125e-05 0.108250014\n",
      "encoder.layer_stack.0.slf_attn.w_vs.weight (256, 256) -0.10825094 0.00028304648 0.10825305\n",
      "encoder.layer_stack.0.slf_attn.fc.weight (256, 256) -0.108244695 -0.00019191732 0.10824863\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.weight (256,) -0.09965586 0.0043836436 0.09980502\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.bias (256,) -0.09824039 0.007093214 0.0999532\n",
      "encoder.layer_stack.0.pos_ffn.w_1.weight (1024, 256) -0.06846482 -5.6530007e-05 0.06846518\n",
      "encoder.layer_stack.0.pos_ffn.w_1.bias (1024,) -0.099701345 -0.0015187723 0.09982433\n",
      "encoder.layer_stack.0.pos_ffn.w_2.weight (256, 1024) -0.06846493 -9.398558e-05 0.06846433\n",
      "encoder.layer_stack.0.pos_ffn.w_2.bias (256,) -0.09850891 0.0018337481 0.09958031\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.weight (256,) -0.09941693 -0.00352176 0.098855756\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.bias (256,) -0.09843438 0.004596854 0.098781906\n",
      "encoder.layer_stack.1.slf_attn.w_qs.weight (256, 256) -0.10825129 -0.00022796882 0.10825044\n",
      "encoder.layer_stack.1.slf_attn.w_ks.weight (256, 256) -0.10824672 -1.1277647e-05 0.10825058\n",
      "encoder.layer_stack.1.slf_attn.w_vs.weight (256, 256) -0.10824761 -0.000107518405 0.10825282\n",
      "encoder.layer_stack.1.slf_attn.fc.weight (256, 256) -0.10825132 -7.634238e-05 0.10824854\n",
      "encoder.layer_stack.1.slf_attn.layer_norm.weight (256,) -0.09971573 -0.0008259942 0.099300936\n",
      "encoder.layer_stack.1.slf_attn.layer_norm.bias (256,) -0.09627926 0.00913398 0.09985211\n",
      "encoder.layer_stack.1.pos_ffn.w_1.weight (1024, 256) -0.06846406 1.2050987e-06 0.06846501\n",
      "encoder.layer_stack.1.pos_ffn.w_1.bias (1024,) -0.09949261 -0.0034271488 0.099512234\n",
      "encoder.layer_stack.1.pos_ffn.w_2.weight (256, 1024) -0.06846523 -7.864842e-05 0.0684653\n",
      "encoder.layer_stack.1.pos_ffn.w_2.bias (256,) -0.09809706 0.0027198691 0.09974729\n",
      "encoder.layer_stack.1.pos_ffn.layer_norm.weight (256,) -0.09803923 -2.649508e-05 0.099291146\n",
      "encoder.layer_stack.1.pos_ffn.layer_norm.bias (256,) -0.09908692 -0.003143331 0.09901791\n",
      "encoder.layer_stack.2.slf_attn.w_qs.weight (256, 256) -0.10824762 -0.00037692944 0.10824889\n",
      "encoder.layer_stack.2.slf_attn.w_ks.weight (256, 256) -0.10825233 0.00016675692 0.10824954\n",
      "encoder.layer_stack.2.slf_attn.w_vs.weight (256, 256) -0.10824434 0.00015211033 0.10825215\n",
      "encoder.layer_stack.2.slf_attn.fc.weight (256, 256) -0.10824833 2.2841501e-05 0.10825166\n",
      "encoder.layer_stack.2.slf_attn.layer_norm.weight (256,) -0.099813044 -1.615961e-05 0.09911547\n",
      "encoder.layer_stack.2.slf_attn.layer_norm.bias (256,) -0.09934373 -0.0023431676 0.09998436\n",
      "encoder.layer_stack.2.pos_ffn.w_1.weight (1024, 256) -0.0684653 -0.0002105448 0.068465054\n",
      "encoder.layer_stack.2.pos_ffn.w_1.bias (1024,) -0.09972197 0.002843818 0.09993984\n",
      "encoder.layer_stack.2.pos_ffn.w_2.weight (256, 1024) -0.0684652 -2.9832197e-05 0.06846509\n",
      "encoder.layer_stack.2.pos_ffn.w_2.bias (256,) -0.09943374 -0.002250409 0.09961816\n",
      "encoder.layer_stack.2.pos_ffn.layer_norm.weight (256,) -0.09940785 -0.0031066192 0.09798489\n",
      "encoder.layer_stack.2.pos_ffn.layer_norm.bias (256,) -0.09958463 0.002407684 0.09908841\n",
      "encoder.layer_norm.weight (256,) -0.099547744 -0.0043449495 0.09990417\n",
      "encoder.layer_norm.bias (256,) -0.098595776 0.0010551829 0.09956359\n",
      "decoder.att_layers.0.slf_attn.w_qs.weight (256, 256) -0.10825303 0.00016558234 0.10824947\n",
      "decoder.att_layers.0.slf_attn.w_ks.weight (256, 256) -0.108243376 -0.0001836656 0.1082484\n",
      "decoder.att_layers.0.slf_attn.w_vs.weight (256, 256) -0.10825125 -9.773843e-05 0.10825143\n",
      "decoder.att_layers.0.slf_attn.fc.weight (256, 256) -0.10825227 0.00015836 0.1082528\n",
      "decoder.att_layers.0.slf_attn.layer_norm.weight (256,) -0.09951263 -0.0029148462 0.09996382\n",
      "decoder.att_layers.0.slf_attn.layer_norm.bias (256,) -0.096184194 -0.0055850553 0.09926219\n",
      "decoder.att_layers.0.pos_ffn.w_1.weight (1024, 256) -0.068465166 3.6212023e-05 0.06846509\n",
      "decoder.att_layers.0.pos_ffn.w_1.bias (1024,) -0.09991312 0.0017472026 0.0995688\n",
      "decoder.att_layers.0.pos_ffn.w_2.weight (256, 1024) -0.06846506 -4.8816022e-05 0.06846513\n",
      "decoder.att_layers.0.pos_ffn.w_2.bias (256,) -0.09958183 -0.0057274187 0.099101424\n",
      "decoder.att_layers.0.pos_ffn.layer_norm.weight (256,) -0.09977486 -0.0013736895 0.099699676\n",
      "decoder.att_layers.0.pos_ffn.layer_norm.bias (256,) -0.09973104 -0.0013133583 0.09983715\n",
      "decoder.att_layers.1.slf_attn.w_qs.weight (256, 256) -0.10825314 -0.00062912394 0.10824665\n",
      "decoder.att_layers.1.slf_attn.w_ks.weight (256, 256) -0.10825215 0.00024985324 0.108251184\n",
      "decoder.att_layers.1.slf_attn.w_vs.weight (256, 256) -0.108252786 0.00044362852 0.108252645\n",
      "decoder.att_layers.1.slf_attn.fc.weight (256, 256) -0.10825268 0.0001536732 0.10825169\n",
      "decoder.att_layers.1.slf_attn.layer_norm.weight (256,) -0.09971907 -0.004044026 0.09966115\n",
      "decoder.att_layers.1.slf_attn.layer_norm.bias (256,) -0.09898194 0.0012426043 0.099755876\n",
      "decoder.att_layers.1.pos_ffn.w_1.weight (1024, 256) -0.06846484 -8.843129e-05 0.06846498\n",
      "decoder.att_layers.1.pos_ffn.w_1.bias (1024,) -0.099532 -0.00039334456 0.09994133\n",
      "decoder.att_layers.1.pos_ffn.w_2.weight (256, 1024) -0.06846479 -4.640561e-05 0.068465255\n",
      "decoder.att_layers.1.pos_ffn.w_2.bias (256,) -0.099366605 0.0035381247 0.09877115\n",
      "decoder.att_layers.1.pos_ffn.layer_norm.weight (256,) -0.09921664 0.0005266005 0.09914919\n",
      "decoder.att_layers.1.pos_ffn.layer_norm.bias (256,) -0.09900304 0.0010239799 0.09657792\n",
      "decoder.att_layers.2.slf_attn.w_qs.weight (256, 256) -0.10825259 -0.00011974651 0.10824995\n",
      "decoder.att_layers.2.slf_attn.w_ks.weight (256, 256) -0.10824764 -4.583608e-05 0.10825277\n",
      "decoder.att_layers.2.slf_attn.w_vs.weight (256, 256) -0.10825215 -0.00011659313 0.108250655\n",
      "decoder.att_layers.2.slf_attn.fc.weight (256, 256) -0.108247265 4.521115e-05 0.10825296\n",
      "decoder.att_layers.2.slf_attn.layer_norm.weight (256,) -0.09855187 0.00027052697 0.09958953\n",
      "decoder.att_layers.2.slf_attn.layer_norm.bias (256,) -0.09943258 0.0031881137 0.09987902\n",
      "decoder.att_layers.2.pos_ffn.w_1.weight (1024, 256) -0.06846479 -2.9678617e-05 0.06846517\n",
      "decoder.att_layers.2.pos_ffn.w_1.bias (1024,) -0.0991775 0.0011571835 0.09985782\n",
      "decoder.att_layers.2.pos_ffn.w_2.weight (256, 1024) -0.06846497 -3.4050445e-05 0.0684647\n",
      "decoder.att_layers.2.pos_ffn.w_2.bias (256,) -0.09739591 -0.0006897899 0.09964504\n",
      "decoder.att_layers.2.pos_ffn.layer_norm.weight (256,) -0.099952236 0.0028003352 0.09904412\n",
      "decoder.att_layers.2.pos_ffn.layer_norm.bias (256,) -0.09998895 -0.0056272163 0.09933462\n",
      "decoder.w.weight (256, 256) -0.10825026 -7.8344194e-05 0.10825235\n",
      "decoder.layer_norm.weight (256,) -0.099923566 -0.0012064266 0.09866189\n",
      "decoder.layer_norm.bias (256,) -0.09744872 -0.0050605284 0.09992565\n"
     ]
    }
   ],
   "source": [
    "inp_len = ds_loader.emb_chunk_size if ds_loader.fixed_size else calc_max_inp_size(ds_loader.emb_chunk_size)\n",
    "model_ranker_cfg = parse_yaml_file_as(MllmRankerCfg, ranker_model_cfg_fpath)\n",
    "model_ranker = MllmRankerLevel(model_ranker_cfg, model_level).to(device)\n",
    "checkpoint_ranker = torch.load(ranker_snapshot_fpath)\n",
    "model_ranker.load_state_dict(checkpoint_ranker['model'])\n",
    "model_ranker.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14, 100]),\n",
       " torch.Size([1, 100]),\n",
       " tensor([False, False, False, False, False, False,  True,  True, False, False,\n",
       "         False, False, False, False]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 12\n",
    "batch = ds_loader.get_batch(i, train=True)\n",
    "docs_chunks, target_chunks, target_mask = batch.gen_tensors()\n",
    "docs_chunks.shape, target_chunks.shape, target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|query_begin|> Austrocidaris spinulosaAustrocidaris spinulosa is a species of sea urchins of the family Cidaridae. Their armour is covered with spines. Austrocidaris spinulosa was first scientifically described in 1910 by Ole Mortensen.\\n\\nReferences\\n\\nCategory:Sea Urchins described in 1910\\nCategory:Cidaridae\\nCategory:Taxa named by Ole Theodor Jensen Mortensen <|query_end|>'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_target = tokens_to_text(target_chunks)\n",
    "s_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|doc_begin|> <|doc_id_begin|> 4795098 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  around the world.  The destinations depicted are usually the result of product placement. In 2015, the\n",
      "<|doc_begin|> <|doc_id_begin|> 4795098 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  based on Richard Gordon's novel \"The Captain's Table\".\\n\\nPremise \\nThe premise of the series resembled \n",
      "<|doc_begin|> <|doc_id_begin|> 4795098 <|doc_id_end|> <|doc_offset_begin|> 273 <|doc_offset_end|>  happy-end in each episode.\\n\\nActors \\nCaptain Heinz Hansen was played by Heinz Weiss who in younger yea\n",
      "<|doc_begin|> <|doc_id_begin|> 3463886 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> 1988 Western Soccer Alliance <|doc_title_end|> <|doc_body_begin|> Final league stand\n",
      "<|doc_begin|> <|doc_id_begin|> 3463886 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>, Arturo Velazco, Jeff Stock\\nMidfielders: Peter Hattrup, Billy Thompson, Tomás Boy\\nForwards: Justin Fash\n",
      "<|doc_begin|> <|doc_id_begin|> 3463886 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|> wards: Scott Benedetti, Chance Fry, John Sissons\\n\\nExternal links\\nThe Year in American Soccer - 1988\\n 1\n",
      "<|doc_begin|> <|doc_id_begin|> 3231262 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Austrocidaris spinulosa <|doc_title_end|> <|doc_body_begin|> Austrocidaris spinulosa\n",
      "<|doc_begin|> <|doc_id_begin|> 3231262 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  Mortensen <|doc_body_end|> <|doc_end|>\n",
      "<|doc_begin|> <|doc_id_begin|> 987419 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Gambierdiscus ruetzleri <|doc_title_end|> <|doc_body_begin|> Gambierdiscus ruetzleri \n",
      "<|doc_begin|> <|doc_id_begin|> 987419 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|> ) isolated from New Zealand's sub-tropical northern coastal waters.\" New Zealand Journal of Marine and F\n",
      "<|doc_begin|> <|doc_id_begin|> 987419 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|> 2013): e60882.\\n\\nExternal links\\n\\nAlgaeBase\\n\\nCategory:Gonyaulacales\\nCategory:Species described in 2009 <|\n",
      "<|doc_begin|> <|doc_id_begin|> 4289075 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Urusbiy <|doc_title_end|> <|doc_body_begin|> Urusbiy () is the surname of the mounta\n",
      "<|doc_begin|> <|doc_id_begin|> 4289075 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|> shev, left with his mother at the end of the 18th century, first to the Chegem society, where his mothe\n",
      "<|doc_begin|> <|doc_id_begin|> 4289075 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  possessions of the Kabardinian princes Atazhukin, on the site called \"Kamyk\". Soon after the resettle\n"
     ]
    }
   ],
   "source": [
    "for toks in docs_chunks:\n",
    "    s = tokens_to_text(toks)\n",
    "    print(s[:200].replace('\\n', '\\\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embs = model_ranker.run_enc_emb(target_chunks)\n",
    "docs_embs = model_ranker.run_enc_emb(docs_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.201634 F\n",
      "0.051609 F\n",
      "0.047279 F\n",
      "0.121715 F\n",
      "0.023739 F\n",
      "0.243091 F\n",
      "0.921977 T\n",
      "0.025204 T\n",
      "0.752494 F\n",
      "0.503484 F\n",
      "0.547126 F\n",
      "0.451889 F\n",
      "0.235818 F\n",
      "0.269741 F\n"
     ]
    }
   ],
   "source": [
    "cosine = False\n",
    "cosine = True\n",
    "print_dist(target_embs, docs_embs, target_mask, cosine=cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n",
      "0.382868 F\n",
      "0.062052 F\n",
      "0.169623 F\n",
      "0.087439 F\n",
      "0.249196 F\n",
      "0.237066 F\n",
      "0.325658 T\n",
      "0.359878 T\n",
      "0.590362 F\n",
      "0.504442 F\n",
      "0.494654 F\n",
      "0.664267 F\n",
      "0.238684 F\n",
      "0.430113 F\n"
     ]
    }
   ],
   "source": [
    "txt = 'The Captain\\'s Table'\n",
    "# txt = '1988 Western Soccer Alliance'\n",
    "txt = 'Austrocidaris spinulosa'\n",
    "txt = 'Gambierdiscus ruetzleri'\n",
    "txt = 'Urusbiy'\n",
    "\n",
    "# txt = 'The graph sandwich problem for property Π is defined as follows:'\n",
    "cosine = True\n",
    "txt_tokens = text_to_tokens(txt, qbeg_tok=qbeg_tok, qend_tok=qend_tok)\n",
    "# txt_tokens = txt_tokens.repeat(3, 1)\n",
    "print(txt_tokens.shape)\n",
    "txt_embs = model_ranker.run_enc_emb(txt_tokens)\n",
    "print_dist(txt_embs, docs_embs, target_mask, cosine=cosine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.050682',\n",
       " '0.006449',\n",
       " '0.044166',\n",
       " '0.000333',\n",
       " '0.041805',\n",
       " '0.001856',\n",
       " '0.040835',\n",
       " '0.084292',\n",
       " '0.241429',\n",
       " '0.164106',\n",
       " '0.266632',\n",
       " '0.973829',\n",
       " '0.019062',\n",
       " '0.037045']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rank = model_ranker.run_qs_infer(docs_chunks, txt_tokens)\n",
    "rank_str = [f'{r:.06f}' for r in rank.flatten()]\n",
    "rank_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 100])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_chunks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8737, 0.8907, 0.7371, 0.5201, 0.4101, 0.8237, 0.7342, 0.8183, 0.8694,\n",
       "         0.6263, 0.6608, 0.6087, 0.2565, 0.3135, 0.3250]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = model_ranker(txt_tokens, docs_chunks)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6538e-21, 3.7294e-11, 2.4412e-19, 3.4020e-23, 7.5630e-20, 3.8663e-25,\n",
       "         1.3986e-18, 7.2614e-22, 1.0000e+00, 1.0000e+00, 1.0000e+00, 4.7166e-09,\n",
       "         1.9997e-11, 1.3684e-08]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = model_ranker(target_chunks, docs_chunks)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device1 = torch.device('cpu')\n",
    "device2 = torch.device('cuda')\n",
    "device3 = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(device1 == device2)\n",
    "print(device2 == device3)\n",
    "print(device1 == device3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cpu', str)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device1.type, type(device1.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0.5,  0.5],\n",
       "       [ 1.7,  1.7,  1.7],\n",
       "       [-1. ,  7. , 33. ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "toks = [\n",
    "    np.ones(3) * 0.5,\n",
    "    np.ones(3) * 1.7,\n",
    "    np.array([-1, 7, 33])\n",
    "]\n",
    "np.stack(toks, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0.5,  0.5],\n",
       "       [ 1.7,  1.7,  1.7],\n",
       "       [-1. ,  7. , 33. ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(np.array(toks), np.stack(toks, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
