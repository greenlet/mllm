{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import requests\n",
    "import sys\n",
    "from typing import Optional\n",
    "\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pydantic_yaml import parse_yaml_file_as, to_yaml_file\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertGenerationEncoder, BertGenerationDecoder, EncoderDecoderModel, BertTokenizer, AutoTokenizer\n",
    "from transformers.modeling_outputs import Seq2SeqLMOutput, BaseModelOutputWithPastAndCrossAttentions, CausalLMOutputWithCrossAttentions\n",
    "\n",
    "from mllm.config.model import GenmixBertCfg\n",
    "from mllm.exp.args import GENMIX_BERT_MODEL_CFG_FNAME\n",
    "from mllm.model.genmix import GenmixBert\n",
    "from mllm.train.utils import get_squadv2_df, get_squadv2_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Generator model inference\n",
    "## Configs and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(os.path.expandvars('$HOME')) / 'data'\n",
    "\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "random_seed = 111\n",
    "inp_len = 128\n",
    "train_genmix_bert_path = DATA_PATH / 'train_mllm_genmix_bert'\n",
    "genmix_subdir = 'genmixbert-20250508_221933-bert-base-uncased-d768-inp128'\n",
    "\n",
    "genmix_train_path = train_genmix_bert_path / genmix_subdir\n",
    "genmix_snapshot_fpath = genmix_train_path / 'best.pth'\n",
    "\n",
    "device_name = 'cpu'\n",
    "# device_name = 'cuda'\n",
    "\n",
    "device = torch.device(device_name)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenmixBertCfg(inp_len=128, d_model=768, pretrained_model_name='bert-base-uncased', tokenizer_name='bert-base-uncased')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cfg = parse_yaml_file_as(GenmixBertCfg, genmix_train_path / GENMIX_BERT_MODEL_CFG_FNAME)\n",
    "model_cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models and dataset\n",
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type bert-generation. This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type bert to instantiate a model of type bert-generation. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of BertGenerationDecoder were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'lm_head.bias', 'lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = GenmixBert(model_cfg, device=device)\n",
    "\n",
    "\n",
    "tkz = BertTokenizer.from_pretrained(bert_model_name)\n",
    "print(tkz)\n",
    "genmix_model: BertGenerationEncoder = BertGenerationEncoder.from_pretrained(bert_model_name, bos_token_id=101, eos_token_id=102)\n",
    "# add cross attention layers and use BERT's cls token as BOS token and sep token as EOS token\n",
    "dec_model: BertGenerationDecoder = BertGenerationDecoder.from_pretrained(\n",
    "    bert_model_name, add_cross_attention=True, is_decoder=True, bos_token_id=101, eos_token_id=102\n",
    ")\n",
    "model = EncoderEmbDecoderModel(\n",
    "    encoder=enc_model, decoder=dec_model, enc_emb_exp_type=genmix_params.exp_type, enc_emb_exp_bias=genmix_params.exp_bias,\n",
    "    enc_inp_len=inp_len, enc_inp_batch_size=genmix_params.enc_batch_size,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-base-uncased'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertGenerationConfig\n",
    "cfg: BertGenerationConfig = enc_model.config\n",
    "cfg.name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load /home/misha/data/train_mllm_eed_bert_qna/eedbert-20250503_172002-bert_base_uncased-d768-emp_f-qi_enc-exp_emb_b-bt_11-chkpt_none/best.pth\n"
     ]
    }
   ],
   "source": [
    "print(f'Load {genmix_snapshot_fpath}')\n",
    "checkpoint = torch.load(genmix_snapshot_fpath, map_location=device)\n",
    "model.load_state_dict(checkpoint['model'], strict=True)\n",
    "del checkpoint\n",
    "model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squad v2 Qna dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad_v2 (/home/misha/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7880e25d6fd4d11b94da248049ae256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove empty answers from dataset squad_v2. Size: 142192 --> 92749\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(random_seed)\n",
    "# exclude_empty_answers = False\n",
    "exclude_empty_answers = True\n",
    "df_sq = get_squadv2_df(exclude_empty_answers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context1. Older than The Game by 23 years, the Harvard-Yale Regatta was the original source of the athletic rivalry between the two schools. It is held annually in June on the Thames River in eastern Connecticut. The Harvard crew is typically considered to be one of the top teams in the country in rowing. Today, Harvard fields top teams in several other sports, such as the Harvard Crimson men's ice hockey team (with a strong rivalry against Cornell), squash, and even recently won NCAA titles in Men's and Women's Fencing. Harvard also won the Intercollegiate Sailing Association National Champio\n",
      "Context2. When aspirated consonants are doubled or geminated, the stop is held longer and then has an aspirated release. An aspirated affricate consists of a stop, fricative, and aspirated release. A doubled aspirated affricate has a longer hold in the stop portion and then has a release consisting of the fricative and aspiration.\n",
      "Context3. After being lit at the birthplace of the Olympic Games in Olympia, Greece on March 24, the torch traveled to the Panathinaiko Stadium in Athens, and then to Beijing, arriving on March 31. From Beijing, the torch was following a route passing through six continents. The torch has visited cities along the Silk Road, symbolizing ancient links between China and the rest of the world. The relay also included an ascent with the flame to the top of Mount Everest on the border of Nepal and Tibet, China from the Chinese side, which was closed specially for the event.\n",
      "Context4. When Link enters the Twilight Realm, the void that corrupts parts of Hyrule, he transforms into a wolf.[h] He is eventually able to transform between his Hylian and wolf forms at will. As a wolf, Link loses the ability to use his sword, shield, or any secondary items; he instead attacks by biting, and defends primarily by dodging attacks. However, \"Wolf Link\" gains several key advantages in return—he moves faster than he does as a human (though riding Epona is still faster) and digs holes to create new passages and uncover buried items, and has improved senses, including the ability \n",
      "Context5. Many Han Chinese and Khitan defected to the Mongols to fight against the Jin. Two Han Chinese leaders, Shi Tianze, Liu Heima (劉黑馬, Liu Ni), and the Khitan Xiao Zhala (蕭札剌) defected and commanded the 3 Tumens in the Mongol army. Liu Heima and Shi Tianze served Ogödei Khan. Liu Heima and Shi Tianxiang led armies against Western Xia for the Mongols. There were 4 Han Tumens and 3 Khitan Tumens, with each Tumen consisting of 10,000 troops. The three Khitan Generals Shimobeidier (石抹孛迭兒), Tabuyir (塔不已兒) and Xiaozhacizhizizhongxi (蕭札刺之子重喜) commanded the three Khitan Tumens and the four Han G\n",
      "Context6. Required attendance at school is 10 years for males and 11 years for females (2001). The adult literacy rate is 99.0% (2002). In 2010, there were 1,918 students who were taught by 109 teachers (98 certified and 11 uncertified). The teacher-pupil ratio for primary schools in Tuvalu is around 1:18 for all schools with the exception of Nauti School, which has a teacher-student ratio of 1:27. Nauti School on Funafuti is the largest primary in Tuvalu with more than 900 students (45 percent of the total primary school enrolment). The pupil-teacher ratio for Tuvalu is low compared to the Pa\n",
      "Context7. Throughout most of his career, Athanasius had many detractors. Classical scholar Timothy Barnes relates contemporary allegations against Athanasius: from defiling an altar, to selling Church grain that had been meant to feed the poor for his own personal gain, and even violence and murder to suppress dissent. Athanasius used \"Arian\" to describe both followers of Arius, and as a derogatory polemical term for Christians who disagreed with his formulation of the Trinity. Athanasius called many of his opponents \"Arian\", except for Miletus.\n",
      "Context8. The Paris Region economy has gradually shifted from industry to high-value-added service industries (finance, IT services, etc.) and high-tech manufacturing (electronics, optics, aerospace, etc.). The Paris region's most intense economic activity through the central Hauts-de-Seine department and suburban La Défense business district places Paris' economic centre to the west of the city, in a triangle between the Opéra Garnier, La Défense and the Val de Seine. While the Paris economy is dominated by services, and employment in manufacturing sector has declined sharply, the region rema\n",
      "Context9. In many places in Switzerland, household rubbish disposal is charged for. Rubbish (except dangerous items, batteries etc.) is only collected if it is in bags which either have a payment sticker attached, or in official bags with the surcharge paid at the time of purchase. This gives a financial incentive to recycle as much as possible, since recycling is free. Illegal disposal of garbage is not tolerated but usually the enforcement of such laws is limited to violations that involve the unlawful disposal of larger volumes at traffic intersections and public areas. Fines for not paying\n",
      "Context10. The centre-left Australian Labor Party (ALP), the centre-right Liberal Party of Australia, the rural-based National Party of Australia, and the environmentalist Australian Greens are Victoria's main political parties. Traditionally, Labor is strongest in Melbourne's working class western and northern suburbs, and the regional cities of Ballarat, Bendigo and Geelong. The Liberals' main support lies in Melbourne's more affluent eastern and outer suburbs, and some rural and regional centres. The Nationals are strongest in Victoria's North Western and Eastern rural regional areas. The G\n"
     ]
    }
   ],
   "source": [
    "batch_size = eed_params.batch_size or 5\n",
    "inds = np.arange(batch_size)\n",
    "inds += batch_size * 1\n",
    "batch = get_squadv2_batch(tkz=tkz, df_sq=df_sq, inds=inds, inp_len=inp_len, device=device, ques_inp=eed_params.ques_inp)\n",
    "for ctx in batch.contexts:\n",
    "    print(ctx[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What as the Paris Region's economy shifted towards?. A: high-value-added service industries\n",
      "Q: Who is the primary rival of the Harvard Crimson hockey team?. A: Cornell\n",
      "Q: What happens when an aspirated consonant is doubled or geminated?. A: the stop is held longer and then has an aspirated release.\n",
      "Q: What political party is strongest in Melbourne's working class suburbs?. A: Australian Labor Party\n",
      "Q: What si the teacher-student ratio for Tuvalu schools?. A: 1:18\n",
      "Q: How many Khitan Tumens were there?. A: three\n",
      "Q: How many Khitan Tumens were there?. A: 3\n",
      "Q: What are Poes?. A: enemy ghosts\n",
      "Q: Where did the Olympics originate?. A: Olympia, Greece\n",
      "Q: Who is the primary rival of the Harvard Crimson hockey team?. A: strong rivalry against Cornell\n"
     ]
    }
   ],
   "source": [
    "for q, a in batch.qas:\n",
    "    print(f'Q: {q}. A: {a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctxs_toks, other_toks = batch.gen_tensors()\n",
    "ctxs_mask = (ctxs_toks > 0).to(batch.device)\n",
    "ctx_enc_out: BaseModelOutputWithPastAndCrossAttentions = model.encoder(input_ids=ctxs_toks, attention_mask=ctxs_mask)\n",
    "ctx_lhs = ctx_enc_out.last_hidden_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_lhs = torch.rand_like(ctx_lhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctx_lhs: torch.Size([10, 128, 768]). q_lhs: torch.Size([1, 128, 768]). ctxq_emb: torch.Size([1, 11, 768])\n"
     ]
    }
   ],
   "source": [
    "qa_ind = 5\n",
    "\n",
    "if batch.ques_inp == QnaQuesInp.Enc:\n",
    "    q_toks_l, a_toks_l, a_att_masks_l, a_tgt_masks_l = other_toks\n",
    "    n_ans = len(a_toks_l)\n",
    "    q_toks, a_toks, a_att_mask, a_tgt_mask = q_toks_l[qa_ind], a_toks_l[qa_ind], a_att_masks_l[qa_ind], a_tgt_masks_l[qa_ind]\n",
    "    q_toks = q_toks.unsqueeze(0)\n",
    "    q_mask = (q_toks > 0).to(batch.device)\n",
    "    q_enc_out: BaseModelOutputWithPastAndCrossAttentions = model.encoder(input_ids=q_toks, attention_mask=q_mask)\n",
    "    ctxq_lhs = torch.concatenate([ctx_lhs, q_enc_out.last_hidden_state], dim=0)\n",
    "    ctxq_emb = model.run_expansion(ctxq_lhs)\n",
    "    # ctxq_emb = model.run_expansion(ctx_lhs)\n",
    "    print(f'ctx_lhs: {ctx_lhs.shape}. q_lhs: {q_enc_out.last_hidden_state.shape}. ctxq_emb: {ctxq_emb.shape}')\n",
    "    # a_toks = a_toks.repeat(len(a_att_mask), 1)\n",
    "    # # a_toks_inp = a_toks * a_att_mask\n",
    "    # a_toks_inp = a_toks\n",
    "    # a_dec_out: CausalLMOutputWithCrossAttentions = model.decoder(\n",
    "    #     input_ids=a_toks_inp, attention_mask=a_att_mask, encoder_hidden_states=ctxq_emb,\n",
    "    # )\n",
    "\n",
    "elif batch.ques_inp == QnaQuesInp.Dec:\n",
    "    qa_toks_l, qa_att_masks_l, qa_tgt_masks_l = other_toks\n",
    "    n_qas = len(qa_toks_l)\n",
    "    qa_toks, qa_att_mask, qa_tgt_mask = qa_toks_l[qa_ind].unsqueeze(0), qa_att_masks_l[qa_ind], qa_tgt_masks_l[qa_ind]\n",
    "    # qa_toks = qa_toks.repeat(len(qa_att_mask), 1)\n",
    "    # qa_toks_inp = qa_toks * qa_att_mask\n",
    "    # dec_out: CausalLMOutputWithCrossAttentions = model.decoder(\n",
    "    #     input_ids=qa_toks_inp, attention_mask=qa_att_mask, encoder_hidden_states=ctx_emb\n",
    "    # )\n",
    "    # n = 0\n",
    "    # for i in range(qa_toks.shape[1]):\n",
    "    #     if qa_att_mask[0, i] == 0:\n",
    "    #         n = i\n",
    "    #         break\n",
    "    # q_toks = qa_toks[0, :n + 1].clone()\n",
    "    # q_toks[-1] = 0\n",
    "\n",
    "else:\n",
    "    raise Exception(f'Unsupported Question input type: {batch.ques_inp}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What political party is strongest in Melbourne's working class suburbs? - Labor\n",
      "[CLS] [SEP]\n",
      "[CLS] one [SEP]\n",
      "[CLS] five [SEP]\n",
      "[CLS] third [SEP]\n",
      "[CLS] - [SEP]\n",
      "[CLS] [SEP]\n"
     ]
    }
   ],
   "source": [
    "def predict(model: EncoderEmbDecoderModel, enc_emb: torch.Tensor, toks: torch.Tensor, max_len: int = 10) -> list[int]:\n",
    "    i, toks_cur, toks_out = 0, toks.tolist(), []\n",
    "    inp_ids = toks.unsqueeze(0)\n",
    "    while i < max_len:\n",
    "        print(tkz.decode(toks_cur))\n",
    "        # att_mask = (inp_ids > 0).to(torch.int32)\n",
    "        dec_out: CausalLMOutputWithCrossAttentions = model.decoder(\n",
    "            input_ids=inp_ids, encoder_hidden_states=enc_emb, use_cache=False,\n",
    "        )\n",
    "        # print(dec_out.logits.shape)\n",
    "        probs_pred = torch.softmax(dec_out.logits[0, -1], dim=-1)\n",
    "        # print(probs_pred.shape)\n",
    "        tok_out = torch.argmax(probs_pred, dim=-1)\n",
    "        # print(tok_out.item())\n",
    "        tok = tok_out.item()\n",
    "        if tok == 102:\n",
    "            break\n",
    "        toks_cur.append(tok)\n",
    "        inp_ids = torch.tensor(toks_cur, dtype=toks.dtype, device=toks.device).unsqueeze(0)\n",
    "\n",
    "        i += 1\n",
    "    return toks_cur if toks_cur[-1] != tkz.cls_token_id else toks_cur[:-1]\n",
    "\n",
    "def predict_beam(model: EncoderEmbDecoderModel, enc_emb: torch.Tensor, toks: torch.Tensor, num_beams: int = 5, max_len: int = 10,\n",
    "                 temperature: float = 1) -> list[int]:\n",
    "    beam_search = BeamSearch(\n",
    "        num_beams=num_beams, max_len=max_len, temperature=temperature, next_token_id=tkz.cls_token_id,\n",
    "        last_token_id=tkz.sep_token_id, device=device, append_next_token_id=False,\n",
    "    )\n",
    "    # toks_inp: [n_active_beams, beam_seq_len] -> [n_active_beams, vocab_size]\n",
    "    def run_inference(beam_seq_batch: torch.Tensor) -> torch.Tensor:\n",
    "        n_active_beams = beam_seq_batch.shape[0]\n",
    "        dec_out: CausalLMOutputWithCrossAttentions = model.decoder(\n",
    "            input_ids=beam_seq_batch, encoder_hidden_states=enc_emb,\n",
    "        )\n",
    "        return dec_out.logits[:, -1, :]\n",
    "\n",
    "    beams = beam_search.run(run_inference)\n",
    "    for beam in beams:\n",
    "        print(tkz.decode(beam.tokens_cur))\n",
    "    return beams[0].tokens_cur\n",
    "\n",
    "q, a = batch.qas[qa_ind]\n",
    "print(f'{q} - {a}')\n",
    "if eed_params.ques_inp == QnaQuesInp.Enc:\n",
    "    q_toks = [tkz.cls_token_id]\n",
    "    q_toks = torch.tensor(q_toks, dtype=torch.int64, device=device)\n",
    "    # toks_out = predict(model, ctxq_emb, q_toks, max_len=20)\n",
    "    toks_out = predict_beam(model, ctxq_emb, q_toks, max_len=20)\n",
    "else:\n",
    "    raise Exception(f'{eed_params.ques_inp} qna question input type is not supported.')\n",
    "    q_toks = qa_toks.squeeze().tolist()\n",
    "    print(q_toks)\n",
    "    for i, q_tok in enumerate(q_toks):\n",
    "        # print(i, q_tok, q_tok == tkz.sep_token_id)\n",
    "        if q_tok == tkz.sep_token_id:\n",
    "            q_toks = q_toks[:i + 2]\n",
    "            q_toks[i + 1] = tkz.cls_token_id\n",
    "            break\n",
    "    q_toks = torch.tensor(q_toks, dtype=torch.int64, device=device)\n",
    "    print(q_toks)\n",
    "    ctx_emb = model.run_expansion(ctx_lhs)\n",
    "    toks_out = predict(model, ctx_emb, q_toks, max_len=20)\n",
    "print(tkz.decode(toks_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4, 0, 4, 5, 6]), array([1, 9, 6, 8, 3]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds1 = np.random.randint(0, 10, 5)\n",
    "inds2 = np.random.randint(0, 10, 5)\n",
    "inds1, inds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 4, 5, 6, 1, 9, 6, 8, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([inds1, inds2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False, False],\n",
       "       [ True,  True, False, False],\n",
       "       [ True,  True,  True, False],\n",
       "       [ True,  True,  True,  True]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 4\n",
    "t = np.tril(np.ones((n, n), dtype=bool), k=0)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 90,  9, 20])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randint(100, size=n)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28, 90,  9, 20],\n",
       "       [28, 90,  9, 20],\n",
       "       [28, 90,  9, 20],\n",
       "       [28, 90,  9, 20]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.repeat(a[None], n, axis=0)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[123,   0,   0,   0],\n",
       "       [ 28, 123,   0,   0],\n",
       "       [ 28,  90, 123,   0],\n",
       "       [ 28,  90,   9, 123]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_id = 123\n",
    "mask = np.eye(n, dtype=bool)\n",
    "bb = np.tril(b, k=-1)\n",
    "bb[mask] = mask_token_id\n",
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of mllm.train.embgen_bert failed: Traceback (most recent call last):\n",
      "  File \"/home/misha/miniconda3/envs/mllm/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/misha/miniconda3/envs/mllm/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/misha/miniconda3/envs/mllm/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1017, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 947, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/misha/prog/mllm/notebooks/../mllm/train/embgen_bert.py\", line 477\n",
      "    loss = qna_loss(dec_out.logits, dec_toks_inp\n",
      "                   ^\n",
      "SyntaxError: '(' was never closed\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  7, 22, -1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at = torch.tensor([1, 7, 22, -1])\n",
    "at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  0,  0,  0],\n",
       "        [ 1,  7,  0,  0],\n",
       "        [ 1,  7, 22,  0],\n",
       "        [ 1,  7, 22, -1]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(at)\n",
    "atn = at.repeat(n, 1)\n",
    "atn = torch.tril(atn)\n",
    "atn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False, False],\n",
       "        [False,  True, False, False],\n",
       "        [False, False,  True, False],\n",
       "        [False, False, False,  True]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskt = torch.tensor(mask)\n",
    "maskt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[103,   0,   0,   0],\n",
       "        [ 28, 103,   0,   0],\n",
       "        [ 28,  90, 103,   0],\n",
       "        [ 28,  90,   9, 103]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atn[maskt] = tkz.mask_token_id\n",
    "atn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
