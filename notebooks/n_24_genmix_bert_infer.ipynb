{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import requests\n",
    "import sys\n",
    "from typing import Optional\n",
    "\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pydantic_yaml import parse_yaml_file_as, to_yaml_file\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertGenerationEncoder, BertGenerationDecoder, EncoderDecoderModel, BertTokenizer, AutoTokenizer\n",
    "from transformers.modeling_outputs import Seq2SeqLMOutput, BaseModelOutputWithPastAndCrossAttentions, CausalLMOutputWithCrossAttentions\n",
    "\n",
    "from mllm.config.model import GenmixBertCfg\n",
    "from mllm.model.inference import BeamSearch\n",
    "from mllm.exp.args import GENMIX_BERT_MODEL_CFG_FNAME\n",
    "from mllm.model.genmix import GenmixBert\n",
    "from mllm.train.utils import get_squadv2_df, get_squadv2_batch, QnaQuesInp, get_billsum_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Generator model inference\n",
    "## Configs and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(os.path.expandvars('$HOME')) / 'data'\n",
    "\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "random_seed = 111\n",
    "inp_len = 128\n",
    "train_genmix_bert_path = DATA_PATH / 'train_mllm_genmix_bert'\n",
    "# genmix_subdir = 'genmixbert-20250510_112004-bert-base-uncased-d768-inp128'\n",
    "# genmix_subdir = 'genmixbert-20250514_214424-bert-base-uncased-d768-inp128'\n",
    "# genmix_subdir = 'genmixbert-20250515_223449-bert-base-uncased-d768-inp128-ds_sum-maxi10-maxo50'\n",
    "genmix_subdir = 'genmixbert-20250517_105055-bert-base-uncased-d768-inp128-ds_sum-maxi10-maxo50'\n",
    "\n",
    "genmix_train_path = train_genmix_bert_path / genmix_subdir\n",
    "genmix_snapshot_fpath = genmix_train_path / 'best.pth'\n",
    "\n",
    "device_name = 'cpu'\n",
    "# device_name = 'cuda'\n",
    "\n",
    "device = torch.device(device_name)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenmixBertCfg(inp_len=128, d_model=768, pretrained_model_name='bert-base-uncased', tokenizer_name='bert-base-uncased', max_inp_chunks=10, max_out_toks=50)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cfg = parse_yaml_file_as(GenmixBertCfg, genmix_train_path / GENMIX_BERT_MODEL_CFG_FNAME)\n",
    "model_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models and dataset\n",
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type bert-generation. This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type bert to instantiate a model of type bert-generation. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of BertGenerationDecoder were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'lm_head.bias', 'lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = GenmixBert(model_cfg, device=device)\n",
    "tkz = model.tkz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load /home/misha/data/train_mllm_genmix_bert/genmixbert-20250517_105055-bert-base-uncased-d768-inp128-ds_sum-maxi10-maxo50/best.pth\n"
     ]
    }
   ],
   "source": [
    "print(f'Load {genmix_snapshot_fpath}')\n",
    "checkpoint = torch.load(genmix_snapshot_fpath, map_location=device)\n",
    "model.load_state_dict(checkpoint['model'], strict=True)\n",
    "del checkpoint\n",
    "model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squad v2 Qna dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e6c519302e4eccad4a2a629768e655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c057319fc9f54f859692dc252635f82e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/16.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc36520094d4559b880d67d1c67a7f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/1.35M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075edd7fdcf747b2afadfa53f00635b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/130319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d084c5c99f4a538e15502aa6927bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/11873 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove empty answers from dataset squad_v2. Size: 142192 --> 92749\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(random_seed)\n",
    "# exclude_empty_answers = False\n",
    "exclude_empty_answers = True\n",
    "df_sq = get_squadv2_df(exclude_empty_answers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_beam(model: GenmixBert, enc_emb: torch.Tensor, num_beams: int = 5, max_len: int = 10,\n",
    "                 temperature: float = 1) -> list[int]:\n",
    "    beam_search = BeamSearch(\n",
    "        num_beams=num_beams, max_len=max_len, temperature=temperature, next_token_id=tkz.cls_token_id,\n",
    "        last_token_id=tkz.sep_token_id, device=device, append_next_token_id=False,\n",
    "    )\n",
    "    # toks_inp: [n_active_beams, beam_seq_len] -> [n_active_beams, vocab_size]\n",
    "    def run_inference(beam_seq_batch: torch.Tensor) -> torch.Tensor:\n",
    "        n_active_beams = beam_seq_batch.shape[0]\n",
    "        dec_out: CausalLMOutputWithCrossAttentions = model(\n",
    "            inputs_embeds=enc_emb, decoder_input_ids=beam_seq_batch,\n",
    "        )\n",
    "        return dec_out.logits[:, -1, :]\n",
    "\n",
    "    beams = beam_search.run(run_inference)\n",
    "    for beam in beams:\n",
    "        print(tkz.decode(beam.tokens_cur))\n",
    "    return beams[0].tokens_cur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Traditionally a carnival feast was the last opportunity to eat well before the time of food shortage at the end of the winter during which one was limited to the minimum necessary. On what nowadays is called vastenavond (the days before fasting) all the remaining winter stores of lard, butter and meat which were left would be eaten, for it would soon start to rot and decay. The selected livestock had in fact already been slaughtered in November and the meat would be no longer preservable. All the food that had survived the winter had to be eaten to assure that everyone was fed enough to survive until the coming spring would provide new food sources.\n",
      "Q: What was one limited to during the winter?\n",
      "A: the minimum necessary\n"
     ]
    }
   ],
   "source": [
    "i = 5\n",
    "row = df_sq.iloc[i]\n",
    "context, question, answers = row['context'], row['question'], row['answers']['text']\n",
    "print(f'Context: {context}')\n",
    "print(f'Q: {question}')\n",
    "for answer in answers:\n",
    "    print(f'A: {answer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4493)\n",
      "existing\n"
     ]
    }
   ],
   "source": [
    "# [1, n_cq, d_model]\n",
    "emb = model.context_question_to_emb(context, question)\n",
    "target_ids = torch.tensor([[tkz.cls_token_id]], device=device)\n",
    "# target_ids = torch.tensor([[2491]], device=device)\n",
    "gen_out: Seq2SeqLMOutput = model.gen(inputs_embeds=emb, decoder_input_ids=target_ids, use_cache=False)\n",
    "# [1, tgt_len, n_vocab]\n",
    "gen_logits = gen_out.logits\n",
    "\n",
    "# [tgt_len, n_vocab]\n",
    "logits = gen_logits.view(-1, model.gen.decoder.config.vocab_size)\n",
    "probs = torch.softmax(logits[-1], dim=-1)\n",
    "out_tok = torch.argmax(probs)\n",
    "print(out_tok)\n",
    "print(tkz.decode([out_tok]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1996, 6263, 4072, 102], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkz(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] existing law provides for the licensure and regulation of certain persons who are convicted of a crime.\n"
     ]
    }
   ],
   "source": [
    "out_toks = model.gen_on_qna_txt(context, question)\n",
    "out_ans = tkz.decode(out_toks.flatten())\n",
    "print(out_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] table of contents : title i : amendments to\n",
      "[CLS] table of contents : title i : miscellaneous provisions\n",
      "[CLS] table of contents : title i : supplemental appropriations\n",
      "[CLS] directs the secretary of the interior to provide for\n",
      "[CLS] table of contents : title i : supplemental provisions\n",
      "[CLS] table of contents : title i : amendments to\n"
     ]
    }
   ],
   "source": [
    "enc_emb = model.context_question_to_emb(context=context, question=question)\n",
    "out_toks = predict_beam(model.gen, enc_emb)\n",
    "out_str = tkz.decode(out_toks)\n",
    "print(out_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bilsum Summarization dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SECTION 1. LIABILITY OF BUSINESS ENTITIES PROV...</td>\n",
       "      <td>Shields a business entity from civil liability...</td>\n",
       "      <td>A bill to limit the civil liability of busines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SECTION 1. SHORT TITLE.\\n\\n    This Act may be...</td>\n",
       "      <td>Human Rights Information Act - Requires certai...</td>\n",
       "      <td>Human Rights Information Act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SECTION 1. SHORT TITLE.\\n\\n    This Act may be...</td>\n",
       "      <td>Jackie Robinson Commemorative Coin Act - Direc...</td>\n",
       "      <td>Jackie Robinson Commemorative Coin Act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SECTION 1. NONRECOGNITION OF GAIN WHERE ROLLOV...</td>\n",
       "      <td>Amends the Internal Revenue Code to provide (t...</td>\n",
       "      <td>To amend the Internal Revenue Code to provide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SECTION 1. SHORT TITLE.\\n\\n    This Act may be...</td>\n",
       "      <td>Native American Energy Act - (Sec. 3) Amends t...</td>\n",
       "      <td>Native American Energy Act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>The people of the State of California do enact...</td>\n",
       "      <td>Existing law, the Carpenter-Presley-Tanner Haz...</td>\n",
       "      <td>An act to amend Sections 25173.7 and 25205.6 o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>The people of the State of California do enact...</td>\n",
       "      <td>(1) The Hazardous Waste Control Law authorizes...</td>\n",
       "      <td>An act to amend Sections 25185.6, 25358.1, 253...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>The people of the State of California do enact...</td>\n",
       "      <td>Under existing law, any employer or other pers...</td>\n",
       "      <td>An act to amend Section 1197.1 of the Labor Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>The people of the State of California do enact...</td>\n",
       "      <td>Existing law requires the Director of the Depa...</td>\n",
       "      <td>An act to amend Section 14838 of the Governmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>The people of the State of California do enact...</td>\n",
       "      <td>Existing federal law, the Indian Gaming Regula...</td>\n",
       "      <td>An act to amend Sections 12012.75 and 12012.90...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23455 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     SECTION 1. LIABILITY OF BUSINESS ENTITIES PROV...   \n",
       "1     SECTION 1. SHORT TITLE.\\n\\n    This Act may be...   \n",
       "2     SECTION 1. SHORT TITLE.\\n\\n    This Act may be...   \n",
       "3     SECTION 1. NONRECOGNITION OF GAIN WHERE ROLLOV...   \n",
       "4     SECTION 1. SHORT TITLE.\\n\\n    This Act may be...   \n",
       "...                                                 ...   \n",
       "1232  The people of the State of California do enact...   \n",
       "1233  The people of the State of California do enact...   \n",
       "1234  The people of the State of California do enact...   \n",
       "1235  The people of the State of California do enact...   \n",
       "1236  The people of the State of California do enact...   \n",
       "\n",
       "                                                summary  \\\n",
       "0     Shields a business entity from civil liability...   \n",
       "1     Human Rights Information Act - Requires certai...   \n",
       "2     Jackie Robinson Commemorative Coin Act - Direc...   \n",
       "3     Amends the Internal Revenue Code to provide (t...   \n",
       "4     Native American Energy Act - (Sec. 3) Amends t...   \n",
       "...                                                 ...   \n",
       "1232  Existing law, the Carpenter-Presley-Tanner Haz...   \n",
       "1233  (1) The Hazardous Waste Control Law authorizes...   \n",
       "1234  Under existing law, any employer or other pers...   \n",
       "1235  Existing law requires the Director of the Depa...   \n",
       "1236  Existing federal law, the Indian Gaming Regula...   \n",
       "\n",
       "                                                  title  \n",
       "0     A bill to limit the civil liability of busines...  \n",
       "1                          Human Rights Information Act  \n",
       "2                Jackie Robinson Commemorative Coin Act  \n",
       "3     To amend the Internal Revenue Code to provide ...  \n",
       "4                            Native American Energy Act  \n",
       "...                                                 ...  \n",
       "1232  An act to amend Sections 25173.7 and 25205.6 o...  \n",
       "1233  An act to amend Sections 25185.6, 25358.1, 253...  \n",
       "1234  An act to amend Section 1197.1 of the Labor Co...  \n",
       "1235  An act to amend Section 14838 of the Governmen...  \n",
       "1236  An act to amend Sections 12012.75 and 12012.90...  \n",
       "\n",
       "[23455 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bs = get_billsum_df()\n",
    "df_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A bill to amend title XVIII of the Social Security Act to provide coverage for kidney disease education services under the medicare program, and for other purposes.\n",
      "Text: SECTION 1. SHORT TITLE.\n",
      "\n",
      "    This Act may be cited as the ``Kidney Disease Educational Benefits \n",
      "Act of 2002''.\n",
      "\n",
      "SEC. 2. MEDICARE COVERAGE OF KIDNEY DISEASE EDUCATION SERVICES.\n",
      "\n",
      "    (a) Coverage of Kidney Disease Education Services.--\n",
      "            (1) In general.--Section 1861 of the Social Security Act \n",
      "        (42 U.S.C. 1395x), as amended by section 105 of the Medicare, \n",
      "        Medicaid, and SC\n",
      "Summary: Kidney Disease Educational Benefits Act of 2002 - Amends title XVIII (Medicare) of the Social Security Act, as amended by the Medicare, Medicaid, and SCHIP Benefits Improvement and Protection Act of 2000, to provide coverage for kidney disease education services furnished, upon the managing physician's referral, to an individual with kidney disease who will require dialysis or a kidney transplant. Requires such services to: (1) impart comprehensive information regarding management, prevention, and options regarding treatment of kidney disease; and (2) ensure that such individuals have the opportunity to participate actively in the choice of therapy.\n"
     ]
    }
   ],
   "source": [
    "i = 10\n",
    "row = df_bs.iloc[i]\n",
    "text, summary, title = row['text'], row['summary'], row['title']\n",
    "print('Title:', title)\n",
    "print('Text:', text[:400])\n",
    "print('Summary:', summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] medicare medicare prescription drug access act of 2003 - amends title xviii ( medicare ) of the social\n"
     ]
    }
   ],
   "source": [
    "out_toks = model.gen_on_sum_txt(text=text, title=title)\n",
    "out_ans = tkz.decode(out_toks.flatten())\n",
    "print(out_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] amends title xviii ( medicare ) of the social security act to require the secretary of health\n",
      "[CLS] amends title xviii ( medicare ) of the social security act ( ssa ) to provide\n",
      "[CLS] amends title xviii ( medicare ) of the social security act ( ssa ) to require\n",
      "[CLS] amends title xix ( medicaid ) of the social security act to require the secretary\n",
      "[CLS] amends title xviii ( medicare ) of the social security act to : ( 1 ) provide\n",
      "[CLS] amends title xviii ( medicare ) of the social security act to require the secretary of health\n"
     ]
    }
   ],
   "source": [
    "enc_emb = model.text_title_to_emb(text=text, title=title)\n",
    "out_toks = predict_beam(model.gen, enc_emb, max_len=20)\n",
    "out_str = tkz.decode(out_toks)\n",
    "print(out_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10243.284331698998"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bs['text'].str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
