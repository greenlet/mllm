{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import Optional\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import GPT2Tokenizer, AddedToken, PreTrainedTokenizer\n",
    "\n",
    "from mllm.data.dsfixed import DsLoader\n",
    "from mllm.model.mllm_encdec import MllmEncdec\n",
    "from mllm.model.mllm_ranker import MllmRanker\n",
    "from mllm.model.config import create_mllm_encdec_cfg, create_mllm_ranker_cfg\n",
    "from mllm.tokenization.chunk_tokenizer import calc_max_inp_size, gen_all_tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(os.path.expandvars('$HOME')) / 'data'\n",
    "TRAIN_ENCDEC_PATH = DATA_PATH / 'train_mllm_encdec'\n",
    "TRAIN_RANKER_PATH = DATA_PATH / 'train_mllm_ranker'\n",
    "DS_DIR_PATH = DATA_PATH / 'wiki_20200501_en' / 'ch_100_fixed'\n",
    "\n",
    "encdec_subdir = 'encdec-20240718_221554-wiki_20200501_en-ch_100_fixed'\n",
    "ranker_subdir = 'ranker-20240722_225232-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240724_230827-wiki_20200501_en-ch_100_fixed'\n",
    "encdec_train_path = TRAIN_ENCDEC_PATH / encdec_subdir\n",
    "ranker_train_path = TRAIN_RANKER_PATH / ranker_subdir\n",
    "encdec_snapshot_path = encdec_train_path / 'best.pth'\n",
    "ranker_snapshot_path = ranker_train_path / 'best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "docs_batch_size = 5\n",
    "max_chunks_per_doc = 3\n",
    "device = 'cpu'\n",
    "# device = 'cuda'\n",
    "\n",
    "device = torch.device(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cache from /home/misha/data/wiki_20200501_en/ch_100_fixed/.mllm/ds.csv\n",
      "Loaded dataset size: 50989207\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', model_max_length=100000)\n",
    "tok_dict = gen_all_tokens(tokenizer)\n",
    "pad_tok, qbeg_tok, qend_tok = tok_dict['pad'].ind, tok_dict['query_begin'].ind, tok_dict['query_end'].ind\n",
    "ds_loader = DsLoader(\n",
    "    ds_dir_path=DS_DIR_PATH, docs_batch_size=docs_batch_size, max_chunks_per_doc=max_chunks_per_doc,\n",
    "    pad_tok=pad_tok, qbeg_tok=qbeg_tok, qend_tok=qend_tok, device=device,\n",
    ")\n",
    "ds_loader.shuffle(train=True)\n",
    "ds_loader.shuffle(train=False)\n",
    "inp_len = ds_loader.emb_chunk_size if ds_loader.fixed_size else calc_max_inp_size(ds_loader.emb_chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokten_to_text(tokens: torch.Tensor) -> str:\n",
    "    tokens = tokens.flatten()\n",
    "    tokens = tokens[tokens != pad_tok]\n",
    "    tokens = list(tokens)\n",
    "    s = tokenizer.decode(tokens)\n",
    "    return s\n",
    "\n",
    "def distance(x: np.ndarray, y: np.ndarray, cosine: bool = False):\n",
    "    if not cosine:\n",
    "        return np.linalg.norm(x - y)\n",
    "    x_norm, y_norm = np.linalg.norm(x), np.linalg.norm(y)\n",
    "    return np.sum(x * y) / (x_norm * y_norm)\n",
    "\n",
    "def text_to_tokens(s: str, qbeg_tok: Optional[int] = None, qend_tok: Optional[int] = None) -> torch.Tensor:\n",
    "    tokens = tokenizer(s)['input_ids']\n",
    "    if qbeg_tok is not None:\n",
    "        assert qend_tok is not None\n",
    "        tokens = [qbeg_tok, *tokens, qend_tok]\n",
    "    n_tokens = len(tokens)\n",
    "    n_padded = n_tokens // inp_len + (n_tokens % inp_len > 0)\n",
    "    res = np.full((n_padded * inp_len, ), pad_tok, dtype=np.int32)\n",
    "    res[:n_tokens] = tokens\n",
    "    res = torch.from_numpy(res).to(device)\n",
    "    res = res.reshape(n_padded, inp_len)\n",
    "    return res\n",
    "\n",
    "def print_dist(target_embs: torch.Tensor, docs_embs: torch.Tensor, target_mask: torch.Tensor, cosine: bool = True):\n",
    "    for i, docs_emb in enumerate(docs_embs.detach().numpy()):\n",
    "        for target_emb in target_embs.detach().numpy():\n",
    "            dist = distance(target_emb, docs_emb, cosine)\n",
    "            print(f'{dist:0.6f} ', end='')\n",
    "        sfx = 'T' if target_mask[i] else 'F'\n",
    "        print(sfx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_encoder.src_word_emb.weight (50270, 256) -0.010897282 1.2500475e-06 0.010897281\n",
      "vocab_encoder.layer_norm.weight (256,) -0.099734835 -3.7707156e-05 0.09949229\n",
      "vocab_encoder.layer_norm.bias (256,) -0.09868218 0.0024448738 0.099951915\n",
      "encoder.layer_stack.0.slf_attn.w_qs.weight (256, 256) -0.10824596 -8.811242e-05 0.10825054\n",
      "encoder.layer_stack.0.slf_attn.w_ks.weight (256, 256) -0.108249344 -0.00025192086 0.1082518\n",
      "encoder.layer_stack.0.slf_attn.w_vs.weight (256, 256) -0.10825072 -0.00028878736 0.108250424\n",
      "encoder.layer_stack.0.slf_attn.fc.weight (256, 256) -0.10824778 -8.361798e-05 0.108233996\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.weight (256,) -0.09921829 -0.0034752465 0.09923847\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.bias (256,) -0.09971982 -0.0018919911 0.09789826\n",
      "encoder.layer_stack.0.pos_ffn.w_1.weight (1024, 256) -0.06846406 -9.791839e-06 0.0684653\n",
      "encoder.layer_stack.0.pos_ffn.w_1.bias (1024,) -0.09992825 0.001125851 0.09986128\n",
      "encoder.layer_stack.0.pos_ffn.w_2.weight (256, 1024) -0.06846453 -0.00015453433 0.06846421\n",
      "encoder.layer_stack.0.pos_ffn.w_2.bias (256,) -0.09962275 -0.0013075499 0.09997119\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.weight (256,) -0.09959698 0.001413129 0.09706986\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.bias (256,) -0.09974917 -0.00012810086 0.09847297\n",
      "encoder.w_em.weight (1, 100) -0.24100605 0.004190222 0.24279469\n",
      "decoder.A_emb2sec (100, 256, 256) -0.008113911 -1.3769738e-06 0.008113913\n",
      "decoder.att_layers.0.slf_attn.w_qs.weight (256, 256) -0.10824764 -0.00035854266 0.10825044\n",
      "decoder.att_layers.0.slf_attn.w_ks.weight (256, 256) -0.10825002 -8.2650804e-05 0.10825191\n",
      "decoder.att_layers.0.slf_attn.w_vs.weight (256, 256) -0.10825083 -3.32854e-05 0.1082484\n",
      "decoder.att_layers.0.slf_attn.fc.weight (256, 256) -0.10825215 -0.00028894268 0.108252205\n",
      "decoder.att_layers.0.slf_attn.layer_norm.weight (256,) -0.0999947 -0.003371601 0.09980869\n",
      "decoder.att_layers.0.slf_attn.layer_norm.bias (256,) -0.09941132 0.0024375138 0.099964656\n",
      "decoder.att_layers.0.pos_ffn.w_1.weight (1024, 256) -0.06846428 2.9723215e-06 0.0684652\n",
      "decoder.att_layers.0.pos_ffn.w_1.bias (1024,) -0.099790834 -0.0015057698 0.09950622\n",
      "decoder.att_layers.0.pos_ffn.w_2.weight (256, 1024) -0.06846446 4.07343e-05 0.06846531\n",
      "decoder.att_layers.0.pos_ffn.w_2.bias (256,) -0.098935 0.0036135118 0.09923071\n",
      "decoder.att_layers.0.pos_ffn.layer_norm.weight (256,) -0.0999668 0.002036694 0.09884508\n",
      "decoder.att_layers.0.pos_ffn.layer_norm.bias (256,) -0.09886607 -0.0017279802 0.09992834\n",
      "vocab_decoder.word_prj.weight (50270, 256) -0.010897282 9.802224e-07 0.010897281\n"
     ]
    }
   ],
   "source": [
    "model_encdec_cfg = create_mllm_encdec_cfg(\n",
    "    n_vocab=len(tokenizer), d_word_wec=256, inp_len=inp_len,\n",
    "    enc_n_layers=1, dec_n_layers=1,\n",
    "    n_heads=8, d_model=256, d_inner=1024,\n",
    "    pad_idx=pad_tok, dropout_rate=0.1, enc_with_emb_mat=True,\n",
    ")\n",
    "model_encdec = MllmEncdec(model_encdec_cfg).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_encdec = torch.load(encdec_snapshot_path)\n",
    "model_encdec.load_state_dict(checkpoint_encdec['model'])\n",
    "model_encdec.eval()\n",
    "del checkpoint_encdec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496,   612, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267]],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_tokens('Hello there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 100]),\n",
       " torch.Size([1, 100]),\n",
       " tensor([False, False, False, False, False, False,  True, False, False, False,\n",
       "         False, False]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 10\n",
    "batch = ds_loader.get_batch(i, train=True)\n",
    "docs_chunks, target_chunks, target_mask = batch.gen_tensors()\n",
    "docs_chunks.shape, target_chunks.shape, target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|query_begin|> Track and field at the 2015 Military World Games – Men's discus throwThe men's discus throw event at the 2015 Military World Games was held on 8 October at the KAFAC Sports Complex.\\n\\nRecords\\nPrior to this competition, the existing world and CISM record were as follows:\\n\\nSchedule\\n\\nMedalists\\n\\nResults\\n\\nFinal\\n\\nReferences\\n\\ndiscus throw <|query_end|>\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_target = tokten_to_text(target_chunks)\n",
    "s_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|doc_begin|> <|doc_id_begin|> 2723747 <|doc_id_end|> <|doc_offset_begin|> 818 <|doc_offset_end|> oo, Michigan, October 30–November 25, 2008\\n\\n2007\\nTwo Years, Whitney Museum of American Art, New York, \n",
      "<|doc_begin|> <|doc_id_begin|> 2723747 <|doc_id_end|> <|doc_offset_begin|> 908 <|doc_offset_end|> \\n\\n2005\\nThe Painted World, MoMA PS1, New York\\n\\n2001\\nAs Painting: Division and Displacement, curated by \n",
      "<|doc_begin|> <|doc_id_begin|> 2723747 <|doc_id_end|> <|doc_offset_begin|> 998 <|doc_offset_end|>  York, curated by Robert Nickas\\n\\n1999\\nThe Stroke: An Overview of Contemporary Painting, curated by Ros\n",
      "<|doc_begin|> <|doc_id_begin|> 756349 <|doc_id_end|> <|doc_offset_begin|> 92 <|doc_offset_end|>  native speakers as of 2001.\\n\\nKannauji shares many structural and functional differences from other dial\n",
      "<|doc_begin|> <|doc_id_begin|> 756349 <|doc_id_end|> <|doc_offset_begin|> 184 <|doc_offset_end|>  distribution\\nKannauji is not a standard dialect of Hindi and can be assumed to be the transitory phase\n",
      "<|doc_begin|> <|doc_id_begin|> 756349 <|doc_id_end|> <|doc_offset_begin|> 276 <|doc_offset_end|> Etawah\\nFarrukhabad\\nAuraiya\\nKanpur\\n\\nIn the non-Doabi areas, it is spoken in Hardoi, western parts of Lak\n",
      "<|doc_begin|> <|doc_id_begin|> 4276452 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Track and field at the 2015 Military World Games – Men's discus throw <|doc_title_en\n",
      "<|doc_begin|> <|doc_id_begin|> 2665672 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Aloi (disambiguation) <|doc_title_end|> <|doc_body_begin|> Aloi is a town in Uganda.\n",
      "<|doc_begin|> <|doc_id_begin|> 2665672 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  Aloi (1965– ), Mexican racing car driver <|doc_body_end|> <|doc_end|>\n",
      "<|doc_begin|> <|doc_id_begin|> 744597 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  1st prize in drawing at the Royal Academy of Painting and Sculpture.\\nFrom 1668 to 1671 he lived in Ital\n",
      "<|doc_begin|> <|doc_id_begin|> 744597 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  1678.\\nBy 1684 he was a Professor.\\nHe exhibited at the Salon of 1704.\\nHe died in Paris in 1730.\\n\\nŒuvres\n",
      "<|doc_begin|> <|doc_id_begin|> 744597 <|doc_id_end|> <|doc_offset_begin|> 273 <|doc_offset_end|>  de la religion, oil on canvas, 53x43cm, Paris, Musée du Louvre.\\nLa Chute des anges rebelles, oil on ca\n"
     ]
    }
   ],
   "source": [
    "for toks in docs_chunks:\n",
    "    s = tokten_to_text(toks)\n",
    "    print(s[:200].replace('\\n', '\\\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embs = model_encdec.run_enc_emb(target_chunks)\n",
    "docs_embs = model_encdec.run_enc_emb(docs_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.157678 F\n",
      "0.200629 F\n",
      "0.147184 F\n",
      "0.143557 F\n",
      "0.017989 F\n",
      "-0.021412 F\n",
      "0.397230 T\n",
      "0.011577 F\n",
      "0.085528 F\n",
      "0.188297 F\n",
      "0.340801 F\n",
      "0.156483 F\n"
     ]
    }
   ],
   "source": [
    "cosine = False\n",
    "cosine = True\n",
    "print_dist(target_embs, docs_embs, target_mask, cosine=cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_encoder.src_word_emb.weight (50270, 256) -0.010897282 -1.5456724e-06 0.010897281\n",
      "vocab_encoder.layer_norm.weight (256,) -0.09994151 -0.003787417 0.09852063\n",
      "vocab_encoder.layer_norm.bias (256,) -0.09938567 0.002720798 0.09817394\n",
      "encoders.0.layer_stack.0.slf_attn.w_qs.weight (256, 256) -0.10825065 0.0003224965 0.10825294\n",
      "encoders.0.layer_stack.0.slf_attn.w_ks.weight (256, 256) -0.10825259 0.00016920731 0.1082493\n",
      "encoders.0.layer_stack.0.slf_attn.w_vs.weight (256, 256) -0.10824857 -0.00027747374 0.10825134\n",
      "encoders.0.layer_stack.0.slf_attn.fc.weight (256, 256) -0.10824688 5.7866688e-05 0.108252995\n",
      "encoders.0.layer_stack.0.slf_attn.layer_norm.weight (256,) -0.099243365 -0.0010800387 0.09971624\n",
      "encoders.0.layer_stack.0.slf_attn.layer_norm.bias (256,) -0.09992782 0.00231219 0.09992212\n",
      "encoders.0.layer_stack.0.pos_ffn.w_1.weight (1024, 256) -0.06846407 1.4100352e-05 0.06846438\n",
      "encoders.0.layer_stack.0.pos_ffn.w_1.bias (1024,) -0.09947839 -3.29467e-06 0.0999241\n",
      "encoders.0.layer_stack.0.pos_ffn.w_2.weight (256, 1024) -0.068465255 -2.5921194e-05 0.06846529\n",
      "encoders.0.layer_stack.0.pos_ffn.w_2.bias (256,) -0.09962374 -0.0006341485 0.098760426\n",
      "encoders.0.layer_stack.0.pos_ffn.layer_norm.weight (256,) -0.09910443 0.0049770735 0.09966948\n",
      "encoders.0.layer_stack.0.pos_ffn.layer_norm.bias (256,) -0.09947266 -0.001050842 0.09958517\n",
      "encoders.0.w_em.weight (1, 100) -0.24082695 -0.013617029 0.24329084\n",
      "decoders.0.layer_stack.0.slf_attn.w_qs.weight (256, 256) -0.10825178 -0.00021054226 0.10824827\n",
      "decoders.0.layer_stack.0.slf_attn.w_ks.weight (256, 256) -0.10825028 -0.00017672178 0.108250685\n",
      "decoders.0.layer_stack.0.slf_attn.w_vs.weight (256, 256) -0.10825021 0.000113781774 0.108250745\n",
      "decoders.0.layer_stack.0.slf_attn.fc.weight (256, 256) -0.108250916 -0.00032123562 0.108251184\n",
      "decoders.0.layer_stack.0.slf_attn.layer_norm.weight (256,) -0.0975849 -1.847741e-05 0.0991794\n",
      "decoders.0.layer_stack.0.slf_attn.layer_norm.bias (256,) -0.099788226 -0.00017501367 0.099923566\n",
      "decoders.0.layer_stack.0.pos_ffn.w_1.weight (1024, 256) -0.06846486 1.5073492e-05 0.068464644\n",
      "decoders.0.layer_stack.0.pos_ffn.w_1.bias (1024,) -0.09961404 -0.00073100394 0.09997877\n",
      "decoders.0.layer_stack.0.pos_ffn.w_2.weight (256, 1024) -0.06846364 0.00010940342 0.06846471\n",
      "decoders.0.layer_stack.0.pos_ffn.w_2.bias (256,) -0.099873535 0.00457132 0.099809125\n",
      "decoders.0.layer_stack.0.pos_ffn.layer_norm.weight (256,) -0.09874741 0.0031997215 0.09903258\n",
      "decoders.0.layer_stack.0.pos_ffn.layer_norm.bias (256,) -0.0999846 0.00038394233 0.09859996\n",
      "decoders.0.layer_norm.weight (256,) -0.09994691 0.0005793138 0.09836799\n",
      "decoders.0.layer_norm.bias (256,) -0.098675966 0.0048854817 0.0992013\n",
      "decoders.0.rank_prj.weight (1, 256) -0.15237506 -0.0064108297 0.15069172\n"
     ]
    }
   ],
   "source": [
    "inp_len = ds_loader.emb_chunk_size if ds_loader.fixed_size else calc_max_inp_size(ds_loader.emb_chunk_size)\n",
    "model_ranker_cfg = create_mllm_ranker_cfg(\n",
    "    n_vocab=len(tokenizer), inp_len=inp_len, d_word_wec=256,\n",
    "    n_levels=1, enc_n_layers=1, dec_n_layers=1,\n",
    "    n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024,\n",
    "    pad_idx=pad_tok, dropout_rate=0.1, enc_with_emb_mat=True,\n",
    ")\n",
    "\n",
    "model_ranker = MllmRanker(model_ranker_cfg).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_ranker = torch.load(ranker_snapshot_path)\n",
    "model_ranker.load_state_dict(checkpoint_ranker['model'])\n",
    "model_ranker.eval()\n",
    "del checkpoint_ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 100]),\n",
       " torch.Size([3, 100]),\n",
       " tensor([False, False, False, False, False, False, False, False, False,  True,\n",
       "          True,  True]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 10\n",
    "batch = ds_loader.get_batch(i, train=True)\n",
    "docs_chunks, target_chunks, target_mask = batch.gen_tensors()\n",
    "docs_chunks.shape, target_chunks.shape, target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|query_begin|>  1st prize in drawing at the Royal Academy of Painting and Sculpture.\\nFrom 1668 to 1671 he lived in Italy at the Medici Villa.\\nHe won the Prix de Rome for drawing in 1668 for his work Première conquête de la Franche-Comté,\\nand again in 1671 for Le Roi donnant la paix à l'Europe.\\nHe was admitted to the Academy in 1678.\\nBy 1684 he was a Professor.\\nHe exhibited at the Salon of 1704.\\nHe died in Paris in 1730.\\n\\nŒuvres \\nMany of his drawings and paintings are at the Musée du Louvre.  They include:\\n Saint Paulin de Nole, drawing in red with white chalk highlights, 36.5\\xa0cm  x 28.5\\xa0cm\\nLe triomphe de la religion, oil on canvas, 53x43cm, Paris, Musée du Louvre.\\nLa Chute des anges rebelles, oil on canvas, 163x134cm, Paris, Musée du Louvre.\\nA number of his drawings on religious subjects were made into prints by the engraver Nicolas-Henri Tardieu and are now held in the Museum of Fine Arts of Nancy.\\n\\nGallery\\n\\n <|query_end|>\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_target = tokten_to_text(target_chunks)\n",
    "s_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|doc_begin|> <|doc_id_begin|> 2723747 <|doc_id_end|> <|doc_offset_begin|> 1089 <|doc_offset_end|> : Aspects of Abstract Painting since 1970, curated by Lily Wei; Visual Arts Gallery, New York\\n\\n1996\\nS\n",
      "<|doc_begin|> <|doc_id_begin|> 2723747 <|doc_id_end|> <|doc_offset_begin|> 1179 <|doc_offset_end|>  by Saul Ostrow; Usdan Gallery, Bennington College, Bennington, Vermont\\nNatural Process, Center Galle\n",
      "<|doc_begin|> <|doc_id_begin|> 2723747 <|doc_id_end|> <|doc_offset_begin|> 1269 <|doc_offset_end|> 1994\\nNew York Abstract Painting, Salvatore Ala Gallery, New York\\n\\n1993\\nItalia – America: L’astrazione\n",
      "<|doc_begin|> <|doc_id_begin|> 756349 <|doc_id_end|> <|doc_offset_begin|> 2195 <|doc_offset_end|>  after word tasla so it is an example of eco formation process. Some other examples are\\n\\n haldi-waldi\\n\n",
      "<|doc_begin|> <|doc_id_begin|> 756349 <|doc_id_end|> <|doc_offset_begin|> 2286 <|doc_offset_end|> \\ndama:d  → sarka:r ko dama:d\\n\\ndama:d is a person who is preferred very much in his/her in-laws family/\n",
      "<|doc_begin|> <|doc_id_begin|> 756349 <|doc_id_end|> <|doc_offset_begin|> 2377 <|doc_offset_end|> khchil͜li:\\n\\nOnomatopoeic words \\nOnomatopoeic words are supposed as absolute or original words. They so\n",
      "<|doc_begin|> <|doc_id_begin|> 4276452 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Track and field at the 2015 Military World Games – Men's discus throw <|doc_title_en\n",
      "<|doc_begin|> <|doc_id_begin|> 2665672 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Aloi (disambiguation) <|doc_title_end|> <|doc_body_begin|> Aloi is a town in Uganda.\n",
      "<|doc_begin|> <|doc_id_begin|> 2665672 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  Aloi (1965– ), Mexican racing car driver <|doc_body_end|> <|doc_end|>\n",
      "<|doc_begin|> <|doc_id_begin|> 744597 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  1st prize in drawing at the Royal Academy of Painting and Sculpture.\\nFrom 1668 to 1671 he lived in Ital\n",
      "<|doc_begin|> <|doc_id_begin|> 744597 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  1678.\\nBy 1684 he was a Professor.\\nHe exhibited at the Salon of 1704.\\nHe died in Paris in 1730.\\n\\nŒuvres\n",
      "<|doc_begin|> <|doc_id_begin|> 744597 <|doc_id_end|> <|doc_offset_begin|> 273 <|doc_offset_end|>  de la religion, oil on canvas, 53x43cm, Paris, Musée du Louvre.\\nLa Chute des anges rebelles, oil on ca\n"
     ]
    }
   ],
   "source": [
    "for toks in docs_chunks:\n",
    "    s = tokten_to_text(toks)\n",
    "    print(s[:200].replace('\\n', '\\\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embs = model_ranker.run_enc_emb(target_chunks)\n",
    "docs_embs = model_ranker.run_enc_emb(docs_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.229338 0.503317 0.487222 F\n",
      "0.098186 0.371476 0.392254 F\n",
      "0.184128 0.496609 0.498269 F\n",
      "-0.049690 0.064302 0.018029 F\n",
      "0.061651 0.016034 -0.064635 F\n",
      "-0.014851 0.081973 0.004711 F\n",
      "-0.261946 -0.156148 -0.126469 F\n",
      "0.365198 0.179673 0.196634 F\n",
      "-0.120499 -0.023255 0.088105 F\n",
      "0.744169 0.534230 0.453429 T\n",
      "0.650417 0.657011 0.579204 T\n",
      "0.528779 0.635975 0.575344 T\n"
     ]
    }
   ],
   "source": [
    "cosine = False\n",
    "cosine = True\n",
    "print_dist(target_embs, docs_embs, target_mask, cosine=cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.113991 F\n",
      "0.003470 F\n",
      "0.094656 F\n",
      "-0.167752 F\n",
      "-0.219987 F\n",
      "-0.117217 F\n",
      "0.085706 F\n",
      "0.089210 F\n",
      "0.511148 F\n",
      "0.122731 T\n",
      "0.121838 T\n",
      "0.089691 T\n"
     ]
    }
   ],
   "source": [
    "txt = 'Hong Kong 1987'\n",
    "txt = 'Climate Classification system, Mays Landing has a humid subtropical climate, abbreviated \"Cfa\"'\n",
    "# txt = 'Climate Classification system'\n",
    "txt = 'War and Peace'\n",
    "txt = '1st prize in drawing 1668 Italy'\n",
    "cosine = True\n",
    "txt_tokens = text_to_tokens(txt, qbeg_tok=qbeg_tok, qend_tok=qend_tok)\n",
    "txt_embs = model_ranker.run_enc_emb(txt_tokens)\n",
    "print_dist(txt_embs, docs_embs, target_mask, cosine=cosine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0095e-05],\n",
       "         [1.2888e-05],\n",
       "         [1.0771e-05],\n",
       "         [2.1788e-06],\n",
       "         [3.8103e-06],\n",
       "         [3.2414e-06],\n",
       "         [6.5914e-05],\n",
       "         [2.2676e-03],\n",
       "         [1.7381e-04],\n",
       "         [9.8576e-05],\n",
       "         [8.9405e-06],\n",
       "         [5.7049e-06]]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = model_ranker(txt_tokens, docs_chunks)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0127],\n",
       "         [0.0119],\n",
       "         [0.0085],\n",
       "         [0.0038],\n",
       "         [0.0075],\n",
       "         [0.0041],\n",
       "         [0.0006],\n",
       "         [0.0013],\n",
       "         [0.0007],\n",
       "         [0.1171],\n",
       "         [0.5373],\n",
       "         [0.2596]]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = model_ranker(target_chunks, docs_chunks)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.randint(1, 2, size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
