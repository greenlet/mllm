{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import Optional\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import GPT2Tokenizer, AddedToken, PreTrainedTokenizer\n",
    "\n",
    "from mllm.data.wiki.dswiki import WikiDsLoader\n",
    "from mllm.model.mllm_encdec import MllmEncdec\n",
    "from mllm.model.mllm_ranker import MllmRanker\n",
    "from mllm.exp.cfg import create_mllm_encdec_cfg, create_mllm_ranker_cfg\n",
    "from mllm.tokenization.chunk_tokenizer import calc_max_inp_size, gen_all_tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(os.path.expandvars('$HOME')) / 'data'\n",
    "TRAIN_ENCDEC_PATH = DATA_PATH / 'train_mllm_encdec'\n",
    "# TRAIN_RANKER_PATH = DATA_PATH / 'train_mllm_ranker'\n",
    "TRAIN_RANKER_PATH = DATA_PATH / 'train_mllm_ranker_qs'\n",
    "DS_DIR_PATH = DATA_PATH / 'wiki_20200501_en' / 'ch_100_fixed'\n",
    "\n",
    "encdec_subdir = 'encdec-20240718_221554-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240722_225232-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240724_230827-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240726_232850-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240722_225232-wiki_20200501_en-ch_100_fixed'\n",
    "ranker_subdir = 'ranker-20240730_213328-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240806_221913-msmarco'\n",
    "ranker_subdir = 'ranker-20240814_212415-msmarco'\n",
    "encdec_train_path = TRAIN_ENCDEC_PATH / encdec_subdir\n",
    "ranker_train_path = TRAIN_RANKER_PATH / ranker_subdir\n",
    "encdec_snapshot_path = encdec_train_path / 'best.pth'\n",
    "ranker_snapshot_path = ranker_train_path / 'best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "docs_batch_size = 5\n",
    "max_chunks_per_doc = 3\n",
    "device = 'cpu'\n",
    "# device = 'cuda'\n",
    "\n",
    "device = torch.device(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cache from /home/misha/data/wiki_20200501_en/ch_100_fixed/.mllm/ds.csv\n",
      "Loaded dataset size: 50989207\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', model_max_length=100000)\n",
    "tok_dict = gen_all_tokens(tokenizer)\n",
    "pad_tok, qbeg_tok, qend_tok = tok_dict['pad'].ind, tok_dict['query_begin'].ind, tok_dict['query_end'].ind\n",
    "ds_loader = WikiDsLoader(\n",
    "    ds_path=DS_DIR_PATH, docs_batch_size=docs_batch_size, max_chunks_per_doc=max_chunks_per_doc,\n",
    "    pad_tok=pad_tok, qbeg_tok=qbeg_tok, qend_tok=qend_tok, device=device,\n",
    ")\n",
    "ds_loader.shuffle(train=True)\n",
    "ds_loader.shuffle(train=False)\n",
    "inp_len = ds_loader.emb_chunk_size if ds_loader.fixed_size else calc_max_inp_size(ds_loader.emb_chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokten_to_text(tokens: torch.Tensor) -> str:\n",
    "    tokens = tokens.flatten()\n",
    "    tokens = tokens[tokens != pad_tok]\n",
    "    tokens = list(tokens)\n",
    "    s = tokenizer.decode(tokens)\n",
    "    return s\n",
    "\n",
    "def distance(x: np.ndarray, y: np.ndarray, cosine: bool = False):\n",
    "    if not cosine:\n",
    "        return np.linalg.norm(x - y)\n",
    "    x_norm, y_norm = np.linalg.norm(x), np.linalg.norm(y)\n",
    "    return np.sum(x * y) / (x_norm * y_norm)\n",
    "\n",
    "def text_to_tokens(s: str, qbeg_tok: Optional[int] = None, qend_tok: Optional[int] = None) -> torch.Tensor:\n",
    "    tokens = tokenizer(s)['input_ids']\n",
    "    if qbeg_tok is not None:\n",
    "        assert qend_tok is not None\n",
    "        tokens = [qbeg_tok, *tokens, qend_tok]\n",
    "    n_tokens = len(tokens)\n",
    "    n_padded = n_tokens // inp_len + (n_tokens % inp_len > 0)\n",
    "    res = np.full((n_padded * inp_len, ), pad_tok, dtype=np.int32)\n",
    "    res[:n_tokens] = tokens\n",
    "    res = torch.from_numpy(res).to(device)\n",
    "    res = res.reshape(n_padded, inp_len)\n",
    "    return res\n",
    "\n",
    "def print_dist(target_embs: torch.Tensor, docs_embs: torch.Tensor, target_mask: torch.Tensor, cosine: bool = True):\n",
    "    for i, docs_emb in enumerate(docs_embs.detach().numpy()):\n",
    "        for target_emb in target_embs.detach().numpy():\n",
    "            dist = distance(target_emb, docs_emb, cosine)\n",
    "            print(f'{dist:0.6f} ', end='')\n",
    "        sfx = 'T' if target_mask[i] else 'F'\n",
    "        print(sfx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_encoder.src_word_emb.weight (50270, 256) -0.010897281 -1.8666622e-06 0.010897279\n",
      "vocab_encoder.layer_norm.weight (256,) -0.09827324 0.005363074 0.09857943\n",
      "vocab_encoder.layer_norm.bias (256,) -0.099614 -0.00033356063 0.09982528\n",
      "encoder.layer_stack.0.slf_attn.w_qs.weight (256, 256) -0.10823792 0.0002399791 0.108251676\n",
      "encoder.layer_stack.0.slf_attn.w_ks.weight (256, 256) -0.10824498 3.197349e-05 0.10824982\n",
      "encoder.layer_stack.0.slf_attn.w_vs.weight (256, 256) -0.10824938 -0.00019202907 0.1082476\n",
      "encoder.layer_stack.0.slf_attn.fc.weight (256, 256) -0.108250074 3.539113e-05 0.10824882\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.weight (256,) -0.09914669 -0.0065606707 0.09979097\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.bias (256,) -0.099993445 -0.00055581884 0.09999251\n",
      "encoder.layer_stack.0.pos_ffn.w_1.weight (1024, 256) -0.068464994 -2.0417589e-05 0.06846526\n",
      "encoder.layer_stack.0.pos_ffn.w_1.bias (1024,) -0.099808134 -0.0007240103 0.09992351\n",
      "encoder.layer_stack.0.pos_ffn.w_2.weight (256, 1024) -0.0684651 -7.118905e-05 0.06846522\n",
      "encoder.layer_stack.0.pos_ffn.w_2.bias (256,) -0.09991314 -0.0005049228 0.099973515\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.weight (256,) -0.09978654 0.00066655385 0.09973943\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.bias (256,) -0.09920194 -0.0006293059 0.09649084\n",
      "encoder.w_em.weight (1, 100) -0.24300508 -0.01904188 0.23121975\n",
      "encoder.layer_norm.weight (256,) -0.09864433 0.00026536058 0.099187925\n",
      "encoder.layer_norm.bias (256,) -0.09953687 0.0018475568 0.09853114\n",
      "decoder.A_emb2sec (100, 256, 256) -0.008113919 2.0313037e-06 0.008113912\n",
      "decoder.att_layers.0.slf_attn.w_qs.weight (256, 256) -0.10824974 0.0005463927 0.10825018\n",
      "decoder.att_layers.0.slf_attn.w_ks.weight (256, 256) -0.108251885 0.00011533842 0.10824787\n",
      "decoder.att_layers.0.slf_attn.w_vs.weight (256, 256) -0.10825191 0.00013190316 0.108239286\n",
      "decoder.att_layers.0.slf_attn.fc.weight (256, 256) -0.10825026 4.43116e-05 0.10825183\n",
      "decoder.att_layers.0.slf_attn.layer_norm.weight (256,) -0.0999103 -0.008322891 0.09985931\n",
      "decoder.att_layers.0.slf_attn.layer_norm.bias (256,) -0.098052576 0.0011469827 0.09908984\n",
      "decoder.att_layers.0.pos_ffn.w_1.weight (1024, 256) -0.06846509 0.00012823819 0.06846497\n",
      "decoder.att_layers.0.pos_ffn.w_1.bias (1024,) -0.09999969 0.00017584593 0.099828936\n",
      "decoder.att_layers.0.pos_ffn.w_2.weight (256, 1024) -0.06846482 4.8797734e-05 0.06846496\n",
      "decoder.att_layers.0.pos_ffn.w_2.bias (256,) -0.09985781 -0.0032852318 0.098176934\n",
      "decoder.att_layers.0.pos_ffn.layer_norm.weight (256,) -0.09837432 0.0005972923 0.09908024\n",
      "decoder.att_layers.0.pos_ffn.layer_norm.bias (256,) -0.09814429 0.0021599315 0.09918069\n",
      "vocab_decoder.word_prj.weight (50270, 256) -0.010897282 1.2571276e-06 0.010897281\n"
     ]
    }
   ],
   "source": [
    "model_encdec_cfg = create_mllm_encdec_cfg(\n",
    "    n_vocab=len(tokenizer), d_word_wec=256, inp_len=inp_len,\n",
    "    enc_n_layers=1, dec_n_layers=1,\n",
    "    n_heads=8, d_model=256, d_inner=1024,\n",
    "    pad_idx=pad_tok, dropout_rate=0.1, enc_with_emb_mat=True,\n",
    ")\n",
    "model_encdec = MllmEncdec(model_encdec_cfg).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_encdec = torch.load(encdec_snapshot_path)\n",
    "model_encdec.load_state_dict(checkpoint_encdec['model'], strict=False)\n",
    "model_encdec.eval()\n",
    "del checkpoint_encdec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496,   612, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267]],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_tokens('Hello there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 100]),\n",
       " torch.Size([1, 100]),\n",
       " tensor([False, False, False, False,  True,  True, False, False, False, False,\n",
       "         False, False]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 10\n",
    "batch = ds_loader.get_batch(i, train=True)\n",
    "docs_chunks, target_chunks, target_mask = batch.gen_tensors()\n",
    "docs_chunks.shape, target_chunks.shape, target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|query_begin|> John Williams HarrisJohn Williams Harris (1808–4 February 1872) was a New Zealand trader, whaler and farmer. He was born in Cornwall, United Kingdom, in 1808.\\n\\nReferences\\n\\nCategory:1808 births\\nCategory:1872 deaths\\nCategory:New Zealand farmers\\nCategory:New Zealand traders\\nCategory:New Zealand whalers\\nCategory:Cornish emigrants to New Zealand\\nCategory:Cornish farmers <|query_end|>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_target = tokten_to_text(target_chunks)\n",
    "s_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|doc_begin|> <|doc_id_begin|> 2510265 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Oswaldo Larriva <|doc_title_end|> <|doc_body_begin|> Óscar Oswaldo Larriva Alvarado \n",
      "<|doc_begin|> <|doc_id_begin|> 2510265 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  of Azuay Province in 2019.\\n\\nOn 6 January 2020, Larriva died from cancer at age 74.\\n\\nReferences\\n\\nCatego\n",
      "<|doc_begin|> <|doc_id_begin|> 4439084 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Daulatpur Thikriya <|doc_title_end|> <|doc_body_begin|> Daulatpur Thikriya is a vill\n",
      "<|doc_begin|> <|doc_id_begin|> 4439084 <|doc_id_end|> <|doc_offset_begin|> 90 <|doc_offset_end|>  rate of population excluding children aged 6 and below) is 60.33%.\\n\\nReferences \\n\\nCategory:Villages in \n",
      "<|doc_begin|> <|doc_id_begin|> 4480279 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> John Williams Harris <|doc_title_end|> <|doc_body_begin|> John Williams Harris (1808\n",
      "<|doc_begin|> <|doc_id_begin|> 4480279 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|> Cornish farmers <|doc_body_end|> <|doc_end|>\n",
      "<|doc_begin|> <|doc_id_begin|> 674954 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> UK Addiction Treatment <|doc_title_end|> <|doc_body_begin|> UK Addiction Treatment Ce\n",
      "<|doc_begin|> <|doc_id_begin|> 674954 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  private rooms for a 10 day stay or a full 28 day detox. Patients typically follow the 12-step program.\\n\n",
      "<|doc_begin|> <|doc_id_begin|> 674954 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  addictions doubled in 2018. Admissions for OTC drug addiction increased 22%. In 2018, UKAT has admitte\n",
      "<|doc_begin|> <|doc_id_begin|> 2398859 <|doc_id_end|> <|doc_offset_begin|> 1449 <|doc_offset_end|> ong.\\nThe toe–tow merger is a merger of the Early Modern English vowels  and.\\nThe cot–coat merger is a\n",
      "<|doc_begin|> <|doc_id_begin|> 2398859 <|doc_id_end|> <|doc_offset_begin|> 1539 <|doc_offset_end|>  of the diphthongs  and  before voiced consonants occurring for some speakers of African American Ver\n",
      "<|doc_begin|> <|doc_id_begin|> 2398859 <|doc_id_end|> <|doc_offset_begin|> 1629 <|doc_offset_end|> \" /koəl/.\\nThe muse–mews merger is the merger of /yː/ and /ɪu/ occurring for most English speakers. So\n"
     ]
    }
   ],
   "source": [
    "for toks in docs_chunks:\n",
    "    s = tokten_to_text(toks)\n",
    "    print(s[:200].replace('\\n', '\\\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embs = model_encdec.run_enc_emb(target_chunks)\n",
    "docs_embs = model_encdec.run_enc_emb(docs_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.614007 F\n",
      "0.673856 F\n",
      "0.625156 F\n",
      "0.629489 F\n",
      "0.763358 T\n",
      "0.573496 T\n",
      "0.632314 F\n",
      "0.644705 F\n",
      "0.639496 F\n",
      "0.644607 F\n",
      "0.652777 F\n",
      "0.596580 F\n"
     ]
    }
   ],
   "source": [
    "cosine = False\n",
    "cosine = True\n",
    "print_dist(target_embs, docs_embs, target_mask, cosine=cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_encoder.src_word_emb.weight (50270, 256) -0.010897281 -6.751595e-07 0.010897281\n",
      "vocab_encoder.layer_norm.weight (256,) -0.09936471 -0.003953435 0.09939728\n",
      "vocab_encoder.layer_norm.bias (256,) -0.099776365 0.0010321124 0.09996175\n",
      "encoders.0.layer_stack.0.slf_attn.w_qs.weight (256, 256) -0.108252876 -6.340468e-05 0.108252995\n",
      "encoders.0.layer_stack.0.slf_attn.w_ks.weight (256, 256) -0.10825134 0.00023663577 0.10824148\n",
      "encoders.0.layer_stack.0.slf_attn.w_vs.weight (256, 256) -0.10825018 0.00010743411 0.10825088\n",
      "encoders.0.layer_stack.0.slf_attn.fc.weight (256, 256) -0.1082491 7.4542084e-05 0.10824958\n",
      "encoders.0.layer_stack.0.slf_attn.layer_norm.weight (256,) -0.09864228 -0.00070906454 0.098641984\n",
      "encoders.0.layer_stack.0.slf_attn.layer_norm.bias (256,) -0.09989204 -0.0014073192 0.09974086\n",
      "encoders.0.layer_stack.0.pos_ffn.w_1.weight (1024, 256) -0.06846465 9.7233125e-05 0.06846488\n",
      "encoders.0.layer_stack.0.pos_ffn.w_1.bias (1024,) -0.09999335 0.0012871977 0.09993503\n",
      "encoders.0.layer_stack.0.pos_ffn.w_2.weight (256, 1024) -0.06846522 0.000112974645 0.06846384\n",
      "encoders.0.layer_stack.0.pos_ffn.w_2.bias (256,) -0.09949342 0.0018351849 0.09715368\n",
      "encoders.0.layer_stack.0.pos_ffn.layer_norm.weight (256,) -0.097536325 -0.004072068 0.09964573\n",
      "encoders.0.layer_stack.0.pos_ffn.layer_norm.bias (256,) -0.09765609 0.0030308305 0.09949131\n",
      "encoders.0.w_em.weight (1, 100) -0.24344352 0.0060627996 0.24293011\n",
      "encoders.0.layer_norm.weight (256,) -0.0996119 -0.003213338 0.09981096\n",
      "encoders.0.layer_norm.bias (256,) -0.099811554 -0.002938888 0.099328555\n",
      "decoders.0.w.weight (256, 256) -0.108247705 -0.00017546024 0.10825044\n",
      "decoders.0.layer_norm.weight (256,) -0.098690905 0.006388145 0.09966525\n",
      "decoders.0.layer_norm.bias (256,) -0.0986852 -0.0022070613 0.09977132\n"
     ]
    }
   ],
   "source": [
    "inp_len = ds_loader.emb_chunk_size if ds_loader.fixed_size else calc_max_inp_size(ds_loader.emb_chunk_size)\n",
    "model_ranker_cfg = create_mllm_ranker_cfg(\n",
    "    n_vocab=len(tokenizer), inp_len=inp_len, d_word_wec=256,\n",
    "    n_levels=1, enc_n_layers=1, dec_n_layers=1,\n",
    "    n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024,\n",
    "    pad_idx=pad_tok, dropout_rate=0.1, enc_with_emb_mat=True,\n",
    ")\n",
    "\n",
    "model_ranker = MllmRanker(model_ranker_cfg).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_ranker = torch.load(ranker_snapshot_path)\n",
    "model_ranker.load_state_dict(checkpoint_ranker['model'])\n",
    "model_ranker.eval()\n",
    "del checkpoint_ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 100]),\n",
       " torch.Size([1, 100]),\n",
       " tensor([False, False, False, False,  True,  True, False, False, False, False,\n",
       "         False, False]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 10\n",
    "batch = ds_loader.get_batch(i, train=True)\n",
    "docs_chunks, target_chunks, target_mask = batch.gen_tensors()\n",
    "docs_chunks.shape, target_chunks.shape, target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|query_begin|> John Williams HarrisJohn Williams Harris (1808–4 February 1872) was a New Zealand trader, whaler and farmer. He was born in Cornwall, United Kingdom, in 1808.\\n\\nReferences\\n\\nCategory:1808 births\\nCategory:1872 deaths\\nCategory:New Zealand farmers\\nCategory:New Zealand traders\\nCategory:New Zealand whalers\\nCategory:Cornish emigrants to New Zealand\\nCategory:Cornish farmers <|query_end|>'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_target = tokten_to_text(target_chunks)\n",
    "s_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|doc_begin|> <|doc_id_begin|> 2510265 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Oswaldo Larriva <|doc_title_end|> <|doc_body_begin|> Óscar Oswaldo Larriva Alvarado \n",
      "<|doc_begin|> <|doc_id_begin|> 2510265 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  of Azuay Province in 2019.\\n\\nOn 6 January 2020, Larriva died from cancer at age 74.\\n\\nReferences\\n\\nCatego\n",
      "<|doc_begin|> <|doc_id_begin|> 4439084 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Daulatpur Thikriya <|doc_title_end|> <|doc_body_begin|> Daulatpur Thikriya is a vill\n",
      "<|doc_begin|> <|doc_id_begin|> 4439084 <|doc_id_end|> <|doc_offset_begin|> 90 <|doc_offset_end|>  rate of population excluding children aged 6 and below) is 60.33%.\\n\\nReferences \\n\\nCategory:Villages in \n",
      "<|doc_begin|> <|doc_id_begin|> 4480279 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> John Williams Harris <|doc_title_end|> <|doc_body_begin|> John Williams Harris (1808\n",
      "<|doc_begin|> <|doc_id_begin|> 4480279 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|> Cornish farmers <|doc_body_end|> <|doc_end|>\n",
      "<|doc_begin|> <|doc_id_begin|> 674954 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> UK Addiction Treatment <|doc_title_end|> <|doc_body_begin|> UK Addiction Treatment Ce\n",
      "<|doc_begin|> <|doc_id_begin|> 674954 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  private rooms for a 10 day stay or a full 28 day detox. Patients typically follow the 12-step program.\\n\n",
      "<|doc_begin|> <|doc_id_begin|> 674954 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  addictions doubled in 2018. Admissions for OTC drug addiction increased 22%. In 2018, UKAT has admitte\n",
      "<|doc_begin|> <|doc_id_begin|> 2398859 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  of the idiosyncrasies in English spelling.\\n\\nThe shortening of ante-penultimate syllables in Middle Eng\n",
      "<|doc_begin|> <|doc_id_begin|> 2398859 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  tense and lax vowels.\\n\\nIn some varieties of English, this occurs in particular before  and (in rhotic\n",
      "<|doc_begin|> <|doc_id_begin|> 2398859 <|doc_id_end|> <|doc_offset_begin|> 273 <|doc_offset_end|> . For these speakers, words with  like beg, egg, Greg, keg, leg and peg rhyme with words with   like C\n"
     ]
    }
   ],
   "source": [
    "for toks in docs_chunks:\n",
    "    s = tokten_to_text(toks)\n",
    "    print(s[:200].replace('\\n', '\\\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embs = model_ranker.run_enc_emb(target_chunks)\n",
    "docs_embs = model_ranker.run_enc_emb(docs_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.569388 F\n",
      "0.464496 F\n",
      "0.548942 F\n",
      "0.535388 F\n",
      "0.899940 T\n",
      "0.519560 T\n",
      "0.145180 F\n",
      "0.463652 F\n",
      "0.204229 F\n",
      "0.175676 F\n",
      "0.272292 F\n",
      "0.343683 F\n"
     ]
    }
   ],
   "source": [
    "cosine = False\n",
    "cosine = True\n",
    "print_dist(target_embs, docs_embs, target_mask, cosine=cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n",
      "0.424732 F\n",
      "0.314930 F\n",
      "0.380358 F\n",
      "0.516397 F\n",
      "0.366578 T\n",
      "0.645302 T\n",
      "0.283477 F\n",
      "0.387487 F\n",
      "0.208015 F\n",
      "0.346727 F\n",
      "0.279248 F\n",
      "0.332401 F\n"
     ]
    }
   ],
   "source": [
    "txt = 'Hong Kong 1987'\n",
    "txt = 'Climate Classification system, Mays Landing has a humid subtropical climate, abbreviated \"Cfa\"'\n",
    "# txt = 'Climate Classification system'\n",
    "txt = 'War and Peace'\n",
    "txt = 'Bandar Express, Ichhamati Express and Benapole Express'\n",
    "txt = 'Rick Anderson'\n",
    "txt = 'John Williams Harris 1808'\n",
    "cosine = True\n",
    "txt_tokens = text_to_tokens(txt, qbeg_tok=qbeg_tok, qend_tok=qend_tok)\n",
    "# txt_tokens = txt_tokens.repeat(3, 1)\n",
    "print(txt_tokens.shape)\n",
    "txt_embs = model_ranker.run_enc_emb(txt_tokens)\n",
    "print_dist(txt_embs, docs_embs, target_mask, cosine=cosine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6312, 0.4497, 0.7059, 0.6515, 0.6643, 0.6516, 0.2519, 0.7166, 0.2107,\n",
       "         0.3248, 0.3066, 0.4003]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rank = model_ranker.run_qs_infer(docs_chunks, txt_tokens)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8737, 0.8907, 0.7371, 0.5201, 0.4101, 0.8237, 0.7342, 0.8183, 0.8694,\n",
       "         0.6263, 0.6608, 0.6087, 0.2565, 0.3135, 0.3250]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = model_ranker(txt_tokens, docs_chunks)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6538e-21, 3.7294e-11, 2.4412e-19, 3.4020e-23, 7.5630e-20, 3.8663e-25,\n",
       "         1.3986e-18, 7.2614e-22, 1.0000e+00, 1.0000e+00, 1.0000e+00, 4.7166e-09,\n",
       "         1.9997e-11, 1.3684e-08]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = model_ranker(target_chunks, docs_chunks)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
