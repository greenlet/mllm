{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import Optional\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import GPT2Tokenizer, AddedToken, PreTrainedTokenizer\n",
    "\n",
    "from mllm.data.wiki.dswiki import WikiDsLoader\n",
    "from mllm.model.mllm_encdec import MllmEncdec\n",
    "from mllm.model.mllm_ranker import MllmRanker\n",
    "from mllm.exp.cfg import create_mllm_encdec_cfg, create_mllm_ranker_cfg\n",
    "from mllm.tokenization.chunk_tokenizer import calc_max_inp_size, gen_all_tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(os.path.expandvars('$HOME')) / 'data'\n",
    "TRAIN_ENCDEC_PATH = DATA_PATH / 'train_mllm_encdec'\n",
    "# TRAIN_RANKER_PATH = DATA_PATH / 'train_mllm_ranker'\n",
    "TRAIN_RANKER_PATH = DATA_PATH / 'train_mllm_ranker_qs'\n",
    "DS_DIR_PATH = DATA_PATH / 'wiki_20200501_en' / 'ch_100_fixed'\n",
    "\n",
    "encdec_subdir = 'encdec-20240718_221554-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240722_225232-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240724_230827-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240726_232850-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240722_225232-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240730_213328-wiki_20200501_en-ch_100_fixed'\n",
    "# ranker_subdir = 'ranker-20240806_221913-msmarco'\n",
    "# ranker_subdir = 'ranker-20240815_180317-msmarco'\n",
    "ranker_subdir = 'ranker-20240830_232515-msmarco-fever'\n",
    "encdec_train_path = TRAIN_ENCDEC_PATH / encdec_subdir\n",
    "# ranker_train_path = TRAIN_RANKER_PATH / ranker_subdir\n",
    "ranker_train_path = DATA_PATH / 'train_mllm_ranker_qrels' / ranker_subdir\n",
    "encdec_snapshot_path = encdec_train_path / 'best.pth'\n",
    "ranker_snapshot_path = ranker_train_path / 'best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "docs_batch_size = 5\n",
    "max_chunks_per_doc = 3\n",
    "device = 'cpu'\n",
    "# device = 'cuda'\n",
    "\n",
    "device = torch.device(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cache from /home/misha/data/wiki_20200501_en/ch_100_fixed/.mllm/ds.csv\n",
      "Loaded dataset size: 50989207\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', model_max_length=100000)\n",
    "tok_dict = gen_all_tokens(tokenizer)\n",
    "pad_tok, qbeg_tok, qend_tok = tok_dict['pad'].ind, tok_dict['query_begin'].ind, tok_dict['query_end'].ind\n",
    "ds_loader = WikiDsLoader(\n",
    "    ds_path=DS_DIR_PATH, docs_batch_size=docs_batch_size, max_chunks_per_doc=max_chunks_per_doc,\n",
    "    pad_tok=pad_tok, qbeg_tok=qbeg_tok, qend_tok=qend_tok, device=device,\n",
    ")\n",
    "ds_loader.shuffle(train=True)\n",
    "ds_loader.shuffle(train=False)\n",
    "inp_len = ds_loader.emb_chunk_size if ds_loader.fixed_size else calc_max_inp_size(ds_loader.emb_chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokten_to_text(tokens: torch.Tensor) -> str:\n",
    "    tokens = tokens.flatten()\n",
    "    tokens = tokens[tokens != pad_tok]\n",
    "    tokens = list(tokens)\n",
    "    s = tokenizer.decode(tokens)\n",
    "    return s\n",
    "\n",
    "def distance(x: np.ndarray, y: np.ndarray, cosine: bool = False):\n",
    "    if not cosine:\n",
    "        return np.linalg.norm(x - y)\n",
    "    x_norm, y_norm = np.linalg.norm(x), np.linalg.norm(y)\n",
    "    return np.sum(x * y) / (x_norm * y_norm)\n",
    "\n",
    "def text_to_tokens(s: str, qbeg_tok: Optional[int] = None, qend_tok: Optional[int] = None) -> torch.Tensor:\n",
    "    tokens = tokenizer(s)['input_ids']\n",
    "    if qbeg_tok is not None:\n",
    "        assert qend_tok is not None\n",
    "        tokens = [qbeg_tok, *tokens, qend_tok]\n",
    "    n_tokens = len(tokens)\n",
    "    n_padded = n_tokens // inp_len + (n_tokens % inp_len > 0)\n",
    "    res = np.full((n_padded * inp_len, ), pad_tok, dtype=np.int32)\n",
    "    res[:n_tokens] = tokens\n",
    "    res = torch.from_numpy(res).to(device)\n",
    "    res = res.reshape(n_padded, inp_len)\n",
    "    return res\n",
    "\n",
    "def print_dist(target_embs: torch.Tensor, docs_embs: torch.Tensor, target_mask: torch.Tensor, cosine: bool = True):\n",
    "    for i, docs_emb in enumerate(docs_embs.detach().numpy()):\n",
    "        for target_emb in target_embs.detach().numpy():\n",
    "            dist = distance(target_emb, docs_emb, cosine)\n",
    "            print(f'{dist:0.6f} ', end='')\n",
    "        sfx = 'T' if target_mask[i] else 'F'\n",
    "        print(sfx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_encoder.src_word_emb.weight (50270, 256) -0.010897282 -7.307192e-07 0.010897281\n",
      "vocab_encoder.layer_norm.weight (256,) -0.09903387 -0.00037897477 0.099014\n",
      "vocab_encoder.layer_norm.bias (256,) -0.09947115 0.0054700524 0.0999892\n",
      "encoder.layer_stack.0.slf_attn.w_qs.weight (256, 256) -0.10825222 3.0783922e-06 0.108249314\n",
      "encoder.layer_stack.0.slf_attn.w_ks.weight (256, 256) -0.108250104 0.00014931659 0.10824773\n",
      "encoder.layer_stack.0.slf_attn.w_vs.weight (256, 256) -0.108249344 0.00015622671 0.10824616\n",
      "encoder.layer_stack.0.slf_attn.fc.weight (256, 256) -0.10825161 -0.00036529166 0.10825222\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.weight (256,) -0.099452436 -0.0011238996 0.09880356\n",
      "encoder.layer_stack.0.slf_attn.layer_norm.bias (256,) -0.09775269 -0.0021109863 0.09953707\n",
      "encoder.layer_stack.0.pos_ffn.w_1.weight (1024, 256) -0.06846505 -0.00024030457 0.06846458\n",
      "encoder.layer_stack.0.pos_ffn.w_1.bias (1024,) -0.09998661 1.6074628e-06 0.099938095\n",
      "encoder.layer_stack.0.pos_ffn.w_2.weight (256, 1024) -0.06846437 0.00014953893 0.06846513\n",
      "encoder.layer_stack.0.pos_ffn.w_2.bias (256,) -0.09950399 8.630357e-05 0.09980068\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.weight (256,) -0.099788904 -0.0013694994 0.09949763\n",
      "encoder.layer_stack.0.pos_ffn.layer_norm.bias (256,) -0.099202 0.0010072044 0.099944904\n",
      "encoder.w_em.weight (1, 100) -0.24370395 -0.0058969622 0.23695414\n",
      "encoder.layer_norm.weight (256,) -0.09873604 -0.002790293 0.09735414\n",
      "encoder.layer_norm.bias (256,) -0.09974509 0.0035143131 0.099932626\n",
      "decoder.A_emb2sec (100, 256, 256) -0.008113919 -2.70077e-06 0.008113917\n",
      "decoder.att_layers.0.slf_attn.w_qs.weight (256, 256) -0.10825285 0.00034705095 0.10825266\n",
      "decoder.att_layers.0.slf_attn.w_ks.weight (256, 256) -0.10824857 1.3373392e-05 0.10825316\n",
      "decoder.att_layers.0.slf_attn.w_vs.weight (256, 256) -0.10824848 -0.0006494292 0.10824743\n",
      "decoder.att_layers.0.slf_attn.fc.weight (256, 256) -0.108251885 4.9813923e-05 0.108241014\n",
      "decoder.att_layers.0.slf_attn.layer_norm.weight (256,) -0.09996469 -0.0011300792 0.098074175\n",
      "decoder.att_layers.0.slf_attn.layer_norm.bias (256,) -0.09994751 0.0028959322 0.099780045\n",
      "decoder.att_layers.0.pos_ffn.w_1.weight (1024, 256) -0.068465315 -0.00016590243 0.068464525\n",
      "decoder.att_layers.0.pos_ffn.w_1.bias (1024,) -0.09989607 -0.0017506484 0.09952736\n",
      "decoder.att_layers.0.pos_ffn.w_2.weight (256, 1024) -0.06846467 1.8775099e-06 0.0684653\n",
      "decoder.att_layers.0.pos_ffn.w_2.bias (256,) -0.099847846 -0.0030422066 0.09660833\n",
      "decoder.att_layers.0.pos_ffn.layer_norm.weight (256,) -0.09977233 0.0038040623 0.09994157\n",
      "decoder.att_layers.0.pos_ffn.layer_norm.bias (256,) -0.099411145 -0.0014481294 0.099824764\n",
      "vocab_decoder.word_prj.weight (50270, 256) -0.010897281 1.6369663e-06 0.010897281\n"
     ]
    }
   ],
   "source": [
    "model_encdec_cfg = create_mllm_encdec_cfg(\n",
    "    n_vocab=len(tokenizer), d_word_wec=256, inp_len=inp_len,\n",
    "    enc_n_layers=1, dec_n_layers=1,\n",
    "    n_heads=8, d_model=256, d_inner=1024,\n",
    "    pad_idx=pad_tok, dropout_rate=0.1, enc_with_emb_mat=True,\n",
    ")\n",
    "model_encdec = MllmEncdec(model_encdec_cfg).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_encdec = torch.load(encdec_snapshot_path)\n",
    "model_encdec.load_state_dict(checkpoint_encdec['model'], strict=False)\n",
    "model_encdec.eval()\n",
    "del checkpoint_encdec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496,   612, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267,\n",
       "         50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267, 50267]],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_tokens('Hello there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14, 100]),\n",
       " torch.Size([2, 100]),\n",
       " tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True,  True]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 10\n",
    "batch = ds_loader.get_batch(i, train=True)\n",
    "docs_chunks, target_chunks, target_mask = batch.gen_tensors()\n",
    "docs_chunks.shape, target_chunks.shape, target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|query_begin|> Coleophora squamosellaColeophora squamosella is a moth of the family Coleophoridae. It is found in Europe (from Great Britain to Poland and Hungary and from Fennoscandia to France, Italy and Austria), the Baltic states, the Caucasus, Russia (Baikal and Altai) and Turkey.\\n\\nThe wingspan is 11–13\\xa0mm. Adults are on wing in June and July.\\n\\nThe larvae feed in a case on Erigeron species, including Erigeron acer.\\n\\nReferences\\n\\nExternal links\\n Lepiforum.de\\n\\nsquamosella\\nCategory:Moths described in 1856\\nCategory:Moths of Asia\\nCategory:Moths of Europe\\nCategory:Taxa named by Henry Tibbats Stainton <|query_end|>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_target = tokten_to_text(target_chunks)\n",
    "s_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|doc_begin|> <|doc_id_begin|> 363907 <|doc_id_end|> <|doc_offset_begin|> 818 <|doc_offset_end|>  the combined efforts of a strengthened Graystripe and newly trained Millie is enough to fight them off\n",
      "<|doc_begin|> <|doc_id_begin|> 363907 <|doc_id_end|> <|doc_offset_begin|> 908 <|doc_offset_end|>  series.\\n\\nCritical Reaction\\nThe Lost Warrior was praised by Publishers Weekly, which felt that \"Many li\n",
      "<|doc_begin|> <|doc_id_begin|> 363907 <|doc_id_end|> <|doc_offset_begin|> 998 <|doc_offset_end|> seaux praised both the writing and artwork of the book: \"Writer Dan Jolley hits the ground running, sho\n",
      "<|doc_begin|> <|doc_id_begin|> 1353355 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|> (V, E2) if \\nE1 ⊆ E ⊆ E2.\\nThe graph sandwich problem for property Π is defined as follows:\\n\\nGraph Sandw\n",
      "<|doc_begin|> <|doc_id_begin|> 1353355 <|doc_id_end|> <|doc_offset_begin|> 273 <|doc_offset_end|>  ⊆ E ⊆ E2 and G satisfies property Π?\\n\\nThe recognition problem for a class of graphs (those satisfying\n",
      "<|doc_begin|> <|doc_id_begin|> 1353355 <|doc_id_end|> <|doc_offset_begin|> 364 <|doc_offset_end|>, comparability graph, permutation graph, chordal bipartite graph, or chain graph. It can be solved in \n",
      "<|doc_begin|> <|doc_id_begin|> 3503856 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Dillon Gabriel <|doc_title_end|> <|doc_body_begin|> Dillon Gabriel is an American fo\n",
      "<|doc_begin|> <|doc_id_begin|> 3503856 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  the University of Central Florida to play college football (UCF).\\n\\nCollege career\\nGabriel entered his \n",
      "<|doc_begin|> <|doc_id_begin|> 3503856 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|> Category:Living people\\nCategory:Players of American football from Hawaii\\nCategory:American football qu\n",
      "<|doc_begin|> <|doc_id_begin|> 1929789 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  and Joel Schumacher, as the Dark Knight film series provides a full arc for the character and was inte\n",
      "<|doc_begin|> <|doc_id_begin|> 1929789 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  begins fighting crime in Gotham City as Batman, utilizing advanced technology in doing so and basing \n",
      "<|doc_begin|> <|doc_id_begin|> 1929789 <|doc_id_end|> <|doc_offset_begin|> 273 <|doc_offset_end|>.\\n\\nCharacter concept and development\\n\\nBatman first appeared in DC Comics stories in 1939 as the writers\n",
      "<|doc_begin|> <|doc_id_begin|> 553056 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Coleophora squamosella <|doc_title_end|> <|doc_body_begin|> Coleophora squamosella is\n",
      "<|doc_begin|> <|doc_id_begin|> 553056 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  June and July.\\n\\nThe larvae feed in a case on Erigeron species, including Erigeron acer.\\n\\nReferences\\n\\nEx\n"
     ]
    }
   ],
   "source": [
    "for toks in docs_chunks:\n",
    "    s = tokten_to_text(toks)\n",
    "    print(s[:200].replace('\\n', '\\\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embs = model_encdec.run_enc_emb(target_chunks)\n",
    "docs_embs = model_encdec.run_enc_emb(docs_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.685041 0.596315 F\n",
      "0.645687 0.553201 F\n",
      "0.640477 0.568395 F\n",
      "0.708415 0.589032 F\n",
      "0.700093 0.562377 F\n",
      "0.671513 0.563533 F\n",
      "0.651670 0.515344 F\n",
      "0.662804 0.521132 F\n",
      "0.600119 0.680734 F\n",
      "0.632610 0.550342 F\n",
      "0.599716 0.575529 F\n",
      "0.701156 0.560992 F\n",
      "0.835970 0.634110 T\n",
      "0.710499 0.725314 T\n"
     ]
    }
   ],
   "source": [
    "cosine = False\n",
    "cosine = True\n",
    "print_dist(target_embs, docs_embs, target_mask, cosine=cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_encoder.src_word_emb.weight (50270, 256) -0.010897278 1.1813366e-06 0.010897279\n",
      "vocab_encoder.layer_norm.weight (256,) -0.099263765 -0.0056994637 0.09828945\n",
      "vocab_encoder.layer_norm.bias (256,) -0.09996396 -0.0025367192 0.09967184\n",
      "encoders.0.layer_stack.0.slf_attn.w_qs.weight (256, 256) -0.10825035 -0.00019270678 0.10825103\n",
      "encoders.0.layer_stack.0.slf_attn.w_ks.weight (256, 256) -0.108252995 0.0003052362 0.10825147\n",
      "encoders.0.layer_stack.0.slf_attn.w_vs.weight (256, 256) -0.10824431 0.00021790384 0.10825293\n",
      "encoders.0.layer_stack.0.slf_attn.fc.weight (256, 256) -0.108249806 -0.0001041878 0.10825263\n",
      "encoders.0.layer_stack.0.slf_attn.layer_norm.weight (256,) -0.09909047 0.002910266 0.09988958\n",
      "encoders.0.layer_stack.0.slf_attn.layer_norm.bias (256,) -0.09803982 0.00083962997 0.09796279\n",
      "encoders.0.layer_stack.0.pos_ffn.w_1.weight (1024, 256) -0.06846532 -5.16994e-05 0.06846457\n",
      "encoders.0.layer_stack.0.pos_ffn.w_1.bias (1024,) -0.09976538 0.0021414077 0.0999813\n",
      "encoders.0.layer_stack.0.pos_ffn.w_2.weight (256, 1024) -0.0684653 -1.3883434e-05 0.06846462\n",
      "encoders.0.layer_stack.0.pos_ffn.w_2.bias (256,) -0.09521476 0.002662808 0.09890775\n",
      "encoders.0.layer_stack.0.pos_ffn.layer_norm.weight (256,) -0.09941099 -0.0076603703 0.09851251\n",
      "encoders.0.layer_stack.0.pos_ffn.layer_norm.bias (256,) -0.09907893 -0.0041869273 0.097813606\n",
      "encoders.0.w_em.weight (1, 100) -0.23609312 -0.0052162088 0.2286787\n",
      "encoders.0.layer_norm.weight (256,) -0.09948206 -0.0070748576 0.09909085\n",
      "encoders.0.layer_norm.bias (256,) -0.09983275 -0.0048615495 0.099953294\n",
      "decoders.0.w.weight (256, 256) -0.10824987 0.00026496188 0.10824982\n",
      "decoders.0.layer_norm.weight (256,) -0.09810865 0.004260531 0.099297345\n",
      "decoders.0.layer_norm.bias (256,) -0.099953525 0.0034048595 0.09988052\n"
     ]
    }
   ],
   "source": [
    "inp_len = ds_loader.emb_chunk_size if ds_loader.fixed_size else calc_max_inp_size(ds_loader.emb_chunk_size)\n",
    "model_ranker_cfg = create_mllm_ranker_cfg(\n",
    "    n_vocab=len(tokenizer), inp_len=inp_len, d_word_wec=256,\n",
    "    n_levels=1, enc_n_layers=1, dec_n_layers=1,\n",
    "    n_heads=8, d_k=32, d_v=32, d_model=256, d_inner=1024,\n",
    "    pad_idx=pad_tok, dropout_rate=0.1, enc_with_emb_mat=True,\n",
    ")\n",
    "\n",
    "model_ranker = MllmRanker(model_ranker_cfg).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_ranker = torch.load(ranker_snapshot_path)\n",
    "model_ranker.load_state_dict(checkpoint_ranker['model'])\n",
    "model_ranker.eval()\n",
    "del checkpoint_ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14, 100]),\n",
       " torch.Size([3, 100]),\n",
       " tensor([False, False, False, False, False, False, False, False, False,  True,\n",
       "          True,  True, False, False]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 10\n",
    "batch = ds_loader.get_batch(i, train=True)\n",
    "docs_chunks, target_chunks, target_mask = batch.gen_tensors()\n",
    "docs_chunks.shape, target_chunks.shape, target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|query_begin|>  only a couple of months to help him physically prepare for the role. He first went well over the weight required and created concern over whether he would look right for the part. Bale recognized that his large physique was not appropriate for Batman, who relies on speed and strategy. He lost the excess weight by the time filming began. Bale trained in Wing Chun Kung Fu under Eric Oram in preparation for the movie. Child actor Gus Lewis portrays an 8-year-old Bruce at the beginning of the film.\\n\\nBale reprised the role of Batman in the sequel The Dark Knight, released on July 18, 2008. He trained in the Keysi Fighting Method, and performed many of his own stunts. He reprised the role again for the sequel The Dark Knight Rises, released on July 20, 2012. Bale became the actor to have portrayed Batman on film for the lengthiest period. Following the shooting at a midnight showing of The Dark Knight Rises, he visited survivors of the movie theater in an Aurora, Colorado hospital. Despite the success of the Dark Knight Trilogy, Bale decided not to return for a potential fourth film appearance as Batman out of respect for Christopher Nolan's creative direction and the fact that the trilogy provided a full arc for the character.\\n\\nVoice\\n\\nThough previous Batman actors Michael Keaton and Kevin Conroy created <|query_end|>\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_target = tokten_to_text(target_chunks)\n",
    "s_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|doc_begin|> <|doc_id_begin|> 363907 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  James Barry.\\n\\nPlot summary\\nThe Lost Warrior opens with narration from Graystripe, a warrior who was sep\n",
      "<|doc_begin|> <|doc_id_begin|> 363907 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|>  attempt to flee but gets lost in Twolegplace and battles with a kittypet named Duke. After being force\n",
      "<|doc_begin|> <|doc_id_begin|> 363907 <|doc_id_end|> <|doc_offset_begin|> 273 <|doc_offset_end|>  Twolegplace. She then shows it to Graystripe and asks him to teach her how to hunt and fight after lea\n",
      "<|doc_begin|> <|doc_id_begin|> 1353355 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|> (V, E2) if \\nE1 ⊆ E ⊆ E2.\\nThe graph sandwich problem for property Π is defined as follows:\\n\\nGraph Sandw\n",
      "<|doc_begin|> <|doc_id_begin|> 1353355 <|doc_id_end|> <|doc_offset_begin|> 273 <|doc_offset_end|>  ⊆ E ⊆ E2 and G satisfies property Π?\\n\\nThe recognition problem for a class of graphs (those satisfying\n",
      "<|doc_begin|> <|doc_id_begin|> 1353355 <|doc_id_end|> <|doc_offset_begin|> 364 <|doc_offset_end|>, comparability graph, permutation graph, chordal bipartite graph, or chain graph. It can be solved in \n",
      "<|doc_begin|> <|doc_id_begin|> 3503856 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Dillon Gabriel <|doc_title_end|> <|doc_body_begin|> Dillon Gabriel is an American fo\n",
      "<|doc_begin|> <|doc_id_begin|> 3503856 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  the University of Central Florida to play college football (UCF).\\n\\nCollege career\\nGabriel entered his \n",
      "<|doc_begin|> <|doc_id_begin|> 3503856 <|doc_id_end|> <|doc_offset_begin|> 182 <|doc_offset_end|> Category:Living people\\nCategory:Players of American football from Hawaii\\nCategory:American football qu\n",
      "<|doc_begin|> <|doc_id_begin|> 1929789 <|doc_id_end|> <|doc_offset_begin|> 1539 <|doc_offset_end|>  only a couple of months to help him physically prepare for the role. He first went well over the wei\n",
      "<|doc_begin|> <|doc_id_begin|> 1929789 <|doc_id_end|> <|doc_offset_begin|> 1629 <|doc_offset_end|> year-old Bruce at the beginning of the film.\\n\\nBale reprised the role of Batman in the sequel The Dark\n",
      "<|doc_begin|> <|doc_id_begin|> 1929789 <|doc_id_end|> <|doc_offset_begin|> 1719 <|doc_offset_end|>  Following the shooting at a midnight showing of The Dark Knight Rises, he visited survivors of the m\n",
      "<|doc_begin|> <|doc_id_begin|> 553056 <|doc_id_end|> <|doc_offset_begin|> 0 <|doc_offset_end|> <|doc_title_begin|> Coleophora squamosella <|doc_title_end|> <|doc_body_begin|> Coleophora squamosella is\n",
      "<|doc_begin|> <|doc_id_begin|> 553056 <|doc_id_end|> <|doc_offset_begin|> 91 <|doc_offset_end|>  June and July.\\n\\nThe larvae feed in a case on Erigeron species, including Erigeron acer.\\n\\nReferences\\n\\nEx\n"
     ]
    }
   ],
   "source": [
    "for toks in docs_chunks:\n",
    "    s = tokten_to_text(toks)\n",
    "    print(s[:200].replace('\\n', '\\\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embs = model_ranker.run_enc_emb(target_chunks)\n",
    "docs_embs = model_ranker.run_enc_emb(docs_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.719577 0.795197 0.721252 F\n",
      "0.601030 0.647313 0.544734 F\n",
      "0.799284 0.755250 0.678450 F\n",
      "0.044161 0.152418 0.302960 F\n",
      "0.076853 0.116556 0.247412 F\n",
      "0.068192 0.091181 0.179821 F\n",
      "0.531020 0.374339 0.441042 F\n",
      "0.572577 0.367769 0.423692 F\n",
      "0.377396 0.291212 0.371668 F\n",
      "0.969273 0.852169 0.780423 T\n",
      "0.839205 0.974415 0.878834 T\n",
      "0.804989 0.911748 0.950284 T\n",
      "0.234581 0.394426 0.307070 F\n",
      "0.100861 0.176553 0.153062 F\n"
     ]
    }
   ],
   "source": [
    "cosine = False\n",
    "cosine = True\n",
    "print_dist(target_embs, docs_embs, target_mask, cosine=cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n",
      "0.198856 F\n",
      "0.254959 F\n",
      "0.152381 F\n",
      "0.598274 F\n",
      "0.535477 F\n",
      "0.416071 F\n",
      "0.066260 F\n",
      "0.030352 F\n",
      "0.191550 F\n",
      "0.132326 T\n",
      "0.280754 T\n",
      "0.288930 T\n",
      "0.282488 F\n",
      "0.348249 F\n"
     ]
    }
   ],
   "source": [
    "txt = 'Hong Kong 1987'\n",
    "txt = 'Climate Classification system, Mays Landing has a humid subtropical climate, abbreviated \"Cfa\"'\n",
    "# txt = 'Climate Classification system'\n",
    "txt = 'War and Peace'\n",
    "txt = 'Bandar Express, Ichhamati Express and Benapole Express'\n",
    "txt = 'Rick Anderson'\n",
    "txt = 'Makangarawe Temeke ward'\n",
    "# txt = 'graph sandwich'\n",
    "txt = 'james barry'\n",
    "txt = 'erigeron'\n",
    "txt = 'Dillon Gabriel america'\n",
    "txt = 'graph sandwich'\n",
    "# txt = 'The graph sandwich problem for property Π is defined as follows:'\n",
    "cosine = True\n",
    "txt_tokens = text_to_tokens(txt, qbeg_tok=qbeg_tok, qend_tok=qend_tok)\n",
    "# txt_tokens = txt_tokens.repeat(3, 1)\n",
    "print(txt_tokens.shape)\n",
    "txt_embs = model_ranker.run_enc_emb(txt_tokens)\n",
    "print_dist(txt_embs, docs_embs, target_mask, cosine=cosine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0357, 0.1303, 0.0144, 0.9366, 0.8794, 0.5010, 0.0042, 0.0024, 0.0354,\n",
       "         0.0126, 0.0750, 0.0531, 0.0980, 0.1661]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rank = model_ranker.run_qs_infer(docs_chunks, txt_tokens)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442500"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 59\n",
    "batch_size = 15\n",
    "train_steps = 500\n",
    "\n",
    "n_epochs * train_steps * batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8737, 0.8907, 0.7371, 0.5201, 0.4101, 0.8237, 0.7342, 0.8183, 0.8694,\n",
       "         0.6263, 0.6608, 0.6087, 0.2565, 0.3135, 0.3250]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = model_ranker(txt_tokens, docs_chunks)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6538e-21, 3.7294e-11, 2.4412e-19, 3.4020e-23, 7.5630e-20, 3.8663e-25,\n",
       "         1.3986e-18, 7.2614e-22, 1.0000e+00, 1.0000e+00, 1.0000e+00, 4.7166e-09,\n",
       "         1.9997e-11, 1.3684e-08]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = model_ranker(target_chunks, docs_chunks)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
